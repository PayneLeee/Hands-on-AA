{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "11ca1230678c48aba78d4012d7c6e7e2",
    "deepnote_app_block_group_id": null,
    "deepnote_app_block_order": 0,
    "deepnote_app_block_visible": true,
    "deepnote_cell_type": "markdown",
    "id": "E5AD5587F5624CBC8AFC9750B93D3A99",
    "mdEditEnable": false
   },
   "source": [
    "# 第一章 初探大模型智能体"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "f22ab96c9b8d477b8e1c1dc9bad2e3d8",
    "deepnote_app_block_group_id": null,
    "deepnote_app_block_order": 1,
    "deepnote_app_block_visible": true,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## 1.1 简介\n",
    "<!-- 从传统对话系统谈起，回顾 LLM 与智能体技术栈的交汇（说清楚LLM和智能体的本质区别）。传统智能体和现代语言语言智能体，以及一些有意思的开放讨论。 -->\n",
    "\n",
    "亲爱的读者，欢迎翻开《动手学大模型智能体》！在这本书中，我们将带你从零开始，系统掌握大模型智能体的核心原理与实践方法。你不仅会了解智能体技术的演进脉络，还将动手编写、调试并部署真正能“感知—思考—执行”的智能代理；每一个示例都配有简洁易懂的代码，让你在实战中迅速上手。无论你是对人工智能初窥门径的新手，还是希望将大模型能力落地为实际产品的开发者，这本书都将成为你最可靠的实践指南。现在，就让我们一起打开第一章的大门，开启一场从代码到智能体的奇妙旅程吧！\n",
    "\n",
    "在过去几十年里，软件代理和智能助手已经经历了从简单脚本与规则引擎（如电子邮件过滤器、批处理脚本），到引入统计和神经网络技术的智能体框架，直至如今以大型语言模型（LLM）为核心、能够理解与生成自然语言的智能体系统的演化历程。然而，仅依赖大模型强大的“语言能力”并不能让程序真正“懂得行动”——它们更像能够回答问题的百科全书，而非能够自主感知环境、制定行动策略并执行各种任务的“智能体”。本章将带你穿越传统软件代理与现代大模型智能体的分水岭：一方面回顾软件代理从硬编码规则到生成式模型的演进思路，另一方面剖析智能体的本质——将语言理解、规划算法与执行引擎有机融合，才能实现“感知—思考—执行”的闭环，让程序从接收指令到多步推理再到实际行动，真正具备完整的智能行为。\n",
    "\n",
    "\n",
    "在接下来的小节里，我们将一步步揭示智能体与环境、人与智能体之间的交互模式；同时，你将动手搭建第一个简单的问答助手，体验如何从安装依赖、调用API，到观察输出、分析结果，快速迈入大模型智能体的实践世界。让我们从这里，打开智能体的大门。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "77aca8f641c74c7cbe132ba0bf6e2904",
    "deepnote_app_block_group_id": null,
    "deepnote_app_block_order": 2,
    "deepnote_app_block_visible": true,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## 1.2 什么是智能体\n",
    "<!-- 介绍什么是“智能体”，以及其产生的背景和发展历程（从对话系统开始）。\n",
    "通俗解释智能体的定义（自主感知和行动的系统），帮助新人理解基本概念。 -->\n",
    "智能体（Agent）这一概念，最早源自对“让机器像人一样思考和行动”的追求。20 世纪 50 年代，计算机科学家提出了“人工智能”（AI）这一宏大目标，并通过专家系统、规则引擎尝试让程序在受限环境中执行决策。进入 90 年代，随着互联网和分布式计算的发展，“软件代理”（Software Agent）应运而生：它们能在网络中自动搜集信息、完成交易或过滤邮件，具备了一定的“主动性”。21 世纪以来，强化学习、多智能体系统，以及深度学习的突破，让机器人在物理世界中自主导航、协作；与此同时，大型语言模型（LLM）的出现，将自然语言理解和生成能力注入智能体，使得它们不仅能“看”与“听”，还能“说”与“写”，真正迈向通用智能代理的时代。\n",
    "\n",
    "![image](./assets/cp1_1.png)\n",
    "\n",
    "基于以上背景，我们可以进一步对智能体进行一个通俗的概括：**智能体就是一个能够“自己看见世界、自己思考、自己做决定并付诸行动”的程序或装置**。为了更好地理解，我们可以把它拆成三个关键环节：\n",
    "* **感知：** 智能体首先通过各种“传感器”获取对世界的初步认知：物理机器人借助摄像头、激光雷达等硬件扫描周围环境；软件代理会监听网络消息、读取日志或调用外部 API 获取数据；而基于大模型的语言智能体则接收用户的文字或语音输入。所有这些感知信息汇聚成对“当前状态”的数字化描述，为后续思考提供基础。\n",
    "* **思考：** 在拥有了对环境的感知后，智能体会结合自身的目标与记忆（包括先前的经验和内部状态），运用规则系统、规划算法或深度学习模型来分析当前形势。这一过程类似于我们人类在做选择前进行权衡——评估各种可能性、预测未来结果，并最终确定最优策略。无论是调度清扫路径、策划多步对话，还是制定协作方案，智能体都在这一环节中完成“思考—决策”的关键一跃。\n",
    "* **行动：** 决策一旦形成，智能体就会将其转化为实际操作：机器人驱动电机行走或操控机械臂执行物理动作；自动化脚本在服务器上发起请求、读写文件；LLM 智能体则调用接口或直接输出生成的文本答案。执行的结果又会被实时反馈到感知模块，使得“感知–思考–行动”的闭环得以持续，不断循环直到任务目标达成。\n",
    "\n",
    "\n",
    "举个例子，扫地机器人就是一种直观的智能体：它先用传感器扫描房间地图（感知），再根据家中布局规划清扫路线（思考），最后驱动滚刷和轮子开始清洁（决策），并在一段时间后或遇到障碍时不断重复“感知-—思考—行动”这一过程，直到清扫完成。现代的大模型智能体，则是在这一框架上，加入了对自然语言深度理解与生成的能力，让“指令—规划—执行”的闭环更灵活、更通用，也更贴近人类与机器的自然交互。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "5591fa2602bf413cb9ff457960d26108",
    "deepnote_app_block_group_id": null,
    "deepnote_app_block_order": 3,
    "deepnote_app_block_visible": true,
    "deepnote_cell_type": "markdown",
    "id": "A9ED05C1D4AA43A6960DB0FEC8A9B069",
    "mdEditEnable": false
   },
   "source": [
    "## 1.3 智能体中的交互\n",
    "\n",
    "在了解了智能体“感知–思考–行动”三步闭环的基本流程后，我们再进一步聚焦“交互”这一核心环节。智能体的价值很大程度上体现在它与外界——无论是人与环境——的双向互动能力。接下来，我们分别从“智能体与人”和“智能体与环境”两个维度来剖析。\n",
    "![image](./assets/cp1_2.png)\n",
    "\n",
    "### 1.3.1 智能体与人的交互\n",
    "<!-- 接收目标指令、输出回复 -->\n",
    "智能体与人的交互是大模型智能体最直观、最常见的场景，也是用户体验的关键所在。一个成熟的对话式智能体通常会经历以下几个环节：\n",
    "* **输入理解：** 智能体首先在输入理解阶段，通过多模态接入渠道获取用户信息：无论是文本输入、语音指令，还是界面上的点击与表单操作，都能被系统捕获并转为统一的数据格式；接着，借助分词与词性标注、命名实体识别和意图分类技术，智能体能够准确抽取出关键槽位（如时间、地点、人物）和用户意图；最后，通过追踪对话状态，它会将这些信息与历史上下文一同存储，确保在多轮交互中不会丢失先前已收集的约束条件或细节。\n",
    "* **对话管理：** 进入对话管理阶段后，智能体会依据当前对话状态和预设业务逻辑，决策下一步最合适的动作：可能是调用外部 API（如天气、航班查询）、检索内部知识库，或触发本地子流程（如日程创建、文件下载）；如果用户提供的信息不完整或存在歧义，系统会主动生成补充问题，通过多轮问答的形式澄清需求，直到获得执行任务所需的全部要素。\n",
    "* **输出生成：** 在输出生成阶段，智能体将决策结果转化为用户能够理解和操作的形式：自然语言生成模块可选用模板化填槽、检索式回复或基于大型语言模型的生成式输出，以兼顾可控性与灵活性；同时，结合文字、语音播报、卡片式图文以及交互按钮等多媒体呈现方式，智能体不仅准确地传达信息，还能为用户提供后续操作入口，完成一次流畅、高效的“人机对话—执行”闭环。\n",
    "以下是一个完整的交互流程示例：\n",
    "\n",
    "> **示例交互流程**\n",
    "> 1. **用户**：\n",
    ">    “帮我订明天下午从上海到北京的机票。”\n",
    "> 2. **智能体（输入理解）**：\n",
    ">    * 意图：订票\n",
    ">    * 槽位：{出发地: 上海, 目的地: 北京, 时间: 明天下午}\n",
    "> 3. **智能体（对话管理）**：\n",
    ">    * 检查缺失信息 → 发现未指定乘客人数\n",
    ">    * 生成澄清问题\n",
    "> 4. **智能体（输出生成）**：\n",
    ">    “请问是为几位乘客预订？”\n",
    "> 5. **用户**：\n",
    ">    “就我自己”\n",
    "> 6. **智能体（对话管理）**：\n",
    ">    * 从本地记忆中检索用户信息\n",
    ">    * 调用航班 API → 获取可用航班\n",
    ">    * 下单并请求确认\n",
    "> 7. **智能体（输出生成）**：\n",
    ">    “已为您预订 1 张明天下午上海→北京的机票\n",
    ">    航班号 MU513，票价 ￥620\n",
    ">    \\[查看订单详情] \\[取消订单]”\n",
    "\n",
    "\n",
    "### 1.3.2 智能体与环境的交互\n",
    "<!-- 感知环境状态、输出动作 -->\n",
    "智能体与环境的交互，是指智能体如何在虚拟或物理世界中持续感知外部变化、制定行动方案并付诸执行，再根据反馈不断优化自身行为。下面以**电商价格监控与自动下单智能体**为例，分别从感知、建模、决策、执行和反馈五个环节进行阐述。\n",
    "- **环境感知：** 智能体通过电商平台的公开 API、网页爬虫或消息队列，定时获取商品的实时价格、库存和促销信息。抓取到的 HTML 或 JSON 数据会经过清洗与解析——提取价格字段、转换时间格式、过滤无效条目——并存入结构化数据库或时序日志中，为后续分析提供高质量输入。\n",
    "- **状态估计与世界建模：** 在完成对实时价格、库存和促销信息的清洗与解析后，智能体会基于这些数据动态构建“市场模型”：既记录商品在各时间点的价格波动趋势，也对库存补货节奏和促销规则进行解析建模，同时将每次下单历史与市场变化关联存储。这个内部模型不仅反映了“当前是否值得购买”的状态，还为后续的预算分配和策略调整提供了全方位的环境上下文与历史参考。\n",
    "- **规划与决策：** 借助市场模型，智能体按照事先设定或在线学习得到的策略制定具体操作方案：当价格跌破历史平均值一定比例时自动触发下单；在监控多款商品时，结合各自的期望收益动态分配预算；在大型促销（如双十一）期间，则临时切换到高频“抢购模式”以提高下单并发与成功率，平时则保持较低频率以规避风险。这样，智能体能够在不断变化的市场环境中精准、灵活地做出高效决策。\n",
    "- **控制与执行：** 决策完成后，智能体通过调用平台下单 API 或模拟填单接口完成“下单”动作。全程监控接口响应：若遇验证码、人机验证或限流，系统会自动重试、切换代理或触发备用登录流程，直到订单成功提交或达到重试上限，确保执行的可靠性与稳定性。\n",
    "- **环境反馈与闭环：** 下单后，智能体持续通过订单 API、物流通知或支付回执监测订单状态——如支付成功、发货、签收等。当检测到“支付失败”或“缺货”时，自动启动补救策略（如重新下单、改选店铺）。同时，所有成功或失败的交互数据都会被写入日志与训练集，用于离线分析或模型训练，不断优化价格预测、策略决策和执行流程，真正实现“感知–思考–决策”的闭环生态。\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "c005a52a87014f00b294b4e5de9a284c",
    "deepnote_app_block_group_id": null,
    "deepnote_app_block_order": 4,
    "deepnote_app_block_visible": true,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## 1.4 大模型与智能体的交汇\n",
    "<!-- 阐述大型语言模型在智能体中扮演的角色，如何赋予智能体强大的自然语言理解与生成能力。\n",
    "列举LLM智能体可以完成的复杂任务类型（如回答问题、执行指令、多步推理等），激发读者兴趣。 -->\n",
    "\n",
    "在传统智能体的“感知–思考–行动”框架中，核心的“思考”往往依赖于固定规则或专门训练的策略网络，局限于针对某一任务的预定义逻辑。大型语言模型（LLM）的出现，为智能体带来了突破性的变化。它们通过在海量文本上预训练，学会了丰富的世界知识、上下文理解和语言生成能力。将 LLM 嵌入智能体中，意味着智能体能够：\n",
    "\n",
    "* **理解复杂指令：** 对于自然语言提问，或是多层次的复合命令，可以借助 LLM 解析用户意图和关键参数；\n",
    "* **动态生成策略：** 在内部推演多步操作方案，如拆解任务、生成行动计划，并以人类易懂的表达进行反馈；\n",
    "* **灵活调用工具：** 通过函数调用或 API 触发，LLM 智能体可以将语言中的“想法”转化为实际操作，如数据库查询、网页抓取或机器人动作指令；\n",
    "* **维护多轮上下文：** 凭借强大的记忆与连贯生成能力，LLM 智能体能够在长对话中追踪历史信息，避免上下文丢失。\n",
    "\n",
    "得益于这些能力，基于 LLM 的智能体可以胜任多种复杂任务类型，例如：\n",
    "\n",
    "* **问答与知识检索：** 从开放域百科到行业文档，迅速找到并组织答案；\n",
    "* **指令执行与自动化：** 根据用户口述或书面指令，自动填写表单、发送邮件、调度日程；\n",
    "* **多步推理与规划：** 如旅行行程规划，从预算约束到交通衔接，一次性给出可行方案；\n",
    "* **交互式教学与辅导：** 充当语言学习伙伴或编程助教，实时纠错并提供示例；\n",
    "* **创意与内容生成：** 撰写文章大纲、生成营销文案、构思故事情节；\n",
    "* **代码生成与调试：** 根据功能描述，输出可运行的代码片段，并能解读、修改已有代码；\n",
    "* **数据分析与报告：** 从原始表格或日志中提炼洞见，生成图表解读与文字总结；\n",
    "* **复杂工具链调用：** 在同一会话中，综合调用搜索引擎、翻译服务、地图 API 等多种外部资源。\n",
    "\n",
    "通过将 LLM 与智能体框架深度结合，我们不仅让程序“会说话”，更让它们拥有“会思考、会规划、会执行”的完整智能闭环。下一节，我们将通过实践示例，带你动手构建第一个基于 LLM 的问答助手，亲身体验大模型智能体如何将语言指令转化为具体行动。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9879e05841194bd8941ebd9edbc8c239",
    "deepnote_app_block_group_id": null,
    "deepnote_app_block_order": 5,
    "deepnote_app_block_visible": true,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## 1.5 实践第一个智能体\n",
    "接下来，我们先基于 Deepseek 接口尝试动手构建属于你的第一个“智能体”：一个极简版的问答小助手；初步体验 LLM API 的使用以及简单智能体的搭建流程。后续章节中我们将基于本地部署的 LLM 逐步扩展智能体的功能。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "ce013d8a6a9e44f9858c240ab5e22bb7",
    "deepnote_app_block_group_id": null,
    "deepnote_app_block_order": 6,
    "deepnote_app_block_visible": true,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<!-- 指导读者配置基础环境（Python环境、必要的库），为后续实践做准备。 -->\n",
    "**Step1: 库函数导入**\n",
    "为了能够调用 DeepSeek 的远程接口，我们需要先导入相应的工具包（SDK）。因为 DeepSeek 接口采用与 OpenAI 兼容的格式，读者可以直接使用 OpenAI SDK 或者兼容 OpenAI 接口的软件访问 DeepSeek 接口。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "b870665ef8864a85a3b38b7314c4e5f0",
    "deepnote_app_block_group_id": null,
    "deepnote_app_block_order": 7,
    "deepnote_app_block_visible": true,
    "deepnote_app_is_code_hidden": false,
    "deepnote_app_is_output_hidden": true,
    "deepnote_cell_type": "code",
    "execution_context_id": "9f496b80-6a22-406e-9d54-7c6571a274ed",
    "execution_millis": 5613,
    "execution_start": 1747641867139,
    "source_hash": "efa0bf09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.79.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai)\n",
      "  Downloading anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Downloading pydantic-2.11.4-py3-none-any.whl.metadata (66 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.6/66.6 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sniffio (from openai)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>4 (from openai)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions<5,>=4.11 in /tmp/python3.11/kernel-libs/lib/python3.11/site-packages (from openai) (4.13.2)\n",
      "Requirement already satisfied: idna>=2.8 in /tmp/python3.11/kernel-libs/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.8)\n",
      "Requirement already satisfied: certifi in /tmp/python3.11/kernel-libs/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Downloading openai-1.79.0-py3-none-any.whl (683 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m683.3/683.3 kB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.9/100.9 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jiter-0.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (352 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.2/352.2 kB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.11.4-py3-none-any.whl (443 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.9/443.9 kB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m106.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: typing-inspection, tqdm, sniffio, pydantic-core, jiter, h11, distro, annotated-types, pydantic, httpcore, anyio, httpx, openai\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.9.0 distro-1.9.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 jiter-0.10.0 openai-1.79.0 pydantic-2.11.4 pydantic-core-2.33.2 sniffio-1.3.1 tqdm-4.67.1 typing-inspection-0.4.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 导入 OpenAI SDK，如过尚未安装，可以先通过 pip3 install openai 指令进行安装\n",
    "!pip3 install openai\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "36f7e612c4524303ad17eb1e10886a32",
    "deepnote_app_block_group_id": null,
    "deepnote_app_block_order": 8,
    "deepnote_app_block_visible": true,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "**Step2: 实例化智能体**\n",
    "接下来，让我们来实现一个最简单的问答智能体，只需要寥寥几行代码即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "4b4cc6205237430eb3c3f3be781cc253",
    "deepnote_app_block_group_id": null,
    "deepnote_app_block_order": 9,
    "deepnote_app_block_visible": true,
    "deepnote_app_is_code_hidden": false,
    "deepnote_app_is_output_hidden": false,
    "deepnote_cell_type": "code",
    "execution_context_id": "9f496b80-6a22-406e-9d54-7c6571a274ed",
    "execution_millis": 23,
    "execution_start": 1747641879133,
    "source_hash": "4e481c5c"
   },
   "outputs": [],
   "source": [
    "# 定义智能体类\n",
    "class QAgent:\n",
    "    def __init__(self, api_key, base_url, system_prompt=\"你是一个很聪明的智能体。你会用中文回答用户提出的任何问题。\"):\n",
    "        self.api_key = api_key # 自己的 API Key，请前往 DeepSeek 主页获取\n",
    "        self.base_url = base_url # 接口地址，可根据不同平台改变，如 Qwen、DeepSeek\n",
    "        self.system_prompt = system_prompt # 系统提示词，定义智能体角色\n",
    "        self.client = OpenAI(api_key=self.api_key, base_url=self.base_url) # 实例化通信客户端\n",
    "\n",
    "    # 提问接口\n",
    "    def ask(self, question):\n",
    "        # 通过客户端通信，详细说明可查阅 https://api-docs.deepseek.com/\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"deepseek-chat\", # 基座模型，如 “deepseek-chat” 为 DeepSeek-V3；“deepseek-reasoner” 为 DeepSeek-R1\n",
    "            messages=[ # 对话内容\n",
    "                {\"role\": \"system\", \"content\": self.system_prompt},\n",
    "                {\"role\": \"user\", \"content\": question},\n",
    "            ],\n",
    "            stream=False\n",
    "        )\n",
    "        return response.choices[0].message.content # 返回智能体的回答\n",
    "    \n",
    "    # 更新系统提示词\n",
    "    def update_system_prompt(self, system_prompt):\n",
    "        self.system_prompt = system_prompt\n",
    "\n",
    "# 实例化智能体，提供自己的 API Key 和平台相应的接口地址\n",
    "agent = QAgent(\"sk-2ad88b35e31c44a99830ffc9e1c1465b\", \"https://api.deepseek.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "91ad99f99a2d41d3b9f4ea1fc01f35d5",
    "deepnote_app_block_group_id": null,
    "deepnote_app_block_order": 10,
    "deepnote_app_block_visible": true,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "**Step3: 使用智能体**\n",
    "现在，我们可以向它提出任何问题啦。不过大模型的回复可能会比较慢，需要您耐心稍等（大概几十秒）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "d5608587ba5a4d3fa805c1287c18a978",
    "deepnote_app_block_group_id": null,
    "deepnote_app_block_order": 11,
    "deepnote_app_block_visible": true,
    "deepnote_app_is_code_hidden": false,
    "deepnote_app_is_output_hidden": false,
    "deepnote_cell_type": "code",
    "execution_context_id": "9f496b80-6a22-406e-9d54-7c6571a274ed",
    "execution_millis": 34536,
    "execution_start": 1747641883191,
    "source_hash": "1260d435"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大模型智能体（Large Model Agent）是指基于**大规模预训练模型**（如GPT-4、Claude、PaLM等）构建的、具备复杂任务处理能力的智能系统。它不仅能理解和生成自然语言，还能通过工具调用（Tools）、环境交互（如API、数据库）以及多轮推理（Reasoning）完成实际任务，表现出一定程度的自主性和适应性。\n",
      "\n",
      "---\n",
      "\n",
      "### **核心特征**\n",
      "1. **大模型基座**  \n",
      "   依赖千亿级参数的大语言模型（LLM），拥有强大的语言理解、知识存储和逻辑推理能力。\n",
      "\n",
      "2. **任务导向性**  \n",
      "   不同于单纯聊天的AI，智能体被设计为**解决问题**（如数据分析、编程、客服），并能拆解复杂任务为子步骤。\n",
      "\n",
      "3. **工具使用能力**  \n",
      "   可通过调用外部工具（如搜索引擎、计算器、代码执行器）弥补纯文本生成的局限，例如：  \n",
      "   - 查询实时天气 → 调用天气API  \n",
      "   - 解数学题 → 使用计算工具  \n",
      "\n",
      "4. **记忆与状态管理**  \n",
      "   能维护对话历史（短期记忆）或通过外部存储（如向量数据库）实现长期记忆，保证交互连贯性。\n",
      "\n",
      "5. **自主决策**  \n",
      "   根据目标动态选择行动路径（如“先搜索再分析”），甚至能自我反思修正错误（ReAct框架）。\n",
      "\n",
      "---\n",
      "\n",
      "### **典型应用场景**\n",
      "- **自动化助手**  \n",
      "  处理邮件、会议安排、文档摘要等办公任务（如Copilot）。\n",
      "- **垂直领域专家**  \n",
      "  医疗咨询、法律文书生成等专业场景（需结合领域知识库）。\n",
      "- **多模态交互**  \n",
      "  结合视觉、语音模型实现更自然的交互（如机器人导购）。\n",
      "- **模拟社会实验**  \n",
      "  通过多个智能体协作/竞争研究人类行为（斯坦福《小镇》实验）。\n",
      "\n",
      "---\n",
      "\n",
      "### **与传统AI的区别**\n",
      "| 特性          | 传统规则AI         | 大模型智能体               |\n",
      "|---------------|-------------------|---------------------------|\n",
      "| **灵活性**    | 依赖预设规则       | 自适应新任务               |\n",
      "| **可解释性**  | 逻辑透明           | 黑箱性较强                 |\n",
      "| **开发成本**  | 高（需人工设计）   | 低（通过提示词微调即可）    |\n",
      "| **泛化能力**  | 狭窄               | 跨领域能力强               |\n",
      "\n",
      "---\n",
      "\n",
      "### **技术挑战**\n",
      "- **幻觉问题**：可能生成错误但看似合理的答案。\n",
      "- **安全风险**：需防止滥用（如生成恶意代码）。\n",
      "- **长程依赖**：复杂任务中可能遗忘早期信息。\n",
      "\n",
      "当前的研究方向包括**智能体框架**（如AutoGPT、LangChain）、**人类对齐**（RLHF）和**多智能体协作**等。这类系统正逐步从“工具”进化为“数字员工”。\n"
     ]
    }
   ],
   "source": [
    "# 提出疑问并获取回复\n",
    "answer = agent.ask(\"什么是大模型智能体？\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "ffc4a44de7fc4fa19471ef08d1350e98",
    "deepnote_app_block_group_id": null,
    "deepnote_app_block_order": 12,
    "deepnote_app_block_visible": true,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "对于复杂的输出内容，大部分大模型生成 Markdown 格式的输出，为了方便阅读，我们可以利用 markdown 库以更美观的形式将其呈现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "aa7a2e64b3874489bcf25fbb2ac30d8a",
    "deepnote_app_block_group_id": null,
    "deepnote_app_block_order": 13,
    "deepnote_app_block_visible": true,
    "deepnote_app_is_code_hidden": false,
    "deepnote_app_is_output_hidden": false,
    "deepnote_cell_type": "code",
    "execution_context_id": "9f496b80-6a22-406e-9d54-7c6571a274ed",
    "execution_millis": 1562,
    "execution_start": 1747642355837,
    "source_hash": "5cf8dd42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting markdown\n",
      "  Downloading markdown-3.8-py3-none-any.whl.metadata (5.1 kB)\n",
      "Downloading markdown-3.8-py3-none-any.whl (106 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.2/106.2 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: markdown\n",
      "Successfully installed markdown-3.8\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "大模型智能体（Large Model Agent）是指基于**大规模预训练模型**（如GPT-4、Claude、PaLM等）构建的、具备复杂任务处理能力的智能系统。它不仅能理解和生成自然语言，还能通过工具调用（Tools）、环境交互（如API、数据库）以及多轮推理（Reasoning）完成实际任务，表现出一定程度的自主性和适应性。\n",
       "\n",
       "---\n",
       "\n",
       "### **核心特征**\n",
       "1. **大模型基座**  \n",
       "   依赖千亿级参数的大语言模型（LLM），拥有强大的语言理解、知识存储和逻辑推理能力。\n",
       "\n",
       "2. **任务导向性**  \n",
       "   不同于单纯聊天的AI，智能体被设计为**解决问题**（如数据分析、编程、客服），并能拆解复杂任务为子步骤。\n",
       "\n",
       "3. **工具使用能力**  \n",
       "   可通过调用外部工具（如搜索引擎、计算器、代码执行器）弥补纯文本生成的局限，例如：  \n",
       "   - 查询实时天气 → 调用天气API  \n",
       "   - 解数学题 → 使用计算工具  \n",
       "\n",
       "4. **记忆与状态管理**  \n",
       "   能维护对话历史（短期记忆）或通过外部存储（如向量数据库）实现长期记忆，保证交互连贯性。\n",
       "\n",
       "5. **自主决策**  \n",
       "   根据目标动态选择行动路径（如“先搜索再分析”），甚至能自我反思修正错误（ReAct框架）。\n",
       "\n",
       "---\n",
       "\n",
       "### **典型应用场景**\n",
       "- **自动化助手**  \n",
       "  处理邮件、会议安排、文档摘要等办公任务（如Copilot）。\n",
       "- **垂直领域专家**  \n",
       "  医疗咨询、法律文书生成等专业场景（需结合领域知识库）。\n",
       "- **多模态交互**  \n",
       "  结合视觉、语音模型实现更自然的交互（如机器人导购）。\n",
       "- **模拟社会实验**  \n",
       "  通过多个智能体协作/竞争研究人类行为（斯坦福《小镇》实验）。\n",
       "\n",
       "---\n",
       "\n",
       "### **与传统AI的区别**\n",
       "| 特性          | 传统规则AI         | 大模型智能体               |\n",
       "|---------------|-------------------|---------------------------|\n",
       "| **灵活性**    | 依赖预设规则       | 自适应新任务               |\n",
       "| **可解释性**  | 逻辑透明           | 黑箱性较强                 |\n",
       "| **开发成本**  | 高（需人工设计）   | 低（通过提示词微调即可）    |\n",
       "| **泛化能力**  | 狭窄               | 跨领域能力强               |\n",
       "\n",
       "---\n",
       "\n",
       "### **技术挑战**\n",
       "- **幻觉问题**：可能生成错误但看似合理的答案。\n",
       "- **安全风险**：需防止滥用（如生成恶意代码）。\n",
       "- **长程依赖**：复杂任务中可能遗忘早期信息。\n",
       "\n",
       "当前的研究方向包括**智能体框架**（如AutoGPT、LangChain）、**人类对齐**（RLHF）和**多智能体协作**等。这类系统正逐步从“工具”进化为“数字员工”。"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 可选：按照 Markdown 库依赖以更美观地展示结果\n",
    "!pip install markdown\n",
    "from IPython.display import Markdown\n",
    "\n",
    "display(Markdown(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "247ae89c5c054b3097748a64bf515598",
    "deepnote_app_block_group_id": null,
    "deepnote_app_block_order": 14,
    "deepnote_app_block_visible": true,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "**Step4: 体验不同的提问**\n",
    "通过上述步骤，我们已经实现了一个基于 DeepSeek 接口的问答小助手。让我们切换不同的系统提示词或者问题，多体验一会吧。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "d017d1ccfda64c78af6f803ebce1d284",
    "deepnote_app_block_group_id": null,
    "deepnote_app_block_order": 15,
    "deepnote_app_block_visible": true,
    "deepnote_app_is_code_hidden": false,
    "deepnote_app_is_output_hidden": false,
    "deepnote_cell_type": "code",
    "execution_context_id": "9f496b80-6a22-406e-9d54-7c6571a274ed",
    "execution_millis": 27080,
    "execution_start": 1747643305597,
    "source_hash": "b5e30f4"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "作为去过上海十几次的旅行老手，我来给你一份避开人流的深度玩法攻略：\n",
       "\n",
       "【行程建议】\n",
       "Day1：经典必打卡路线\n",
       "- 上午8点前到外滩（避开人流高峰），顺路逛圆明园路老建筑群\n",
       "- 10点坐轮渡到陆家嘴（2块钱的浪漫），登上海中心118层观光厅\n",
       "- 下午武康路-安福路文艺漫步（推荐大隐书局、%Arabica咖啡）\n",
       "- 晚上豫园灯会（建议买晚场票，人少更有意境）\n",
       "\n",
       "Day2：本地人生活体验\n",
       "- 早上6点去城隍庙吃地道早餐（南翔小笼包总店6:30开门）\n",
       "- 上午田子坊后门进（泰康路210弄人最少）\n",
       "- 下午徐汇滨江看展（龙美术馆+西岸艺术中心）\n",
       "- 晚上永康路小酒馆（推荐Bar No.3的特调）\n",
       "\n",
       "Day3：近郊秘境\n",
       "- 朱家角古镇（比七宝人少，尝扎肉和粽子）\n",
       "- 或者广富林文化遗址（水下博物馆很特别）\n",
       "\n",
       "【美食红黑榜】\n",
       "✅必吃：\n",
       "- 老吉士酒家（天平路店）的本帮红烧肉\n",
       "- 光明邨鲜肉月饼（排队15分钟内可买）\n",
       "- 莱莱小笼的蟹粉小笼（下午茶时段人少）\n",
       "- 阿娘面馆的黄鱼面\n",
       "\n",
       "❌避雷：\n",
       "- 南京东路所有小吃店\n",
       "- 外滩人均500+的景观餐厅（味道配不上价格）\n",
       "- 网红蝴蝶酥（国际饭店排队2小时不如城市超市买）\n",
       "\n",
       "【实用Tips】\n",
       "1. 交通：下载\"Metro大都会\"APP坐地铁，国庆期间打车非常难\n",
       "2. 住宿：推荐陕西南路/静安寺地铁站附近，去哪都方便\n",
       "3. 隐藏玩法：苏州河游船（新开通的线路人少景美）\n",
       "4. 10月3-4日相对人少，错峰出行体验更佳\n",
       "\n",
       "需要某个区域的详细攻略，或者想了解特定类型的美食，可以告诉我你的偏好哦~"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent.update_system_prompt(\"你是擅长经验丰富的旅行家，你会用你的经验帮用户制定旅行攻略。\") # 更新系统提示词，改变智能体角色\n",
    "new_answer = agent.ask(\"国庆节我想去上海，请问有什么游玩建议或美食推荐吗？\") # 提出新疑问\n",
    "display(Markdown(new_answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "6439492d0f424125bbc551aefbcc4164",
    "deepnote_app_block_group_id": null,
    "deepnote_app_block_order": 16,
    "deepnote_app_block_visible": true,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## 1.6 小结\n",
    "本章系统性地介绍了智能体技术的核心内容与发展脉络。首先阐述了智能体的基本概念，梳理了从早期规则系统到现代自主学习智能体的演进历程。其次深入解析了智能体与人、环境之间的多模态交互机制，包括感知-决策-执行的闭环框架。在技术融合方面，重点探讨了大语言模型为智能体带来的认知提升和泛化能力突破。最后通过问答智能体的开发实例，直观展示了从理论到实践的完整实现路径，为后续复杂智能体系统的构建奠定了基础。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 课后习题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 习题 1：智能体的核心能力是什么？\n",
    "**参考回答：** 智能体的核心能力包括感知、思考和执行：\n",
    "- 感知：智能体通过传感器收集外部环境的数据，为决策提供依据。例如，获取图像输入，接收语音指令，感知可用的工具集等。\n",
    "- 思考：智能体根据感知的数据进行分析、推理，并制定最优的行动计划。这一环节包括决策和策略的制定。\n",
    "- 执行：智能体将决策转化为实际的动作，并在完成任务后进行反馈。例如，机器人驱动电机移动，智能体生成文本响应。\n",
    "\n",
    "#### 习题 2：请讨论大模型智能体与传统规则智能体的主要区别。\n",
    "**参考回答：** 大模型智能体与传统规则AI的区别体现在以下几个方面：\n",
    "灵活性：大模型智能体具有自适应新任务的能力，能够根据不同的情况做出灵活调整；传统规则AI依赖预设的规则，灵活性较差。\n",
    "可解释性：传统规则AI的逻辑透明，可以清楚地理解决策过程；而大模型智能体往往是黑箱模型，决策过程不易解释。\n",
    "开发成本：传统AI系统需要手动编写大量规则，开发成本较高；而大模型智能体基于预训练模型直接开发或微调，成本较低。\n",
    "以及其余特性可开放回答，言之有理即可。\n",
    "\n",
    "#### 习题 3：请扩展 1.5 小节的代码，实现三种以上不同功能。\n",
    "**参考回答：** 开放题型，能够体现具体效果即可。\n",
    "\n",
    "#### 习题 4：如果条件允许的话，尝试使用不同的基座模型，如 Qwen 系列，观察智能体在前面的任务中的表现变化。\n",
    "**参考回答：** 开放题型，能够体现具体效果即可。\n",
    "\n",
    "#### 扩展习题 5：当前的智能体应用仍然面临不少挑战，这些挑战影响了智能体的准确性、稳定性和安全性。包括幻觉问题、安全风险、长程依赖问题、复杂任务的推理与规划等方面的挑战，请在自行搜索并了解这些挑战后，回答下面的子问题：\n",
    "- 什么是智能体中的“幻觉问题”？请解释该问题如何影响智能体的决策，并举一个实际应用中可能出现幻觉问题的例子。\n",
    "- 在智能体应用中，如何防范安全风险？请列举两种常见的安全风险，并说明智能体如何应对这些风险以避免滥用或错误行为。\n",
    "- 长程依赖问题在多轮任务中如何影响智能体的表现？请举例说明在没有良好记忆管理的情况下，智能体如何丢失重要信息并导致决策错误。\n",
    "- 智能体在执行复杂任务时面临推理与规划的挑战，尤其在长时间、多步骤的任务中。请简述智能体在多步推理和任务拆解中的策略，并说明如何提升其推理能力。\n",
    "  \n",
    "**参考回答：**\n",
    "- **幻觉问题：** 幻觉问题指的是智能体生成的内容看似合理但实际上是错误的。这种问题可能会影响智能体提供的信息质量，导致错误决策。例如，智能体在回答医疗问题时可能会生成一个看似准确的答案，但实际上没有根据真实医学知识，进而影响用户健康决策。\n",
    "- **安全风险：** 常见的安全风险包括：1. 智能体滥用，即智能体可能被恶意使用，如自动化生成恶意代码、传播虚假信息等；2. 错误行为，智能体可能在没有足够数据的情况下做出不当决策，并且这些决策导致的错误后果难以消除。为了应对这些风险，可以引入安全性约束和行为审计机制，实时监控智能体的行为，避免产生不良结果。\n",
    "- **长程依赖问题：** 长程依赖问题指的是智能体在执行复杂任务时，可能会丢失早期的关键信息，导致无法正确推断后续步骤。举个例子，如果智能体在回答多轮对话时没有有效的记忆管理，它可能在后续的问答中忘记之前用户提供的关键信息，导致无法准确完成任务。\n",
    "- **复杂任务的推理与规划：** 智能体在面对复杂任务时需要进行多步推理与规划。这包括将一个大任务拆解为多个子任务，并在执行过程中根据环境反馈调整决策。提升推理能力的策略包括利用强化学习（RL）优化决策过程，结合世界模型增强长期规划能力，并通过动态调整策略应对不确定性。"
   ]
  }
 ],
 "metadata": {
  "deepnote_app_hide_all_code_blocks_enabled": false,
  "deepnote_app_layout": "powerful-article",
  "deepnote_app_reactivity_enabled": true,
  "deepnote_notebook_id": "ab4708376e0c42318ac125c76aa828a7",
  "kernelspec": {
   "display_name": "eva",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
