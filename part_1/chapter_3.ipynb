{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第三章 提示工程\n",
    "<!-- In-context examples、CoT、ReAcT、Reflexion等 -->\n",
    "\n",
    "## 3.1 简介\n",
    "\n",
    "提示工程（Prompt Engineering）是一种人与大语言模型（Large Language Model, LLM）对话的艺术与技术，随着大语言模型技术和应用的发展，提示工程已经成为一门重要的学科，是充分挖掘模型能力的重要基础。通过设计合适的输入，即提示词开发和优化，能够引导模型按照我们预期的方式产生回答或行为，从而完成多种多样的有自然语言参与其中的任务。大语言模型具备出色的自然语言理解能力，它不会读心术，但它非常擅长根据输入的提示推测用户的需求，不同的提示可能导致完全不同的回答，例如：\n",
    "\n",
    "- 例1：\n",
    "    - Prompt: “给我介绍一下猫。”\n",
    "    - 回答：猫是一种小型哺乳动物，喜欢吃鱼，喜欢睡觉…\n",
    "\n",
    "- 例2：\n",
    "    - Prompt: “用幽默的方式介绍猫。”\n",
    "    - 回答：猫？它是一种装作不认识你的家伙，但当你拿出猫粮，它立刻乖乖扑进你的怀里！\n",
    "\n",
    "因此，提示工程就是如何更好的使用大语言模型的“说明书”，展示不同行为的模型输出几乎完全取决于输入提示的设计。掌握如何编写有效提示掌握提示工程的相关技能，将有助于使用者更好地了解大型语言模型的能力和局限性，从而开发更有效的智能体工具！\n",
    "\n",
    "### 3.1.1 提示工程的定义\n",
    "\n",
    "提示工程是指通过设计和优化输入语言提示，引导大型语言模型或智能体系统按照预期目标生成内容、执行操作或完成任务的一门技术，它无需调整模型的权重或参数，而是通过精心设计的提示词来实现对模型行为的控制。与传统编程不同，提示工程的“编程语言”是自然语言，开发者不需要调用复杂的 API 或写严谨的代码逻辑，而是通过措辞、结构和上下文的组织，控制模型的行为路径和输出风格。提示工程的作用在于将大语言模型庞大的知识能力转化为具体、有用、稳定的智能应用能力。大语言模型本身具备丰富的语言理解和生成能力，但缺少主动性、目标感和任务意识。提示工程正是通过语言性指令，为模型设定角色、明确任务、添加约束，从而实现内容创作、代码生成、自动问答、决策辅助、多智能体协作、工具调用等功能，成为当代智能体开发与语言模型应用中的核心手段之一。\n",
    "\n",
    "<!-- 研究人员可利用提示工程来提升大语言模型处理复杂任务场景的能力，如问答和算术推理能力。开发人员可通过提示工程设计、研发强大的工程技术，实现和大语言模型或其他生态工具的高效接轨。用户可以通过提示工程来提高大语言模型的安全性，也可以赋能大语言模型，如借助专业领域知识和外部工具来增强大语言模型的能力。 -->\n",
    "![提示工程概述](./assets/intro.png)\n",
    "\n",
    "随着语言模型规模的不断扩大和应用场景的日益丰富，提示工程也经历了从简单对话指令，到Few-shot示例提示、Chain of Thought推理链提示、上下文学习，再到多智能体协作提示、工具调用提示、动态提示调度（Prompt Orchestration）等复杂形式的演进。从一开始“怎么问模型才能答好”，发展到如今“如何编排、调度、优化多提示链路和工具调用”，提示工程逐渐成为构建智能体系统与高性能语言模型应用不可或缺的关键模块。在这种背景下，涌现出了LangChain、CrewAI、DSPy、OpenAgents等开源框架，围绕提示工程扩展出多提示链管理、工具调用等功能，以支撑复杂任务和多智能体协作。可以说，提示工程是语言模型时代，人与机器智能协作的一座桥梁，也是推动大语言模型从文本生成工具向通用智能体进化的重要驱动力。\n",
    "\n",
    "### 3.1.2 本章重点内容\n",
    "1. 提示工程及其概念介绍，包括提示词的组成、高质量提示词的基本原则；\n",
    "2. 利用提示工程角色扮演；\n",
    "3. 提示工程常用技术，思维链、上下文学习、自我一致、自我反思等；\n",
    "4. 提示工程调优方法；\n",
    "5. 常用的提示词结构以及开源实践推荐。\n",
    "\n",
    "## 3.2 提示工程的组成\n",
    "\n",
    "<!-- 解释什么是提示工程（Prompt Engineering），以及在大模型应用中的重要性。 -->\n",
    "\n",
    "<!-- 提示工程是一种通过设计和优化输入提示，引导生成式人工智能（如大型语言模型，LLM）生成特定输出的技术。它无需调整模型的权重或参数，而是通过精心设计的提示词来实现对模型行为的控制。 -->\n",
    "\n",
    "### 3.2.1 提示词\n",
    "\n",
    "提示词是输入给大语言模型或智能体的一段自然语言，用来描述用户希望模型完成的任务、限制的条件、以及输出的方式，就像人与人对话时，需要不断地互相提供信息才能够使对话合理地继续，与大语言模型对话时我们也需要通过输入提示来明确任务和规则等。在调用各类大模型API时，提示词一般分为系统提示（System Prompt）和用户提示（User Prompt）两部分，\n",
    "- 系统提示：向大语言模型提供的一组初始指令或背景信息，用于指导智能体的行为方式和响应模式，设定其角色、语气和知识范围\n",
    "- 用户提示：是用户输入的问题、请求或命令，旨在获取大语言模型的具体回应或完成特定任务，是触发大语言模型智能体产生回复的直接原因。 \n",
    "\n",
    "下面我们用代码输出来实际展示系统提示和用户提示是如何使用，并在使用模型时发挥各自作用的。首先，我们为后续实例的展示准备一个简单的调用函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "API_KEY = \"sk-2ad88b35e31c44a99830ffc9e1c1465b\"\n",
    "API_BASE_URL = \"https://api.deepseek.com\"\n",
    "\n",
    "def get_response(system_prompt, user_prompt, model=\"deepseek-chat\", temperature=0.0, top_p=1.0, max_tokens=2048):\n",
    "    \n",
    "    client = OpenAI(api_key=API_KEY, base_url = API_BASE_URL) # 实例化通信客户端\n",
    "    response = client.chat.completions.create(\n",
    "        model=model, # 基座模型，如 “deepseek-chat” 为 DeepSeek-V3；“deepseek-reasoner” 为 DeepSeek-R1\n",
    "        messages=[ # 对话内容\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ],\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        max_tokens=max_tokens,\n",
    "        stream=False\n",
    "        )\n",
    "    return response.choices[0].message.content # 返回智能体的回答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们分别看看，通过修改系统提示和用户提示，模型的输出有什么变化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "亲爱的同学，这是个很好的问题呢！让我来为你详细解释一下系统提示和用户提示的区别以及如何合理分配内容：\n",
      "\n",
      "系统提示(System Prompt)适合放入：\n",
      "1. 助手的身份设定和角色定位\n",
      "2. 回答问题的基本原则和风格要求\n",
      "3. 需要长期保持的对话规则\n",
      "4. 不希望被用户轻易覆盖的指令\n",
      "5. 安全性和伦理方面的约束\n",
      "\n",
      "用户提示(User Prompt)适合放入：\n",
      "1. 具体的任务要求和问题内容\n",
      "2. 临时的对话上下文\n",
      "3. 需要即时响应的请求\n",
      "4. 可以随时变化的参数和条件\n",
      "5. 个性化的偏好设置\n",
      "\n",
      "举个🌰：\n",
      "系统提示像是给助教的工作手册，规定了\"要耐心解答问题、用简单易懂的语言\"；而用户提示就像是同学具体问的\"请解释一下神经网络的工作原理\"。\n",
      "\n",
      "小建议是：把固定不变的规则放在系统提示，把具体多变的需求放在用户提示。这样既保持了一致性，又很灵活呢！\n",
      "\n",
      "如果还有不清楚的地方，随时可以继续问我哦~ 😊\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"你是一名助教，需要温柔的回答同学们的问题。\"  # 系统提示\n",
    "user_prompt = \"在做提示工程时，什么内容适合放入系统提示、什么内容适合放入用户提示？\" \n",
    "\n",
    "response = get_response(system_prompt, user_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，deepseek给出的回答确实非常温柔，并且格式清晰。但在实际应用中，我们可能会提取回答中的部分内容做其他处理，现在让我们来修改一下系统提示，让其按照我们需要的格式进行回答，看看会有什么变化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【解释】：\n",
      "在提示工程中，系统提示和用户提示的分工是不同的。系统提示通常用于设定AI助手的角色定位、行为准则和回答风格等基础设定，这些内容相对固定且具有指导性。而用户提示则是针对具体问题的输入内容，具有临时性和针对性。简单来说，系统提示是\"AI是谁\"，用户提示是\"用户要问什么\"。\n",
      "\n",
      "【示例】：\n",
      "比如你想让AI扮演数学老师：\n",
      "- 系统提示：\"你是一位耐心的初中数学老师，擅长用生活化例子解释概念，回答时会先讲解原理再举例说明。\"\n",
      "- 用户提示：\"请讲解二元一次方程组的解法\"\n",
      "\n",
      "再比如客服场景：\n",
      "- 系统提示：\"你是某电商平台的客服助手，回答要专业礼貌，遇到复杂问题要分步骤解答。\"\n",
      "- 用户提示：\"我收到的商品有破损该怎么处理？\"\n",
      "\n",
      "【总结】：\n",
      "系统提示设定AI的\"人设\"和回答框架，用户提示则是具体的询问内容。\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"\n",
    "你是一名助教，需要温柔的回答同学们的问题。\n",
    "你回答问题时必须先对问题进行充分的解释，再通过举例支持和形象化你的解释，最后对问题做出一句话的总结。\n",
    "你的回答必须遵循以下格式：\n",
    "【解释】：\n",
    "【示例】：\n",
    "【总结】：\n",
    "\"\"\"  \n",
    "user_prompt = \"在做提示工程时，什么内容适合放入系统提示、什么内容适合放入用户提示？\" \n",
    "\n",
    "response = get_response(system_prompt, user_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，在系统提示中加入规定格式后，模型可以按照设定的格式回答问题，我们可以方便的通过字符串匹配获得解释或者示例。事实上，在进行单轮问答时，将内容放在系统提示和用户提示并没有太大的区别，但是在多轮问答时，将不变的规则放入系统提示，变化的规则放入用户提示中会方便许多。\n",
    "\n",
    "|属性|System Prompt| User Prompt|\n",
    "|:---:|:---:|:---:|\n",
    "|目标|定义规则和角色|阐述问题或任务|\n",
    "|来源|开发者或应用程序设置|用户直接输入|\n",
    "|作用范围|影响每一次对话|仅影响本次对话|\n",
    "|可见性|通常用户不可见|用户可见且直接编辑|\n",
    "\n",
    "最后，我们通过一张表格总结一下系统提示和用户提示的区别。总而言之，系统提示主要用于设定AI的基本行为准则，而用户|提示则是用户与大语言模型智能体互动的直接方式，最终模型会结合二者作为此次对话的提示词，预测并生成符合要求的文本或操作结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 提示词的组成\n",
    "\n",
    "提示词的组成可以从内容和结构两个角度来说明。\n",
    "\n",
    "从内容上划分，一个标准的提示词应该包含背景设定、任务说明、限制和约束、示例（可选）四部分。在有些复杂场景下，还可以加入多轮上下文、经验或历史、工具调用接口说明等特定内容。\n",
    "- 背景设定：说明当前任务、智能体身份或上下文环境。\n",
    "- 任务说明：明确告诉模型你要它完成什么任务。\n",
    "- 限制和约束：规定输出格式、风格或字数，避免答非所问。\n",
    "- 示例（可选）：给出参考案例，帮助模型模仿示例回答方式。\n",
    "\n",
    "从结构上划分，一个完整的提示工程可以分为任务描述，上下文，示例（可选），输入，输出格式五部分。\n",
    "\n",
    "- 任务描述：给模型下达了一个命令或请求。用于告诉模型应该做什么，是任务执行的基础。\n",
    "- 上下文：描述与任务相关的背景信息，它有助于模型更好地理解当前任务所处的环境或情境。在多轮交互中，上下文尤其重要，因为它提供了对话的连贯性和历史信息。\n",
    "- 示例：示范学习，给出的一或多个具体示例，用于演示任务的执行方式或所需输出的格式。这种方法在机器学习中被称为示范学习，已被证明对提高输出正确性有帮助。\n",
    "- 输入：任务的具体数据或信息，它是模型需要处理的内容。在Prompt中，输入应该被清晰地标识出来，以便模型能够准确地识别和处理。\n",
    "- 输出：输出是模型根据输入和指示生成的结果。在Prompt中，通常会描述输出的格式，以便后续模块能够自动解析模型的输出结果。常见的输出格式包括结构化数据格式如JSON、XML等，结构化的输出便于有效的提取回答中的关键信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 高质量提示的基本原则\n",
    "\n",
    "在提示工程中，提示词的质量直接决定了语言模型响应的相关性、准确性和稳定性。大语言模型本身没有主观判断能力，它依赖于我们提供的提示词来理解任务意图、确定回应方式以及选择输出内容。一个高质量的提示，能够有效降低模型的理解歧义，提升输出的一致性和可控性，避免答非所问、格式错乱或风格偏差的问题。为了实现这一目标，提示设计需要遵循一套严谨而实用的基本原则，确保提示在表达意图、限定条件、引导模型思路等方面具备清晰性、规范性和可操作性。在设计高质量提示词时，通常需要遵循明确、具体、避免歧义的基本准则，并且好的提示往往采用指令式语言，明确告知模型该做什么、怎么做、做到什么程度，同时在必要场景下补充上下文背景、角色设定或示例案例，帮助模型准确理解任务边界和输出预期。接下来，我们将逐条介绍高质量提示词应遵循的几项核心原则。\n",
    "\n",
    "- 清晰（Clarity）：清晰性是提示设计中最基础、也是最重要的原则。由于大语言模型本身依赖提示词来推测任务意图，它对语言中的模糊表达和省略信息非常敏感，因此提示的措辞必须清晰直接，尽可能排除多种解读的空间，如明确告知模型你希望它做什么、以什么方式完成、输出什么内容。比如简单说“介绍一下人工智能”，模型可能给出泛泛而谈的解释，甚至讲历史渊源或技术分类，而如果你改写为“用简洁正式语言，介绍人工智能的定义、特点和应用场景”，模型就能围绕指定内容组织答案，避免跑题。设计提示时，应避免使用“可以”“适当”“随便”这类模糊措辞，优先采用直接、具体的指令句式。\n",
    "    - 较差：“介绍一下人工智能。”\n",
    "    - 更优：“用简洁正式语言，介绍人工智能的定义、特点和应用场景。”\n",
    "\n",
    "- 具体（Specificity）：具体性原则强调，提示词不仅要说明“做什么”，还要写清楚做成什么效果。大语言模型如果缺少细节限制，往往会过度自由发挥，导致输出内容结构不稳定、风格不统一，影响实用性。为了让模型输出更加规范，提示中应明确约定输出格式、风格、长度、数量、内容范围等细节。具体化约束可以显著提升模型响应的一致性和可控性，尤其适用于需要格式化结果、表格输出、多项列举或情感倾向控制等任务。\n",
    "    - “请用‘概念：内容’的格式，列出3个人工智能常见应用。”\n",
    "\n",
    "- 上下文适配（Contextuality）：上下文适配是提示工程中提升模型理解深度和表达准确度的重要方法。大语言模型的输出与当前提示中提供的上下文信息息息相关，不同的背景设定会显著影响模型的语言风格、内容重点和回应方式。通过在提示中加入背景信息或角色设定，可以有效调整模型的语气、专业度和思考方式。例如，在智能助手场景中，可以设定“假设你是产品经理，现在向团队介绍GPT-4的商业应用价值”，这样模型就会自动调整措辞风格，聚焦商业价值，而非单纯介绍技术原理。上下文适配尤其适用于多智能体协作、角色扮演、决策推理等对场景和身份敏感的任务。\n",
    "    - “假设你是产品经理，现在向团队介绍GPT-4的商业应用价值。”\n",
    "\n",
    "- 可验证性（Verifiability）：可验证性原则要求提示设计者在提示词中设定清晰、具体、易判断的结果标准，便于用户或程序自动判断模型输出是否符合预期。这一原则的作用在于，减少模型自由发挥空间，避免出现主观性强、标准模糊的输出结果。例如，可以在提示中要求“输出字数不超过100”“必须包含‘人工智能’这个词”“结尾用一句话总结全文”等，通过这些可验证的条件，让任务目标更具客观性。良好的可验证性不仅提升交互效率，也方便后续自动化处理，适合知识问答、摘要生成、报告撰写等结果标准化需求强的任务场景。\n",
    "\n",
    "- 适度冗余（Redundancy for Control）：适度冗余是一种防止模型遗漏关键信息的提示策略。由于大语言模型对复杂任务的响应存在遗漏或忽略细节的可能，特别是在多项条件叠加、长提示链或多轮交互中，适度重复强调重要约束条件可以降低模型遗漏限制条件的概率，有效提高输出的稳定性和可靠性。适度冗余不等于啰嗦，而是有策略、有重点地强化对重要约束的提醒，尤其适用于高风险场景、长文本对话、多条件输出和结构化文本生成等任务。\n",
    "\n",
    "我们以第一个原则为例，展示清晰指令和含糊指令对于模型输出的影响。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "含糊指令回答：\n",
      " 作为营养师，我建议通过科学饮食结合运动来健康减重。以下是具体建议：\n",
      "\n",
      "1. 饮食结构调整\n",
      "- 采用\"211餐盘法则\"：每餐2份蔬菜+1份优质蛋白+1份粗粮\n",
      "- 推荐食材：\n",
      "  √ 蛋白质：鸡胸肉、鱼类、虾、豆腐\n",
      "  √ 碳水：燕麦、糙米、红薯、藜麦\n",
      "  √ 脂肪：坚果、牛油果、橄榄油\n",
      "\n",
      "2. 关键饮食原则\n",
      "- 每天喝够2000ml水（约8杯）\n",
      "- 控制精制糖摄入，戒含糖饮料\n",
      "- 烹饪方式以蒸、煮、炖为主\n",
      "- 晚餐在19点前完成，控制碳水\n",
      "\n",
      "3. 推荐一日食谱示例：\n",
      "早餐：水煮蛋2个+燕麦粥+凉拌菠菜\n",
      "午餐：杂粮饭+清蒸鱼+西兰花\n",
      "晚餐：鸡胸肉沙拉+菌菇汤\n",
      "加餐：无糖酸奶/一小把坚果\n",
      "\n",
      "4. 注意事项：\n",
      "- 每周减重不超过1kg\n",
      "- 配合每周3-5次有氧运动\n",
      "- 保证7-8小时睡眠\n",
      "- 记录饮食日记\n",
      "\n",
      "建议每周安排1次\"开放餐\"满足口欲，但注意控制量。如需个性化方案，建议咨询专业营养师进行体脂分析和代谢评估。\n",
      "\n",
      "记住：减肥是养成健康生活习惯的过程，不要追求快速瘦身。如有任何不适请及时调整。\n",
      "\n",
      "\n",
      "清晰指令回答：\n",
      " 好的！根据您的目标，我为您制定了一个均衡且可持续的1500卡路里饮食计划。这个计划注重蛋白质摄入、膳食纤维和健康脂肪，同时控制精制碳水和添加糖。\n",
      "\n",
      "【早餐（约400卡）】\n",
      "1. 水煮蛋2个（140卡）\n",
      "2. 全麦面包1片（80卡）+ 1/4牛油果（60卡）\n",
      "3. 无糖希腊酸奶150g（90卡）+ 蓝莓50g（30卡）\n",
      "4. 黑咖啡/绿茶（0卡）\n",
      "\n",
      "【午餐（约500卡）】\n",
      "1. 杂粮饭100g（120卡）\n",
      "2. 清蒸鱼/鸡胸肉150g（180卡）\n",
      "3. 水煮西兰花200g（60卡）+ 橄榄油5g（45卡）\n",
      "4. 凉拌黄瓜番茄沙拉（50卡）\n",
      "5. 海带豆腐汤1碗（45卡）\n",
      "\n",
      "【晚餐（约450卡）】\n",
      "1. 红薯150g（130卡）\n",
      "2. 瘦牛肉100g（150卡）清炒\n",
      "3. 蒜蓉菠菜200g（50卡）+ 亚麻籽油5g（45卡）\n",
      "4. 紫菜蛋花汤1碗（75卡）\n",
      "\n",
      "【加餐（150卡以内，可选）】\n",
      "- 原味杏仁15颗（100卡）\n",
      "- 苹果1小个（80卡）\n",
      "- 无糖豆浆200ml（50卡）\n",
      "\n",
      "【执行建议】\n",
      "1. 每天喝够2000ml水\n",
      "2. 每周可安排1次\"灵活餐\"（不超过800卡）\n",
      "3. 配合每周3-5次运动（建议有氧+力量结合）\n",
      "4. 每2周调整一次食谱以防平台期\n",
      "\n",
      "【注意事项】\n",
      "1. 严格控油，每日食用油不超过20g\n",
      "2. 避免含糖饮料和精加工食品\n",
      "3. 晚餐在19点前完成\n",
      "4. 保证7-8小时睡眠\n",
      "\n",
      "这个计划平均每天约1450卡，蛋白质约90g，能保证基础代谢的同时健康减重。建议每周称重一次，如果2周后体重下降超过2kg，可适当增加100-200卡摄入。需要我根据您的具体口味或饮食禁忌调整吗？\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"你是一个营养师，擅长为人们制定健康饮食计划。\"\n",
    "# 含糊指令\n",
    "user_prompt_blur = \"怎样吃才能减肥？\"\n",
    "# 清晰指令\n",
    "user_prompt_clear = \"我想减肥，目标是半年内从120斤减到100斤，请为我制定一个包含早餐、午餐和晚餐的健康饮食计划，确保每天摄入的热量不超过1500卡路里。\"\n",
    "\n",
    "answer_blur = get_response(system_prompt, user_prompt_blur)\n",
    "print(\"含糊指令回答：\\n\", answer_blur)\n",
    "\n",
    "answer_clear = get_response(system_prompt, user_prompt_clear)\n",
    "print(\"\\n\\n清晰指令回答：\\n\", answer_clear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们使用的deepseek模型能力本身比较强，但是在指令含糊时，模型回答内容松散，缺乏针对性，而当我们使用清晰的指令阐述需求时，模型便可以根据用户需要做出相应的回答。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 角色扮演\n",
    "\n",
    "角色扮演是提示工程中非常重要且实用的技巧之一。想象你有一个问题，想咨询专家来解决这些疑问，例如，你在找工作的时候，可以让大模型扮演面试官，提前练习面试技巧；在买车的时候，让大模型扮演一个具有多年经验的汽车销售，让他根据你的需求推荐合适的汽车。角色扮演通过在提示词中明确指定模型“扮演”的身份、角色或职业，来影响模型的语言风格、思考角度和行为模式，从而提高生成内容的准确性和贴合度。由于大语言模型本质上是基于上下文进行预测的概率机器，其对“我是谁”这个信息非常敏感。通过明确告诉模型的角色“现在是一名医生”、“现在是法律顾问”或“现在是一位诗人”等，可以引导模型用符合该角色知识体系和表达习惯的方式来生成回答。一般而言，添加角色扮演能够提升模型的能力。举例说明："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "无角色扮演：\n",
      " 治疗感冒的常见方法包括：  \n",
      "1. **休息**：保证充足睡眠，帮助免疫系统恢复。  \n",
      "2. **多喝水**：保持水分，缓解喉咙干燥和鼻塞。  \n",
      "3. **对症药物**：  \n",
      "   - 退烧止痛（如对乙酰氨基酚、布洛芬）。  \n",
      "   - 鼻塞用减充血剂（如伪麻黄碱）。  \n",
      "   - 咳嗽可用止咳药或蜂蜜（1岁以上）。  \n",
      "4. **保持湿润**：使用加湿器或盐水喷鼻缓解鼻塞。  \n",
      "5. **避免传染**：戴口罩、勤洗手。  \n",
      "\n",
      "**注意**：感冒由病毒引起，抗生素无效。若症状严重或持续超10天，需就医。\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"请简要回答如何治疗感冒\"\n",
    "direct_answer = get_response(\"\", user_prompt)\n",
    "print(\"无角色扮演：\\n\\n\", direct_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "有角色扮演：\n",
      "\n",
      " 作为医生，我建议感冒治疗以缓解症状为主：\n",
      "\n",
      "1. 休息：保证充足睡眠\n",
      "2. 补水：每日饮水1.5-2L\n",
      "3. 药物：\n",
      "   - 发热/头痛：对乙酰氨基酚\n",
      "   - 鼻塞：生理盐水冲洗\n",
      "   - 咳嗽：蜂蜜（1岁以上）或右美沙芬\n",
      "4. 保持室内湿度40-60%\n",
      "5. 病程一般7-10天自愈\n",
      "\n",
      "若出现以下情况请及时就医：\n",
      "- 高热＞3天\n",
      "- 呼吸困难\n",
      "- 症状持续＞10天\n",
      "\n",
      "需要具体用药指导或其他症状咨询吗？\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"你是一位经验丰富的医生，擅长治疗各种常见疾病，尤其是感冒。你会非常专业、耐心地回答患者的问题，有效安抚患者情绪，并提供详细的治疗建议。\"\n",
    "response = get_response(system_prompt, user_prompt)\n",
    "print(\"有角色扮演：\\n\\n\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总结而言，通过在提示中设定模型角色，能够增强回复专业性，模型会调动该角色相关的内容和表达习惯，输出更专业的内容，让模型聚焦于角色职责，减少跑题和无关回答。通过设定性格，可以统一回答语气和风格，能够丰富互动体验，提供更自然、有代入感的交互。由此可见，角色扮演特别适合需要专业知识或特定表达风格的场景。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 提示工程技术\n",
    "\n",
    "从这一小节开始，我们展开提示工程的技术篇，介绍目前最为常见的几种提示工程技术，如思维链、上下文学习（包含零样本提示、少样本提示）、推理提示、反思提示等。检索增强生成也属于提示工程中的一种技术，但其具有更广阔的应用范围和更复杂广泛的技术路径，我们会在后面单独用一个章节来进行阐述。\n",
    "\n",
    "### 3.4.1 思维链\n",
    "\n",
    "思维链 Chain of Thought（CoT），即通过引导模型进行深度思考后再回答，有效提高回复的创新型和准确性。该方法强调模型逐步推理，通过构建一系列有序、相互关联的思考步骤，模型能够更深入地理解问题，并生成结构化、逻辑清晰的回答。最常见的链式思考提示词形如“让我们一步一步思考”，“Let us think step by step.”，这样的提示词能够直接促使模型显式分步推理，从而提高复杂问题的解答准确性。我们也可以使用其他类似的提示词，只要能够表达“链式思考”的含义。下面的示例清晰地说明了思维链技术的有效性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "白球来自甲盒的概率为 \\(\\frac{3}{13}\\)。\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"直接给出问题的答案，禁止任何分析和思考。\"\n",
    "question = \"有甲、乙、丙三个盒子，甲盒中有一个白球和两个黑球，乙盒中有两个白球和一个黑球，丙盒中有三个白球和三个黑球，掷一枚骰子决定盒子。若出现的点数为1，2，3，选择甲盒，若出现的点数为4，选择乙盒，若出现的点数为5，6，选择丙盒。再从选中的盒子中任意选取一球。求：当取出的球为白球时，此球来自甲盒的概率？\"\n",
    "response = get_response(system_prompt, question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 问题重述\n",
      "\n",
      "我们有三个盒子：甲、乙、丙。每个盒子中球的分布如下：\n",
      "\n",
      "- **甲盒**：1个白球，2个黑球\n",
      "- **乙盒**：2个白球，1个黑球\n",
      "- **丙盒**：3个白球，3个黑球\n",
      "\n",
      "首先掷一枚骰子来决定选择哪个盒子：\n",
      "\n",
      "- 骰子点数为1, 2, 3：选择**甲盒**\n",
      "- 骰子点数为4：选择**乙盒**\n",
      "- 骰子点数为5, 6：选择**丙盒**\n",
      "\n",
      "然后，从选中的盒子中随机抽取一个球。已知取出的球是白球，求这个白球来自甲盒的概率。\n",
      "\n",
      "### 解决思路\n",
      "\n",
      "这是一个典型的**条件概率**问题，可以使用**贝叶斯定理**来解决。我们需要计算在已知取出的球是白球的条件下，这个白球来自甲盒的概率。\n",
      "\n",
      "定义以下事件：\n",
      "\n",
      "- \\( A \\)：选择甲盒\n",
      "- \\( B \\)：选择乙盒\n",
      "- \\( C \\)：选择丙盒\n",
      "- \\( W \\)：取出的球是白球\n",
      "\n",
      "我们需要求的是 \\( P(A | W) \\)，即在取出白球的条件下，选择的是甲盒的概率。\n",
      "\n",
      "根据贝叶斯定理：\n",
      "\n",
      "\\[\n",
      "P(A | W) = \\frac{P(W | A) \\cdot P(A)}{P(W)}\n",
      "\\]\n",
      "\n",
      "其中：\n",
      "\n",
      "- \\( P(W | A) \\)：在甲盒中取出白球的概率\n",
      "- \\( P(A) \\)：选择甲盒的概率\n",
      "- \\( P(W) \\)：在任何盒子中取出白球的总概率\n",
      "\n",
      "### 计算各项概率\n",
      "\n",
      "1. **选择盒子的概率**：\n",
      "\n",
      "   - 骰子有6个面，每个面出现的概率相同。\n",
      "   - 选择甲盒的点数为1, 2, 3，共3个情况：\n",
      "     \\[\n",
      "     P(A) = \\frac{3}{6} = \\frac{1}{2}\n",
      "     \\]\n",
      "   - 选择乙盒的点数为4，共1个情况：\n",
      "     \\[\n",
      "     P(B) = \\frac{1}{6}\n",
      "     \\]\n",
      "   - 选择丙盒的点数为5, 6，共2个情况：\n",
      "     \\[\n",
      "     P(C) = \\frac{2}{6} = \\frac{1}{3}\n",
      "     \\]\n",
      "\n",
      "2. **在各自盒子中取出白球的概率**：\n",
      "\n",
      "   - 甲盒：1白，2黑，共3球\n",
      "     \\[\n",
      "     P(W | A) = \\frac{1}{3}\n",
      "     \\]\n",
      "   - 乙盒：2白，1黑，共3球\n",
      "     \\[\n",
      "     P(W | B) = \\frac{2}{3}\n",
      "     \\]\n",
      "   - 丙盒：3白，3黑，共6球\n",
      "     \\[\n",
      "     P(W | C) = \\frac{3}{6} = \\frac{1}{2}\n",
      "     \\]\n",
      "\n",
      "3. **总的白球概率 \\( P(W) \\)**：\n",
      "\n",
      "   根据全概率公式：\n",
      "\n",
      "   \\[\n",
      "   P(W) = P(W | A) \\cdot P(A) + P(W | B) \\cdot P(B) + P(W | C) \\cdot P(C)\n",
      "   \\]\n",
      "\n",
      "   代入数值：\n",
      "\n",
      "   \\[\n",
      "   P(W) = \\left(\\frac{1}{3} \\times \\frac{1}{2}\\right) + \\left(\\frac{2}{3} \\times \\frac{1}{6}\\right) + \\left(\\frac{1}{2} \\times \\frac{1}{3}\\right)\n",
      "   \\]\n",
      "   \\[\n",
      "   P(W) = \\frac{1}{6} + \\frac{2}{18} + \\frac{1}{6}\n",
      "   \\]\n",
      "   \\[\n",
      "   P(W) = \\frac{1}{6} + \\frac{1}{9} + \\frac{1}{6}\n",
      "   \\]\n",
      "\n",
      "   通分（最小公倍数为18）：\n",
      "\n",
      "   \\[\n",
      "   \\frac{1}{6} = \\frac{3}{18}, \\quad \\frac{1}{9} = \\frac{2}{18}, \\quad \\frac{1}{6} = \\frac{3}{18}\n",
      "   \\]\n",
      "   \\[\n",
      "   P(W) = \\frac{3}{18} + \\frac{2}{18} + \\frac{3}{18} = \\frac{8}{18} = \\frac{4}{9}\n",
      "   \\]\n",
      "\n",
      "4. **计算 \\( P(A | W) \\)**：\n",
      "\n",
      "   现在我们有：\n",
      "\n",
      "   \\[\n",
      "   P(A | W) = \\frac{P(W | A) \\cdot P(A)}{P(W)} = \\frac{\\frac{1}{3} \\times \\frac{1}{2}}{\\frac{4}{9}} = \\frac{\\frac{1}{6}}{\\frac{4}{9}} = \\frac{1}{6} \\times \\frac{9}{4} = \\frac{9}{24} = \\frac{3}{8}\n",
      "   \\]\n",
      "\n",
      "### 验证\n",
      "\n",
      "为了确保我们的答案正确，让我们验证一下各个部分：\n",
      "\n",
      "- 选择甲盒并取出白球的联合概率：\n",
      "  \\[\n",
      "  P(A \\cap W) = P(W | A) \\cdot P(A) = \\frac{1}{3} \\times \\frac{1}{2} = \\frac{1}{6}\n",
      "  \\]\n",
      "  \n",
      "- 选择乙盒并取出白球的联合概率：\n",
      "  \\[\n",
      "  P(B \\cap W) = \\frac{2}{3} \\times \\frac{1}{6} = \\frac{2}{18} = \\frac{1}{9}\n",
      "  \\]\n",
      "  \n",
      "- 选择丙盒并取出白球的联合概率：\n",
      "  \\[\n",
      "  P(C \\cap W) = \\frac{1}{2} \\times \\frac{1}{3} = \\frac{1}{6}\n",
      "  \\]\n",
      "  \n",
      "- 总的白球概率：\n",
      "  \\[\n",
      "  P(W) = \\frac{1}{6} + \\frac{1}{9} + \\frac{1}{6} = \\frac{3}{18} + \\frac{2}{18} + \\frac{3}{18} = \\frac{8}{18} = \\frac{4}{9}\n",
      "  \\]\n",
      "  \n",
      "- 因此：\n",
      "  \\[\n",
      "  P(A | W) = \\frac{P(A \\cap W)}{P(W)} = \\frac{\\frac{1}{6}}{\\frac{4}{9}} = \\frac{3}{8}\n",
      "  \\]\n",
      "\n",
      "### 结论\n",
      "\n",
      "当取出的球为白球时，此球来自甲盒的概率为：\n",
      "\n",
      "\\[\n",
      "\\boxed{\\dfrac{3}{8}}\n",
      "\\]\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"逐步思考并给出问题答案\"\n",
    "question = \"有甲、乙、丙三个盒子，甲盒中有一个白球和两个黑球，乙盒中有两个白球和一个黑球，丙盒中有三个白球和三个黑球，掷一枚骰子决定盒子。若出现的点数为1，2，3，选择甲盒，若出现的点数为4，选择乙盒，若出现的点数为5，6，选择丙盒。再从选中的盒子中任意选取一球。求：当取出的球为白球时，此球来自甲盒的概率？\"\n",
    "response = get_response(system_prompt, question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用思维链后，模型给出了正确的答案。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2 上下文学习\n",
    "\n",
    "上下文学习 In-Context-Learning（ICL），是通过在输入中添加适当的示例文本以针对性的提高模型能力。由于大语言模型本质是根据上下文语义空间的概率预测得到输出文本，所以在上下文中添加适当的信息如类似的问题和回答示例，能够有效提高模型回复的质量和准确程度。上下文学习可以分为零样本提示（Zero-Shot），单样本提示（One-Shot），少样本提示（Few-Shot）等，顾名思义，即在输入的提示词中分别不加、只加一个、加几个示例。上下文学习技术可以与CoT结合，往往能取得更好的效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "情感：正面\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "将文本分类为正面、中性、或负面情感。请根据以下示例进行分类：\n",
    "文本：我今天过得很开心！\n",
    "情感：正面\n",
    "文本：这部电影真是太糟糕了。\n",
    "情感：负面\n",
    "文本：我人为这个餐厅的食物还可以。\n",
    "情感：中性\n",
    "\n",
    "对以下文本进行分类：\n",
    "文本：这个地方风景优美，鸟语花香，气候宜人。\n",
    "情感：\n",
    "\"\"\"\n",
    "response = get_response(\"\", prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.3 自我一致\n",
    "自我一致性（Self-Consistency）通过多次生成取众数的方法提高回复的质量，旨在“替换链式思维提示中使用的天真贪婪解码方法”，通过少样本CoT采样多个不同的推理路径，并使用生成结果选择最一致的答案，以提高CoT方法在设计算数和常识推理任务中的性能。\n",
    "\n",
    "![自我一致方法示意图](./assets/self-consist.png)\n",
    "\n",
    "### 3.4.4 推理提示\n",
    "推理提示顾名思义，就是让模型在回答问题时进行推理，它与思维链相似却有所不同，思维链强调逐步思考的方法，而推理侧重富有逻辑地深度思考某一个问题。将推理和任务执行交替进行，就得到了ReAcT方法。该方法支持智能体通过与环境接触不断更新自己的知识，具体而言分为三个步骤：思考，行动，观察。\n",
    "- 思考：对问题以及已有的观察和操作进行自由形式的思考，如分解问题、提取信息、算术推理等。\n",
    "- 行动：提取思考结果中必要执行的行动，如引导搜索、合成最终答案等。\n",
    "- 观察：一般是行动后得到的结果或者环境的变化。\n",
    "\n",
    "如下是ReAct原文中的一个示例：\n",
    "```python\n",
    "问题 科罗拉多造山带东部区域延伸到的区域的海拔范围是多少？\n",
    "思考 1 我需要搜索科罗拉多造山带，找到科罗拉多造山带东段延伸的区域，然后找到该区域的海拔范围。\n",
    "操作 1 搜索 [科罗拉多造山带]\n",
    "观察 1 科罗拉多造山带是科罗拉多及其周边地区造山运动的一段。\n",
    "思考 2 它没有提到东部地区。所以我需要查一下东部地区。\n",
    "操作 2 查找 [东部地区]\n",
    "观察 2 (结果 1 / 1) 东部区域延伸至高平原，称为中原造山带。\n",
    "思考 3 科罗拉多造山运动的东部区域延伸到高平原。所以我需要搜索高平原，找到它的海拔范围。\n",
    "操作 3 搜索 [高平原]\n",
    "观察 3 高平原指的是两个截然不同的陆地区域之一。\n",
    "思考 4 我需要搜索高平原（美国）\n",
    "操作 4 搜索 [高平原（美国）]\n",
    "观察 4 高平原是大平原的一个分区。从东到西，高平原的海拔从 1800 到 7000 英尺 (550 到 2130 米) 不等。[3]\n",
    "思考 5 高平原海拔高度从 1800 到 7000 英尺，所以答案是 1800 到 7000 英尺。\n",
    "操作 5 结束 [1800 到 7000 英尺]\n",
    "...\n",
    "```\n",
    "\n",
    "### 3.4.5 反思提示\n",
    "反思提示主要指自我反思Self-Reflexion，通过语言反馈强化基于语言的智能体。自我反思将来自环境的反馈（自由形式的语言或者标量）转换为语言反馈，作为下一轮大语言模型智能体的上下文，帮助智能体有效的从之前的错误中学习，进而提升处理当前问题的能力。自我反思由三个不同的模型组成。实际使用中，每个模型可以通过使用不同的提示工程技术实现。\n",
    "- 执行者（Actor）：根据状态和观测结果生成文本和动作，在环境中采取动作并接收观察结果，从而形成轨迹。记忆组件用于提供额外的上下文信息，例如曾经的错误。\n",
    "- 评估者（Evaluator）：对执行者的输出进行评估，对执行者产生的轨迹进行奖励打分，具体的奖励函数跟随任务而设置。\n",
    "- 自我反思（Self-Reflexion）：生成语言性的强化指导帮助执行者完成自我完善，简单而言，就是根据轨迹和奖励分数对智能体过去的动作提供反馈和建议，并将反馈和建议存储在记忆组件中供执行者使用。\n",
    "\n",
    "![反思提示示意图](./assets/self-refine.png)\n",
    "\n",
    "当智能体执行的任务需要从尝试和错误中学习时，使用反思提示往往会取得较好的效果。但是该方法也存在一些限制，如依赖自我评估和反思模型的能力、长期记忆组件限制等。当然，提示工程技术还有很多，篇幅限制我们难以一一介绍，具体使用哪种提示工程技术要根据实际情况而定。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 提示工程实用方法\n",
    "<!-- 如何提示工程 -->\n",
    "### 3.5.1 提示工程调优方法\n",
    "\n",
    "提示工程调优（Prompt Refinement）指的是在实际应用中，开发者通过反复试验和迭代优化提示词的措辞、结构与约束条件，逐步提升语言模型输出质量和稳定性的过程。与传统程序调试不同，提示调优是一种人与机器协同完成的语言交互优化过程。它不仅依赖清晰准确的需求表达，也要求理解模型的语言特性和推理方式，从而通过语言策略调整，获得最理想的交互效果。\n",
    "\n",
    "在提示调优的过程中，开发者通常需要从三个视角来审视和优化提示设计。首先是**人的视角**，即确保自己清晰、具体地传达任务需求，避免含糊不清的表达导致模型误判意图，复杂任务应简化拆解，转化为模型易于理解的指令化表达。其次是**机器的视角**，要认识到语言模型缺乏人类的常识性直觉和场景感知能力，必须在提示中详细提供必要的信息、背景和上下文，精确选择措辞和结构，避免歧义和模型自由发挥。最后是**模型的视角**，不同的大语言模型、不同场景下的交互需求，往往需要调整提示的表达方式与技巧，通过实践不断试验词汇、结构、推理链等语言技巧，寻找最契合当前模型特性的表达方法，是提示调优不可或缺的一环。\n",
    "<!-- \n",
    "一、人的视角：明确需求\n",
    "- 核心点：确保清晰、具体地传达自己的意图。\n",
    "- 策略：简化复杂需求，分解为模型易理解的指令。\n",
    "\n",
    "二、机器的视角：注重细节\n",
    "- 核心点：机器缺乏人类直觉，需详细提供信息和上下文。\n",
    "- 策略：精确选择词汇和结构，避免歧义，提供完整线索。\n",
    "\n",
    "三、模型的视角：灵活应用技巧\n",
    "- 核心点：不同模型、情境需不同Prompt表达方式。\n",
    "- 策略：通过实践找到最佳词汇、结构和技巧，适应模型特性。 -->\n",
    "\n",
    "\n",
    "优化Prompt通常涉及多种操作，包括调整词汇选择、改变句子结构、添加上下文信息、规范输出格式等，目的在于帮助AI模型更准确理解用户意图，生成符合预期且结构规范的输出，从而提升交互性能和输出质量。为了指导调优实践，以下列出几种常用的方法，供开发者参考。\n",
    "\n",
    "**调优常用方法：**\n",
    "1. 观察输出偏差：分析模型输出与预期目标之间的差距，判断内容是否跑题、格式是否混乱、逻辑是否薄弱，确定调整方向。\n",
    "\n",
    "2. 调整提示措辞：改写指令，使其更具体、清晰，减少模型理解歧义。\n",
    "\n",
    "3. 添加约束条件：控制输出内容，如限制字数、设定格式要求、指定语言风格、约定输出结构。\n",
    "\n",
    "4. 分步提示化：若发现模型逻辑推理性不足，可以尝试分步提示化（CoT），将模型自主将复杂任务拆解为简单的步骤，或人为构建思考步骤，提升模型的推理清晰度。\n",
    "\n",
    "5. 加入示例：加入带有思维链的示例也能够增强模型推理能力，另外，当输出风格或者格式不稳定时，可通过上下文内嵌1-2个示例，引导模型模仿示例风格。\n",
    "\n",
    "6. 角色设定优化：明确告诉模型“你现在是某某角色”，能有效降低偏题率，增强输出的角色适配性。\n",
    "\n",
    "<!-- 首先，观察输出偏差是调优的起点。通过分析模型输出与预期目标之间的差距，判断内容是否跑题、格式是否混乱、逻辑是否薄弱，从而确定调整方向。\n",
    "接下来，可以通过调整提示措辞，改写指令语言，使其更具体、清晰，减少模型理解歧义。\n",
    "第三，添加约束条件是控制输出内容的重要手段，包括限制字数、设定格式要求、指定语言风格，或约定输出结构。\n",
    "若发现模型逻辑推理性不足，可以尝试分步提示化（Chain of Thought），将复杂任务拆解为简单的步骤，或人为构建思考链，提升模型的推理清晰度。\n",
    "此外，**加入示例（Few-shot）**也是常用技巧，尤其在输出风格、格式不稳定时，通过上下文内嵌1-2个示例，引导模型模仿示例风格。\n",
    "最后，角色设定优化也是提升输出质量的重要策略，明确告诉模型“你现在是某某角色”，能有效降低偏题率，增强输出的角色适配性。 -->\n",
    "\n",
    "需要强调的是，尽管提示设计方法已有大量理论总结，但优秀的Prompt绝非一蹴而就，而是通过迭代试验不断调优出来的。提示工程本质上是一项以实验为核心的实践性工作。为了直观展现调优过程，接下来我们以电影推荐为例，演示如何从一个初版提示出发，通过反复试验，不断根据模型输出调整措辞与结构，最终收敛到输出稳定、符合预期格式和内容标准的理想结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "解释: \n",
      "1. 用户最近的观影记录显示其偏好多样，包括经典剧情片（《肖申克的救赎》《阿甘正传》）、悬疑喜剧（《扬名立万》《这个杀手不太冷静》）、战争剧情（《美丽人生》）和惊悚/科幻（《电锯惊魂》《移动迷宫》）。\n",
      "2. 近期观看的《移动迷宫》和《电锯惊魂》表明用户对悬疑惊悚类电影有兴趣，因此推荐《盗梦空间》（悬疑科幻）和《神探夏洛克》（悬疑推理）。\n",
      "3. 用户也喜欢喜剧元素，如《这个杀手不太冷静》，因此推荐《疯狂的石头》和《抓娃娃》（喜剧）。\n",
      "4. 《美丽人生》和《阿甘正传》显示用户对温情励志类电影有兴趣，因此推荐《穿普拉达的女王》（职场励志）。\n",
      "5. 虽然用户没有明确动画片观影记录，但《哪吒之魔童降世》和《疯狂动物城》是广受好评的动画，可作为备选。\n",
      "\n",
      "推荐: \n",
      "《盗梦空间》, 《疯狂的石头》, 《神探夏洛克》, 《抓娃娃》, 《穿普拉达的女王》, 《哪吒之魔童降世》, 《疯狂动物城》, 《泰坦尼克号》\n"
     ]
    }
   ],
   "source": [
    "MOVIE_RECOMMEND_SYSTEM_PROMPT_CHINESE = \"你是一个专业的电影推荐系统，你的任务是根据用户的观影历史，从候选电影列表中推荐最符合用户口味的电影。\"\n",
    "\n",
    "item_lists = \"\"\"\n",
    "1. 电影ID: 001, 名称: 《蒙娜丽莎的微笑》\n",
    "2. 电影ID: 002, 名称: 《肖申克的救赎》\n",
    "3. 电影ID: 003, 名称: 《阿甘正传》\n",
    "4. 电影ID: 004, 名称: 《扬名立万》\n",
    "5. 电影ID: 005, 名称: 《这个杀手不太冷静》\n",
    "6. 电影ID: 006, 名称: 《美丽人生》\n",
    "7. 电影ID: 007, 名称: 《电锯惊魂》\n",
    "8. 电影ID: 008, 名称: 《移动迷宫》\n",
    "\"\"\"\n",
    "candidates = \"\"\"\n",
    "1. 电影ID: 007, 名称: 《盗梦空间》\n",
    "2. 电影ID: 008, 名称: 《泰坦尼克号》\n",
    "3. 电影ID: 009, 名称: 《抓娃娃》\n",
    "4. 电影ID: 010, 名称: 《哪吒之魔童降世》\n",
    "5. 电影ID: 011, 名称: 《疯狂的石头》\n",
    "6. 电影ID: 012, 名称: 《神探夏洛克》\n",
    "7. 电影ID: 013, 名称: 《疯狂动物城》\n",
    "8. 电影ID: 014, 名称: 《穿普拉达的女王》\n",
    "\"\"\"\n",
    "MOVIE_RECOMMEND_PROMPT_CHINESE = \\\n",
    "\"\"\"\n",
    "**输入信息**\n",
    "1. 用户最近的观影记录，按时间排序，越靠后表示越近期观看，每一项为电影ID和电影名。\n",
    "{item_list}\n",
    "2. 待推荐的候选电影列表，每一项为电影ID和电影名。\n",
    "{candidates}\n",
    "\n",
    "**回答格式**：你必须严格按照以下要求格式回答\n",
    "\n",
    "解释: [你的思考和分析过程]\n",
    "推荐: [名称1, 名称2, 名称3, ... 按照推荐程度降序排列电影的名称]\n",
    "\"\"\"\n",
    "response = get_response(\n",
    "    MOVIE_RECOMMEND_SYSTEM_PROMPT_CHINESE,\n",
    "    MOVIE_RECOMMEND_PROMPT_CHINESE.format(\n",
    "        item_list=item_lists,\n",
    "        candidates=candidates\n",
    "    ))    \n",
    "print(response) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在该回答中，模型根据用户看过的电影分析了用户的喜好，但是没有考虑到时间因素，故我们针对这一问题改进提示词，进一步明确完成任务时需要关注的内容。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "解释: \n",
      "1. 用户观影历史分析：\n",
      "   - 早期偏向文艺/励志类：《蒙娜丽莎的微笑》《肖申克的救赎》《阿甘正传》《美丽人生》\n",
      "   - 中期转向国产悬疑喜剧：《扬名立万》《这个杀手不太冷静》\n",
      "   - 近期出现类型突破：惊悚片《电锯惊魂》和科幻冒险《移动迷宫》\n",
      "\n",
      "2. 偏好变化趋势：\n",
      "   - 从严肃文艺逐渐转向娱乐性更强的类型\n",
      "   - 最近表现出对强情节、高概念类型片的兴趣\n",
      "   - 仍保留对优质剧本的追求（所有影片评分均较高）\n",
      "\n",
      "3. 候选电影匹配：\n",
      "   - 第一优先级：满足近期新开拓的科幻/高概念兴趣《盗梦空间》\n",
      "   - 第二优先级：优质悬疑推理《神探夏洛克》\n",
      "   - 第三优先级：保留喜剧元素《疯狂的石头》《抓娃娃》\n",
      "   - 第四优先级：动画精品满足合家欢需求《疯狂动物城》《哪吒》\n",
      "   - 最后考虑：早期偏好的文艺类型《穿普拉达的女王》《泰坦尼克号》\n",
      "\n",
      "推荐: \n",
      "《盗梦空间》, \n",
      "《神探夏洛克》, \n",
      "《疯狂的石头》, \n",
      "《抓娃娃》, \n",
      "《疯狂动物城》, \n",
      "《哪吒之魔童降世》, \n",
      "《穿普拉达的女王》, \n",
      "《泰坦尼克号》\n"
     ]
    }
   ],
   "source": [
    "MOVIE_RECOMMEND_PROMPT_CHINESE = \\\n",
    "\"\"\"\n",
    "**输入信息**\n",
    "1. 用户最近的观影记录，按时间排序，越靠后表示越近期观看，每一项为电影ID和电影名。\n",
    "{item_list}\n",
    "2. 待推荐的候选电影列表，每一项为电影ID和电影名。\n",
    "{candidates}\n",
    "\n",
    "**任务**\n",
    "你需要根据用户最近的观影记录，通过分析每部电影的风格和内容，以及观看该电影的时间顺序，整合分析用户可能的电影喜好以及近期偏好变化，推荐出用户可能最想观看的下一部电影。输出时，请排序待推荐的候选电影列表，要求按照推荐的优先级排序，推荐程度越高位置越靠前。输出列表中仅包含电影的名称。\n",
    "\n",
    "**回答格式**：你必须严格按照以下要求格式回答\n",
    "\n",
    "解释: [你的思考和分析过程]\n",
    "推荐: [名称1, 名称2, 名称3, ... 按照推荐程度降序排列电影的名称]\n",
    "\"\"\"\n",
    "response = get_response(\n",
    "    MOVIE_RECOMMEND_SYSTEM_PROMPT_CHINESE,\n",
    "    MOVIE_RECOMMEND_PROMPT_CHINESE.format(\n",
    "        item_list=item_lists,\n",
    "        candidates=candidates\n",
    "    ))    \n",
    "print(response) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这一次，模型不仅分析了用户的电影偏好，并且分析出了用户的偏好变化，考虑的信息更加全面，推理结果也更加合理。但是输出格式却出现了问题。这在实际做提示工程时是很容易出现的，因为大模型底层逻辑中的注意力机制，在输入文本过长时，可能会产生忽视关键信息的问题，所以我们需要调整提示词，在保证模型当前能力的同时，让它按照预想的格式输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "解释: \n",
      "1. 用户观影历史分析：\n",
      "   - 早期偏向文艺/励志类：《蒙娜丽莎的微笑》《肖申克的救赎》《阿甘正传》《美丽人生》\n",
      "   - 中期转向国产悬疑喜剧：《扬名立万》《这个杀手不太冷静》\n",
      "   - 近期出现类型突破：《电锯惊魂》(惊悚)、《移动迷宫》(科幻悬疑)\n",
      "   \n",
      "2. 偏好变化趋势：\n",
      "   - 从严肃文艺逐渐转向娱乐性更强的作品\n",
      "   - 近期展现出对悬疑、惊悚元素的兴趣\n",
      "   - 保持对高质量叙事的追求（所有作品评分均较高）\n",
      "\n",
      "3. 候选电影匹配：\n",
      "   - 第一优先级：满足近期悬疑/烧脑偏好的《盗梦空间》（007）\n",
      "   - 第二优先级：高质量叙事且含励志元素的《穿普拉达的女王》（014）\n",
      "   - 第三优先级：国产优质喜剧《疯狂的石头》（011）延续中期偏好\n",
      "   - 第四优先级：动画佳作《疯狂动物城》（013）拓展观影维度\n",
      "   - 其他作品与当前偏好关联性较弱\n",
      "\n",
      "推荐: [《盗梦空间》, 《穿普拉达的女王》, 《疯狂的石头》, 《疯狂动物城》, 《泰坦尼克号》, 《抓娃娃》, 《哪吒之魔童降世》, 《神探夏洛克》]\n"
     ]
    }
   ],
   "source": [
    "MOVIE_RECOMMEND_PROMPT_CHINESE = \\\n",
    "\"\"\"\n",
    "**输入信息**\n",
    "1. 用户最近的观影记录，按时间排序，越靠后表示越近期观看，每一项为电影ID和电影名。\n",
    "{item_list}\n",
    "2. 待推荐的候选电影列表，每一项为电影ID和电影名。\n",
    "{candidates}\n",
    "\n",
    "**任务**\n",
    "你需要根据用户最近的观影记录，通过分析每部电影的风格和内容，以及观看该电影的时间顺序，整合分析用户可能的电影喜好以及近期偏好变化，推荐出用户可能最想观看的下一部电影。输出时，请排序待推荐的候选电影列表，要求按照推荐的优先级排序，推荐程度越高位置越靠前。输出列表中仅包含电影的名称。\n",
    "\n",
    "**回答格式**：你必须严格按照以下要求格式回答，否则你的答案会被视为无效。\n",
    "\n",
    "解释: [详细描述你的思考和分析过程]\n",
    "推荐: [名称1, 名称2, 名称3, ... 按照推荐程度降序排列电影的名称]\n",
    "\"\"\"\n",
    "response = get_response(\n",
    "    MOVIE_RECOMMEND_SYSTEM_PROMPT_CHINESE,\n",
    "    MOVIE_RECOMMEND_PROMPT_CHINESE.format(\n",
    "        item_list=item_lists,\n",
    "        candidates=candidates\n",
    "    ))    \n",
    "print(response) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你也可以根据自己的需求尝试新的问题和提示词。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总结来说，提示调优过程为：初版提示 → 观察模型表现，找出问题点 → 针对性改写提示，逐轮试验调整 → 直至输出符合预期。提示工程是一个实验性很强、非常依赖试错的过程，没有“万能好用”的初版提示，调优迭代是提示工程中最核心、最真实的工作方式。\n",
    "\n",
    "### 3.5.2 常用的提示工程结构\n",
    "<!-- 它涉及清晰表达、上下文设计、任务分解、角色设定、以及逐步推理等技巧 -->\n",
    "\n",
    "在实际的提示工程应用中，单靠简单的任务指令往往无法满足复杂、多样化的需求。为了更有效地引导语言模型输出符合预期的内容，人们逐渐总结出一些常用的提示结构设计方法。所谓提示结构，指的是根据不同任务目标、输出要求和风险控制需求，对提示词进行有组织、有层次的表达方式设计。不同类型的提示结构能够帮助开发者针对性地解决模型在安全性、格式规范、逻辑推理、情感表达等方面存在的问题，提升交互效果和结果质量。\n",
    "常见的提示结构大致可以分为安全性提示结构、结构性提示结构、逻辑性/推理性提示结构、角色扮演型提示结构、分步式推理提示结构（Chain of Thought）、工具调用型提示结构等几类。每一类结构都有其特定适用场景和设计技巧，既可以独立使用，也常常被组合应用于复杂任务之中。接下来，我们将逐一介绍这些提示结构的特点、适用需求、常用措辞技巧，并配以典型示例，帮助读者系统性掌握高效提示工程设计的方法。\n",
    "\n",
    "\n",
    "\n",
    "一、安全性提示结构——防偏见、防敏感、防价值判断\n",
    "\n",
    "- 适用需求：\n",
    "    - 禁止模型做价值判断、偏见性陈述\n",
    "    - 限制敏感领域回答\n",
    "    - 保证语言中立客观\n",
    "\n",
    "- 常用提示用词技巧：\n",
    "\n",
    "    - 明确禁止性要求：“请不要……”“禁止……”\n",
    "    - 引导客观标准：“请基于公开数据/事实/法律规定……”\n",
    "    - 限定判断范围：“在不涉及价值观判断的前提下……”\n",
    "\n",
    "- 示例：请基于公开统计数据，客观列举2023年全球GDP排名前5的国家名称。不要发表任何主观评价或价值判断。\n",
    "\n",
    "二、结构性提示结构——保证输出格式固定规范\n",
    "- 适用需求：\n",
    "    - 输出成表格、JSON、列表、Markdown、代码块等结构化格式\n",
    "    - 保证输出数据清晰、易解析\n",
    "\n",
    "- 常用提示用词技巧：\n",
    "\n",
    "    - 格式指令前置：“请用Markdown表格形式列出……”\n",
    "    - 明确列名/字段名：“表格列名依次为……”\n",
    "    - 指定输出结构：“以如下格式输出：{“name”: “xxx”, “value”: “xxx”}”\n",
    "\n",
    "- 示例：请列出常见排序算法及时间复杂度，并用Markdown表格形式展示，列名依次为‘算法名称’和‘时间复杂度’。\n",
    "\n",
    "三、逻辑性/推理性提示结构\n",
    "\n",
    "- 适用需求：\n",
    "    - 多步骤复杂推导\n",
    "    - 数学、逻辑、因果关系分析\n",
    "\n",
    "- 常用提示用词技巧：\n",
    "\n",
    "    - 强制逐步推理：“请逐步列出你的思考过程”\n",
    "    - 链式步骤指示：“第1步…… 第2步……”\n",
    "    - 思考后给结论：“在完成所有推理后再给出最终答案”\n",
    "\n",
    "- 示例：判断2, 4, 8, 16, ? 的下一个数是多少。请逐步列出你的推导过程，再给出最终答案。\n",
    "\n",
    "四、社交性/角色扮演型提示结构\n",
    "\n",
    "- 适用需求：\n",
    "    - 模拟专家/人物角色语言风格\n",
    "    - 定制语气、行为约束\n",
    "    - 模拟社交对话或团队协同\n",
    "\n",
    "- 常用提示用词技巧：\n",
    "\n",
    "    - 明确角色身份：“你现在是……”\n",
    "    - 限定语气风格：“使用正式/幽默/温暖/权威口吻”\n",
    "    - 交互式问答控制：“等待用户回复后再继续下一步”\n",
    "\n",
    "- 示例：你现在是一位循证医学专家，用严谨学术语言，解读最新AI辅助诊断论文核心结论。\n",
    "\n",
    "五、工具调用/流程调度型提示结构\n",
    "\n",
    "- 适用需求：\n",
    "    - 调用外部插件、搜索、计算器、API\n",
    "    - 多步骤任务调度\n",
    "\n",
    "- 常用提示用词技巧：\n",
    "\n",
    "    - 条件判断式调用：“如果无法确定，请调用xxx工具/执行xxx步骤”\n",
    "    - 明确调用目的：“调用xxx用于获取当前年份”\n",
    "    - 工具返回值接入：“将工具返回值插入到回复第3步中”\n",
    "\n",
    "- 示例：如果你不知道当前年份，请调用search工具获取，再计算50年后的年份。\n",
    "\n",
    "### 3.5.3 提示工程开发实践资源\n",
    "\n",
    "提示工程这一学科发展至今已经拥有了许多学术成果和开源平台，方便大家快速的学习、掌握和实践。在这里，我们推荐几个可用于学习的开源平台。\n",
    "\n",
    "**PromptHub**：这是一个开源的提示词管理平台，用户可以在其上搜索、存储和分享自己的提示词模板，比较适合新手学习如何编写提示词，或者快速开发。\n",
    "\n",
    "**Prompt‑Engineering‑Guide**：该开源项目整理了提示工程的指南、论文、讲座、工具与案例等各种资源，便于全面学习提示工程。\n",
    "\n",
    "**prompt-eng-interactive-tutorial**：Anthropic 公司基于 Claude 模型提供的 9 章互动式教程＋练习＋答案，适合动手学习提示工程。\n",
    "\n",
    "**awesome-chatgpt-prompts**：该项目也是一个提示词模板仓库，专为 ChatGPT 及其他 AI 语言模型（如 Claude、Gemini、Llama 和 Mistral）设计，方便用于探索和利用这些模型的功能。\n",
    "\n",
    "## 3.6 小结\n",
    "\n",
    "本章系统性的介绍了提示工程的核心内容及其应用。通过介绍提示工程的含义、提示词的组成、提示词基本标准、常见的提示工程技术、以及提示工程的实用方法，帮助同学们快速了解和上手提示工程。在大语言模型（LLM）时代，提示工程（Prompt Engineering）本质上是一门人与模型对话、操控智能体思维路径的语言艺术。不同于传统编程通过代码行令机器执行命令，提示工程通过自然语言提示，引导模型在庞大的知识空间中，找到符合人类需求的最优解答路径。好的提示工程，不仅是“告诉模型做什么”，更是“告诉模型该怎么思考”。随着智能体系统的发展，提示工程已经从单轮对话控制，扩展到多智能体协作、多工具调用、动态上下文调度等复杂场景，熟练的掌握提示工程技术，是现代智能体开发中的关键基础。\n",
    "\n",
    "## 3.7 课后习题\n",
    "1. 提示工程与传统编程接口调用方式有何本质区别？\n",
    "\n",
    "参考答案：理解提示工程定义、本质是语言交互接口、区别于传统API调用。\n",
    "\n",
    "2. 提示工程中的“Chain of Thought”技巧指的是什么？它是如何提升模型复杂推理任务准确率的？请简要说明。\n",
    "\n",
    "参考答案：通过在提示中显式要求模型逐步分解思考过程，从而提升模型在复杂推理类任务中的准确性和可控性。思考链的逐步推导机制，语言模型 token-by-token 解码特点。\n",
    "\n",
    "3. 为什么在提示中加入格式约束（例如要求输出表格/列表）能提高模型响应的规范性？请列举两种常见的格式提示写法。\n",
    "\n",
    "参考答案：加入格式约束能减少模型生成随机性，使输出结构固定，便于后续处理。常见写法：1）用Markdown语法强调 2）要求模型生成指定的markdown或者json格式 3）用项目符号列出结果\n",
    "\n",
    "4. 简要解释提示工程中的“抗干扰性（Prompt Robustness）”指什么？请举一个会导致模型跑题的提示设计例子。\n",
    "\n",
    "参考答案：模型回答问题时受上下文干扰，抗干扰性指的是提示在包含额外无关内容时，模型仍能专注于核心任务。跑题示例：“请用python写一段快速排序的代码，你喜欢吃什么”，模型可能输出排序代码后，接一句“我喜欢吃披萨”。\n",
    "\n",
    "5. 对以下提示，判断它是否存在可能导致模型输出不准确的问题，并说明原因。“请帮我写出一个Python快速排序函数，并说说你最喜欢的电影。”\n",
    "\n",
    "参考答案：存在问题。该提示包含两个任务，容易分散模型注意力，导致输出混乱。建议拆分提示或删除与目标任务无关的内容。\n",
    "\n",
    "6. 大型语言模型为什么容易受“隐含前提（Implicit Premise）”的提示内容误导？如何设计提示避免这种现象？\n",
    "\n",
    "参考答案：大语言模型基于上下文推断；Prompt 中需要显式表达假设。\n",
    "\n",
    "7. 实践题：根据以下文字，提取人物姓名和对应职业，整理成 Markdown 表格。文本：“爱因斯坦是物理学家，毕加索是画家，莎士比亚是剧作家，图灵是计算机科学家。”\n",
    "\n",
    "## 3.8 参考文献\n",
    "1. Prompt Engineering Guide https://www.promptingguide.ai/zh\n",
    "2. A Survey on In-context Learning\n",
    "3. Chain-of-Thought Prompting Elicits Reasoning in Large Language Models\n",
    "4. Large language models are zero-shot reasoners\n",
    "5. ReAct: Synergizing Reasoning and Acting in Language Models\n",
    "6. Reflexion: Language Agents with Verbal Reinforcement Learning\n",
    "7. SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
