{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第十章 LoRA微调与模型量化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.1 简介"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随着GPT、Llama、Stable Diffusion等大型预训练模型（Large Language Models, LLMs）的崛起，其卓越的通用能力为各行各业带来了革命性的变革与机遇。然而，要将这些强大的通用模型精准适配于特定的业务场景或个性化需求，微调（Fine-tuning）是不可或缺的关键步骤。但对于广大开发者、中小型企业乃至部分研究机构而言，对参数量动辄数十亿、上千亿的大模型进行传统的“全参数微调”，在计算资源和存储成本上都是一项几乎不可能完成的挑战。\n",
    "\n",
    "我们可以将一个庞大的预训练模型（如GPT-3）想象成一个知识渊博、经验丰富的“超级大脑”。若想让这个“大脑”掌握一项全新的、具体的技能（例如，扮演特定角色进行对话，或理解某一专业领域的术语），传统的“全参数微调”（Full Fine-tuning）方法要求我们更新“大脑”中几乎所有的神经元连接（即模型的全部参数）。这不仅需要海量的计算能力（如顶级的GPU集群）和巨大的存储空间，训练过程也同样耗时且昂贵。\n",
    "\n",
    "为解决这一难题，本章将深入介绍LoRA（Low-Rank Adaptation）——一种高效、轻量化的参数高效微调（Parameter-Efficient Fine-tuning, PEFT）技术。LoRA的核心思想是**“冻结”预训练模型的绝大部分原始参数，仅在模型中注入少量、可训练的“低秩”矩阵**来巧妙地适应新任务。这种方法好比是为“超级大脑”安装了一个小巧而高效的“插件”，使其能够在不改变原有知识结构的基础上，快速掌握新技能。通过这种方式，我们得以用极低的成本，实现对大模型的个性化定制与优化。\n",
    "\n",
    "然而，高效微调仅仅解决了“训练”阶段的资源难题。当我们希望将微调后的模型部署到实际应用中，尤其是部署在消费级硬件、边缘设备或移动端时，模型本身巨大的体积和推理时的高显存占用成为了新的瓶颈。这时，**模型量化（Quantization）** 技术便应运而生。量化通过降低模型参数的数值精度（例如，从32位浮点数转换为8位或4位整数），在几乎不影响模型性能的前提下，大幅压缩模型大小、降低显存消耗并加速推理速度。它为大模型走出数据中心、落地于更广泛的场景提供了可能。\n",
    "\n",
    "本章将结合LoRA与模型量化这两大关键技术，为您揭示如何在有限的资源下，高效地完成大模型的“训练”与“部署”全流程。\n",
    "\n",
    "<figure style=\"text-align: center;\">\n",
    "    <img src=\"./png_chap10/introduction.png\">\n",
    "    <figcaption style=\"font-size: 0.9em; margin-top: 8px;\">\n",
    "    图1：LoRA微调与模型量化技术概览\n",
    "  </figcaption>\n",
    "</figure>\n",
    "\n",
    "\n",
    "**本章重点内容：**\n",
    "\n",
    "- LoRA的核心原理： 探究低秩适应（Low-Rank Adaptation）背后的核心思想，理解其如何通过少量可训练参数来模拟全参数微调的效果\n",
    "- LoRA的实战应用： 学习如何将LoRA技术应用于主流的大型语言模型或文生图模型，并掌握其在具体任务中的配置与训练流程\n",
    "- 模型量化的价值： 探讨在资源受限的环境下（如消费级显卡或移动设备），模型量化（Quantization）作为关键压缩技术的原理及其对推理性能的提升"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.2 大模型微调的难点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "大模型微调的难点主要集中在资源瓶颈、训练效率和后续部署三大方面。\n",
    "\n",
    "直接微调一个拥有数十亿甚至上千亿参数的预训练模型，意味着需要更新模型中的每一个权重。这在理论上是让模型“全身心”学习新知识的最佳方式，但在实践中会遇到巨大的算力和存储壁垒。一个新人开发者或一个预算有限的团队，面对动辄需要数台顶级GPU、耗时数周的训练过程，往往会望而却步。这种资源上的巨大鸿沟，成为了阻碍大模型技术普及和创新的核心痛点。\n",
    "\n",
    "下面是传统微调技术在现代遇到的挑战：\n",
    "\n",
    "| **挑战类别**   | **具体问题描述**                                             | **产生的影响**                                               |\n",
    "| -------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |\n",
    "| **显存瓶颈**   | 微调需同时存储模型权重、梯度、优化器状态（如Adam）和激活值。 | 显存需求巨大（如7B模型超60GB），远超单张消费级/专业级GPU容量，导致个人和小型团队无法进行微调。 |\n",
    "| **计算与成本** | 对数十亿参数进行完整的前向和反向传播，计算量极大，且需长期占用昂贵的高端GPU。 | 训练周期长达数天或数周，拖慢研发速度；经济成本高昂，构成巨大的财务壁垒。 |\n",
    "| **部署与存储** | 每个微调任务都需要保存一个完整的模型副本，导致存储空间急剧膨胀；多任务服务需加载多个大模型。 | 造成巨大的存储资源浪费和管理复杂性；生产环境部署困难，服务延迟高，效率低下。 |\n",
    "| **训练质量**   | 1. **灾难性遗忘**：模型忘记预训练学到的通用知识。 <br> 2. **过拟合**：模型仅“背诵”微调数据，泛化能力差。 | 模型在通用任务上表现下降；对新数据的适应能力弱，实际应用价值受损。 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上述种种困难表明，传统的全参数微调技术在大模型时代已经变得不切实际，我们需要更为高效的技术来微调模型。 **参数高效微调（Parameter-Efficient Fine-Tuning，PEFT）** 应运而生，可以有效地解决上面的问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.3 LoRA 微调原理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3.1 概述"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一般来说，LoRA重点微调Transformer架构中的自注意力模块里的**查询**权重矩阵和**值**权重矩阵，即$W_q$和$W_v$。有时也会包含对**键**矩阵$W_k$和**输出**矩阵$W_o$的微调。\n",
    "\n",
    "\n",
    "LoRA的设计思路是在原始的预训练参数中加入旁路，该旁路由低秩矩阵A和B组成。开始训练前，矩阵A采用随机化高斯分布进行初始化，矩阵B则直接初始化为0矩阵。在训练过程中，冻结原模型的参数（即$W_0$），只对低秩矩阵A和低秩矩阵B进行训练操作。在训练结束后，将矩阵B和矩阵A的乘积BA与原模型参数相加，从而得到经过微调的最终模型参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure style=\"text-align: center;\">\n",
    "    <img src=\"./png_chap10/LoRA.png\">\n",
    "    <figcaption style=\"font-size: 0.9em; margin-top: 8px;\">\n",
    "    图2：LoRA微调示意图\n",
    "  </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3.2 LoRA参数更新示例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设原模型参数矩阵$W_0$的大小为$d \\times k$，低秩矩阵B的大小为$d \\times r$，低秩矩阵A的大小为$r \\times k$，且 $r << \\min(d, k)$。设更新后的模型参数为$W_1$，$\\triangle W$代表需要更新的参数。\n",
    "\n",
    "则模型的参数更新计算方式如下式：\n",
    "\n",
    "$W_1 = W_0 + \\triangle W = W_0 + BA$\n",
    "\n",
    "其中，我们只需要训练矩阵A和矩阵B。\n",
    "\n",
    "在秩r的选择上，一般选择1、2、4、8。针对领域跨度较大的任务，可以适当增大秩r的数值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3.3 有关LoRA微调的常见问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 我们应该对Transformer中的哪些权重矩阵应用LoRA？\n",
    "\n",
    "   根据《LoRA: Low-Rank Adaptation of Large Language Models》论文中的实验和分析，我们没有必要对Transformer中的所有权重矩阵都应用LoRA，最有效且参数效率最高的策略是仅对自注意力模块中的权重矩阵应用LoRA。为了在性能和效率之间取得最佳平衡，应优先且主要将LoRA应用于Transformer注意力层中的$W_q$和$W_v$矩阵。这已经足够捕获下游任务所需的核心知识调整，同时最大化地节省了可训练参数。\n",
    "\n",
    "- 我们一般如何确定秩r的取值？\n",
    "\n",
    "   论文的实验表明，对于大型语言模型(如GPT-3 175B)，r=1或r=2这样小的值就已经能够取得非常好的结果，性能显著优于其他参数高效微调方法。对于RoBERTa、DeBERTa等模型，r=8也被证明是一个非常强的设定。虽然增加r会引入更多的可训练参数，让模型有更大的调整空间，但实验表明，当r超过某个较小的值（如4或8）后，性能的提升会迅速减缓，收益递减。从实际应用的角度来看，我们通常会从一个很小的秩（比如r=4或r=8）开始尝试。如果任务非常复杂或微调效果不佳，可以再适当增加r的值进行实验。选择r是在模型性能和训练成本之间的一种权衡。\n",
    "\n",
    "- LoRA 的权重矩阵初始化为何采用“高斯分布 + 零”的组合，而不是“双高斯”或“双零”？这背后的原理是什么？\n",
    "\n",
    "   将 B 初始化为零，无论矩阵 A 如何初始化，其乘积 BA 在初始状态下必然为零矩阵，这意味着在训练的第一步，LoRA模块对模型的改造为零（$ W_0 + \\triangle W = W_0 + 0 = W_0 $）。这可以保证微调是从预训练模型的原始状态平稳开始的，避免因随机扰动导致模型在初期输出混乱，具体来说：\n",
    "\n",
    "   - 如果我们选用“双高斯”初始化，则乘积 BA 将会是一个非零的随机矩阵。这个随机矩阵会作为噪声被直接加到预训练模型的权重上，很可能会严重破坏模型从海量数据中学到的宝贵知识。这种“一上来就胡改”的方式，会使模型在训练初期产生巨大的、无意义的输出，导致训练过程不稳定，甚至可能需要更长的时间才能收敛到理想状态。\n",
    "\n",
    "   - 如果我们选用“双零”初始化，根据链式法则，我们可以得到 $ \\frac{\\partial L}{\\partial A} = \\frac{\\partial L}{\\partial W} \\frac{\\partial W}{\\partial A} $，由于 $ W = W_0 + BA $，可得 $ \\frac{\\partial L}{\\partial A} = B^T \\frac{\\partial L}{\\partial W} $。因为 B 是零矩阵，所以 $ \\frac{\\partial L}{\\partial A} = 0 $ ，同理可得 $ \\frac{\\partial L}{\\partial B} = 0 $。由此可见，无论训练多少轮，A和B的梯度永远是零，它们的参数不会被更新。\n",
    "\n",
    "   - 因此，我们采用“高斯分布 + 零”的组合来初始化矩阵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3.4 LoRA所解决的问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 问题类别                | 具体问题描述                                                 | LoRA 解决方案                                                |\n",
    "| ----------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |\n",
    "| **显存瓶颈**         | 微调大型模型需要为每个任务存储一份完整的模型副本，占用大量显存。 | 冻结预训练模型的权重，仅训练并存储旁路注入的低秩矩阵（A和B）。<br>这些矩阵参数量极小（秩`r`远小于模型维度`d`），可将存储需求降低数千倍。 |\n",
    "| **计算与时间成本**   | 对整个大型模型进行梯度计算和更新，需要消耗大量的计算资源和时间。 | 在训练中，无需计算庞大的预训练权重的梯度。<br> 计算仅集中在新增的低秩矩阵上，从而显著减少了计算量和训练时间。 |\n",
    "| **部署与存储难题**   | 为每个下游任务都部署一个独立的、巨大的微调后模型，导致存储和管理的复杂性。 | 共享同一个基础大模型，每个任务仅需一个非常小的LoRA文件。这带来了两个好处：<br>1. **快速切换**：可在一个基础模型上快速加载和切换不同的LoRA模块，以适应不同任务。<br>2. **类比“模型MOD”**：像游戏MOD一样，在同一个基础模型上应用不同的轻量级调整，实现多样化功能。 |\n",
    "| **训练过程中的问题** | 在小数据集上对大模型进行完全微调时，容易发生“灾难性遗忘”，即模型忘记了在预训练中学到的通用知识。 | 由于原始的预训练权重在训练过程中保持冻结，LoRA有效避免了灾难性遗忘，保留了模型的泛化能力。 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.4 LoRA高效微调实践"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.4.1 环境配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.4.2 加载模型和分词器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这里我们选择加载模型Qwen2.5-0.5B-Instruct用于示例展示，其中涉及到参数*torch_dtype*，其作用是指定模型加载到内存时使用的**数据类型**(精度).\n",
    "\n",
    "下面我们用一个小例子来展示使用 `torch.bfloat16` 类型加载模型，其占用的显存要小于使用 `float32` 类型加载的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/lora/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import gc\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_name = \"Qwen/Qwen2.5-0.5B-Instruct\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义用于打印显存使用情况的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_memory_in_gb(device):\n",
    "    \"\"\"返回指定CUDA设备上已分配的显存，单位为GB\"\"\"\n",
    "    return torch.cuda.memory_allocated(device) / (1024**3)\n",
    "\n",
    "def print_gpu_memory(stage=\"\"):\n",
    "    \"\"\"打印当前已分配的显存\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        # 我们使用 device=0, 即第一张显卡\n",
    "        memory_gb = get_memory_in_gb(device=0)\n",
    "        print(f\"[{stage}] 当前已分配显存: {memory_gb:.4f} GB\")\n",
    "        \n",
    "        return memory_gb\n",
    "    else:\n",
    "        print(\"未检测到 CUDA 设备。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看使用 `float32` 类型加载模型的显存占用情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 1. 测试 float32 (默认精度) ---\n",
      "[加载前] 当前已分配显存: 0.0000 GB\n",
      "[加载后] 当前已分配显存: 1.8411 GB\n",
      "模型参数的数据类型: torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- 1. 测试 float32 (默认精度) ---\")\n",
    "\n",
    "# 清理环境，确保测量准确\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "mem_before = print_gpu_memory(\"加载前\")\n",
    "\n",
    "# 使用默认精度 (float32) 加载模型\n",
    "model_fp32 = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float32).to(device)\n",
    "\n",
    "mem_after = print_gpu_memory(\"加载后\")\n",
    "mem_fp32 = mem_after - mem_before\n",
    "\n",
    "print(f\"模型参数的数据类型: {model_fp32.config.torch_dtype}\")\n",
    "\n",
    "\n",
    "# 清理模型，释放显存\n",
    "del model_fp32\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看使用 `bfloat16` 类型加载模型的显存占用情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 2. 测试 bfloat16 (半精度) ---\n",
      "[加载前] 当前已分配显存: 0.0000 GB\n",
      "[加载后] 当前已分配显存: 0.9279 GB\n",
      "模型参数的数据类型: torch.bfloat16\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- 2. 测试 bfloat16 (半精度) ---\")\n",
    "\n",
    "# 再次清理环境\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "mem_before = print_gpu_memory(\"加载前\")\n",
    "\n",
    "# 指定 torch_dtype=torch.bfloat16 来使用半精度加载\n",
    "model_bf16 = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.bfloat16\n",
    ").to(device)\n",
    "\n",
    "mem_after = print_gpu_memory(\"加载后\")\n",
    "mem_bf16 = mem_after - mem_before\n",
    "\n",
    "print(f\"模型参数的数据类型: {model_bf16.config.torch_dtype}\")\n",
    "\n",
    "# 清理模型\n",
    "del model_bf16\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Float32 模型占用显存: 1.8411 GB\n",
      "BFloat16 模型占用显存: 0.9279 GB\n",
      "\n",
      "Ratio (Float32 / BFloat16): 1.98\n"
     ]
    }
   ],
   "source": [
    "print(f\"Float32 模型占用显存: {mem_fp32:.4f} GB\")\n",
    "print(f\"BFloat16 模型占用显存: {mem_bf16:.4f} GB\")\n",
    "\n",
    "ratio = mem_fp32 / mem_bf16\n",
    "print(f\"\\nRatio (Float32 / BFloat16): {ratio:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结论: 使用 bfloat16 加载模型，占用的显存大约是 float32 的一半。\n",
    "\n",
    "上面的这个例子很好的说明了，当我们使用不同数据类型加载模型时，其占用的显存大小也会不同。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面我们将使用 `torch.bfloat16` 数据类型加载模型，并展开后续的微调操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型和分词器加载完成\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_name = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "model_save_path = f\"{model_name}-local\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name, \n",
    "    torch_dtype=torch.bfloat16, \n",
    "    trust_remote_code=True\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "# 将模型保存到本地\n",
    "model.save_pretrained(model_save_path)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "# 将分词器(tokenizer)的填充符(pad_token)设置为句子结束eos_token)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "print(\"模型和分词器加载完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.4.3 加载数据集并预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里我们选用一个 [github 开源项目](https://github.com/KMnO4-zx/huanhuan-chat) 中的数据集，其存储在本地 *./dataset_chap10/huanhuan.json* 中，微调后我们将得到模仿甄嬛语气的聊天语言模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功加载数据集\n"
     ]
    }
   ],
   "source": [
    "# 加载数据集\n",
    "\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "df = pd.read_json('./dataset_chap10/huanhuan.json')\n",
    "ds = Dataset.from_pandas(df)\n",
    "\n",
    "print(\"成功加载数据集\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['instruction', 'input', 'output'],\n",
      "    num_rows: 3729\n",
      "})\n",
      "数据集结构及其示例\n",
      "instruction: 小姐，别的秀女都在求中选，唯有咱们小姐想被撂牌子，菩萨一定记得真真儿的——\n",
      "input: \n",
      "output: 嘘——都说许愿说破是不灵的。\n"
     ]
    }
   ],
   "source": [
    "# 查看数据集结构\n",
    "print(ds)\n",
    "sample = ds[0]\n",
    "\n",
    "print(\"数据集结构及其示例\")\n",
    "print(f\"instruction: {sample['instruction']}\")\n",
    "print(f\"input: {sample['input']}\")\n",
    "print(f\"output: {sample['output']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义数据预处理函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(example):\n",
    "    # 设置最大长度\n",
    "    MAX_LENGTH = 512\n",
    "\n",
    "    # 指令部分\n",
    "    instruction_part = f\"<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>user\\n{example['instruction'] + example['input']}<|im_end|>\\n<|im_start|>assistant\\n\"\n",
    "    # 目标输出部分\n",
    "    response_part = f\"{example['output']}<|im_end|>\"\n",
    "\n",
    "    instruction_ids = tokenizer(instruction_part, add_special_tokens=False)[\"input_ids\"]\n",
    "    response_ids = tokenizer(response_part, add_special_tokens=False)[\"input_ids\"]\n",
    "\n",
    "    input_ids = instruction_ids + response_ids\n",
    "    labels = [-100] * len(instruction_ids) + response_ids  # 标签是 -100 的地方不需要计算损失\n",
    "\n",
    "    if len(input_ids) > MAX_LENGTH:\n",
    "        input_ids = input_ids[:MAX_LENGTH]\n",
    "        labels = labels[:MAX_LENGTH]\n",
    "\n",
    "    # 手动构建 attention_mask\n",
    "    attention_mask = [1] * len(input_ids)\n",
    "\n",
    "    # 填充到 MAX_LENGTH\n",
    "    padding_len = MAX_LENGTH - len(input_ids)\n",
    "    input_ids += [tokenizer.pad_token_id] * padding_len\n",
    "    labels += [-100] * padding_len # label 的填充值也必须是 -100\n",
    "    attention_mask += [0] * padding_len\n",
    "    \n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"labels\": labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "处理数据并查看数据集结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3729/3729 [00:01<00:00, 2618.62 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 3729\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenized_id = ds.map(preprocess, remove_columns=ds.column_names)\n",
    "\n",
    "print(tokenized_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.4.4 LoRA微调实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name, \n",
    "    torch_dtype=torch.bfloat16, \n",
    "    trust_remote_code=True\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们使用hugging face的 PEFT 库来为模型配置 LoRA 微调。在这里先介绍一些LoRA的基本配置参数：\n",
    "\n",
    "- *task_type*: 指定任务类型，`CAUSAL_LM`是指像GPT一样的文本生成任务\n",
    "- *target_modules*: 最关键的参数之一，告诉PEFT要在模型的哪些模块上应用LoRA\n",
    "- *inference_mode*：设置LoRA的模式，`False` 表示我们正在为训练配置模型，`True` 表示我们准备加载一个已经训练好的LoRA模型用于推理\n",
    "- *r*：LoRA的秩，控制可训练矩阵A和B的大小\n",
    "- *lora_alpha*：一个调节 LoRA 效果强度的超参数，用于平衡原始模型权重和 LoRA 权重的重要性（lora_alpha越大，LoRA权重越重要）。通常将 `lora_alpha` 设置为 `r` 的两倍或四倍。\n",
    "- *lora_dropout*：在 LoRA 层上应用的 Dropout 比率。一种标准的正则化技术，用于防止模型在训练新增的 LoRA 参数时发生过拟合。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,081,344 || all params: 495,114,112 || trainable%: 0.2184\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "# 定义LoRA配置\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"],\n",
    "    inference_mode=False,\n",
    "    r=8,   # LoRA的秩\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    ")\n",
    "\n",
    "'''\n",
    "get_peft_model会遍历model的所有层，找到lora_config中指定的模块，然后\n",
    "1. 冻结原始模块的权重\n",
    "2. 在旁边注入新的、可训练的LoRA矩阵A和B\n",
    "\n",
    "get_peft_model返回一个经过改造后的新模型。它的行为和原始模型几乎一样，但当你开始训练它时，\n",
    "只有那些被注入的 LoRA 层（以及其他一些小的可训练组件，如分类头）的参数会被更新。\n",
    "'''\n",
    "lora_model = get_peft_model(model, lora_config)\n",
    "lora_model_save_path = f\"{model_name}-lora\"\n",
    "\n",
    "# 打印可训练参数详情\n",
    "lora_model.print_trainable_parameters()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练参数介绍：\n",
    "- `per_device_train_batch_size`：每个设备（如一块 GPU）在一个训练步骤中处理的样本数量。这是硬件上的批次大小，直接影响显存占用\n",
    "- `gradient_accumulation_steps=4`：梯度累积步数，模型会先执行4次的前向和反向传播，但不清空梯度，而是将梯度累积起来，最后再用累计的梯度对模型参数进行更新\n",
    "- `logging_steps`：决定控制台打印训练日志的频率\n",
    "- `num_train_epochs=3`：训练的总轮数。模型将会完整地遍历整个训练数据集 3 次。\n",
    "- `save_steps=100`：每隔 100 个训练步，保存一次模型的检查点。\n",
    "- `learning_rate`：模型学习率\n",
    "- `save_on_each_node=True`：在分布式训练（多台机器）环境中，确保每个节点都正确地保存模型，通常由主节点执行。\n",
    "- `gradient_checkpointing`：梯度检查点。在正常的反向传播中，需要存储大量中间激活值以便计算梯度。开启此选项后，\n",
    "大部分中间激活值将不再被存储，而是在反向传播需要它们时重新计算。这使得你可以用有限的显存训练更大的模型或使用更大的批次。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**开始训练**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='699' max='699' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [699/699 05:20, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>4.117700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.929100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>3.845700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.805000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>3.842200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>3.699400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>3.693300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>3.675500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>3.679800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.662600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>3.606600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>3.615500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>3.612900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/lora/lib/python3.10/site-packages/peft/utils/other.py:1110: UserWarning: Unable to fetch remote file due to the following error 401 Client Error: Unauthorized for url: https://hf-mirror.com/Qwen/Qwen2.5-0.5B-Instruct/resolve/main/config.json (Request ID: Root=1-68708155-191a9fc85e0fd6dc301e2930;e6f2279a-cd9e-4303-81b5-4a68b25a9b9c)\n",
      "\n",
      "Invalid credentials in Authorization header - silently ignoring the lookup for the file config.json in Qwen/Qwen2.5-0.5B-Instruct.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/lora/lib/python3.10/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in Qwen/Qwen2.5-0.5B-Instruct - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/lora/lib/python3.10/site-packages/peft/utils/other.py:1110: UserWarning: Unable to fetch remote file due to the following error 401 Client Error: Unauthorized for url: https://hf-mirror.com/Qwen/Qwen2.5-0.5B-Instruct/resolve/main/config.json (Request ID: Root=1-68708183-5896fdc278f872d25dc5e3b3;f1b8d02b-4789-4080-ac16-c5abf3166a84)\n",
      "\n",
      "Invalid credentials in Authorization header - silently ignoring the lookup for the file config.json in Qwen/Qwen2.5-0.5B-Instruct.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/lora/lib/python3.10/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in Qwen/Qwen2.5-0.5B-Instruct - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/lora/lib/python3.10/site-packages/peft/utils/other.py:1110: UserWarning: Unable to fetch remote file due to the following error 401 Client Error: Unauthorized for url: https://hf-mirror.com/Qwen/Qwen2.5-0.5B-Instruct/resolve/main/config.json (Request ID: Root=1-687081b0-72a9fd5a222d4aa619e56909;04658f23-4b29-427f-a54f-355801450614)\n",
      "\n",
      "Invalid credentials in Authorization header - silently ignoring the lookup for the file config.json in Qwen/Qwen2.5-0.5B-Instruct.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/lora/lib/python3.10/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in Qwen/Qwen2.5-0.5B-Instruct - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/lora/lib/python3.10/site-packages/peft/utils/other.py:1110: UserWarning: Unable to fetch remote file due to the following error 401 Client Error: Unauthorized for url: https://hf-mirror.com/Qwen/Qwen2.5-0.5B-Instruct/resolve/main/config.json (Request ID: Root=1-687081de-6743096e745a7fbd2c880a24;8b578bde-ae3f-4c4f-a561-b7ed98f35ed5)\n",
      "\n",
      "Invalid credentials in Authorization header - silently ignoring the lookup for the file config.json in Qwen/Qwen2.5-0.5B-Instruct.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/lora/lib/python3.10/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in Qwen/Qwen2.5-0.5B-Instruct - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/lora/lib/python3.10/site-packages/peft/utils/other.py:1110: UserWarning: Unable to fetch remote file due to the following error 401 Client Error: Unauthorized for url: https://hf-mirror.com/Qwen/Qwen2.5-0.5B-Instruct/resolve/main/config.json (Request ID: Root=1-6870820c-7a257d0d174a212553e84b9b;7b165520-a2cb-4388-8f5a-a1b6fcb62c30)\n",
      "\n",
      "Invalid credentials in Authorization header - silently ignoring the lookup for the file config.json in Qwen/Qwen2.5-0.5B-Instruct.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/lora/lib/python3.10/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in Qwen/Qwen2.5-0.5B-Instruct - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/lora/lib/python3.10/site-packages/peft/utils/other.py:1110: UserWarning: Unable to fetch remote file due to the following error 401 Client Error: Unauthorized for url: https://hf-mirror.com/Qwen/Qwen2.5-0.5B-Instruct/resolve/main/config.json (Request ID: Root=1-6870823b-59e350b11adaff8f43744ee9;cf5fd988-9174-4790-8ae9-3db569ba4ebb)\n",
      "\n",
      "Invalid credentials in Authorization header - silently ignoring the lookup for the file config.json in Qwen/Qwen2.5-0.5B-Instruct.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/lora/lib/python3.10/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in Qwen/Qwen2.5-0.5B-Instruct - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/lora/lib/python3.10/site-packages/peft/utils/other.py:1110: UserWarning: Unable to fetch remote file due to the following error 401 Client Error: Unauthorized for url: https://hf-mirror.com/Qwen/Qwen2.5-0.5B-Instruct/resolve/main/config.json (Request ID: Root=1-68708268-7be4c866488b3a7f338aeaac;ea00ad30-44aa-4018-951b-767a32d9fbc7)\n",
      "\n",
      "Invalid credentials in Authorization header - silently ignoring the lookup for the file config.json in Qwen/Qwen2.5-0.5B-Instruct.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/lora/lib/python3.10/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in Qwen/Qwen2.5-0.5B-Instruct - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=699, training_loss=3.742911168263535, metrics={'train_runtime': 321.7119, 'train_samples_per_second': 34.773, 'train_steps_per_second': 2.173, 'total_flos': 1.2326929487364096e+16, 'train_loss': 3.742911168263535, 'epoch': 2.996784565916399})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer, DataCollatorForSeq2Seq\n",
    "\n",
    "### 训练参数\n",
    "args = TrainingArguments(\n",
    "    output_dir=lora_model_save_path,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    logging_steps=50,\n",
    "    num_train_epochs=3,\n",
    "    save_steps=100,\n",
    "    learning_rate=1e-4,\n",
    "    save_on_each_node=True,\n",
    "    gradient_checkpointing=False\n",
    ")\n",
    "\n",
    "'''\n",
    "data_collator的作用：\n",
    "当 Trainer 从 train_dataset 中取出一批样本（一个包含多个字典的列表）时，\n",
    "data_collator 负责将这批数据整理成一个单一的、可以直接输入模型的批处理张量。\n",
    "\n",
    "DataCollatorForSeq2Seq 是 Hugging Face 提供的一个数据整理器，专门用于序列到序列（Seq2Seq）任务。\n",
    "它负责将一批样本整理成一个可以输入模型的格式。\n",
    "\n",
    "padding=True：表示在整理数据时，如果样本长度不一致，需要进行填充，使得所有样本长度相同。\n",
    "'''\n",
    "trainer = Trainer(\n",
    "    model=lora_model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_id,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer, padding=True),\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.4.5 全参数微调实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "model_name = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "\n",
    "fft_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name, \n",
    "    torch_dtype=torch.bfloat16, \n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "fft_model_save_path = f\"{model_name}-fft\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='699' max='699' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [699/699 06:38, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>4.750700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>4.309700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>4.130800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.992100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>3.540600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.362600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>2.324600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.311400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>2.240400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.414200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.908200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.890900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.882300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=699, training_loss=2.4961076826496695, metrics={'train_runtime': 399.0207, 'train_samples_per_second': 28.036, 'train_steps_per_second': 1.752, 'total_flos': 1.2289797414715392e+16, 'train_loss': 2.4961076826496695, 'epoch': 2.996784565916399})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer, DataCollatorForSeq2Seq\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=f\"{fft_model_save_path}-train\",\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    logging_steps=50,\n",
    "    num_train_epochs=3,\n",
    "    save_steps=100,\n",
    "    learning_rate=1e-4,\n",
    "    save_on_each_node=True,\n",
    "    gradient_checkpointing=False\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=fft_model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_id,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer, padding=True),\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_model.save_pretrained(fft_model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**设计测试样例**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '你在这做什么？'}], [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '我好久没见到你了，你最近怎么样？'}], [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': '你最近在忙什么？'}]]\n"
     ]
    }
   ],
   "source": [
    "prompts = [\"你在这做什么？\", \"我好久没见到你了，你最近怎么样？\", \"你最近在忙什么？\"]\n",
    "\n",
    "messages = [\n",
    "    [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    for prompt in prompts\n",
    "]\n",
    "\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**加载原始模型**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_name = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name, \n",
    "    device_map=\"auto\", \n",
    "    torch_dtype=torch.bfloat16, \n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**获取原始模型输出**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instruction 0: 你在这做什么？\n",
      "response 0: \n",
      "我是一个人工智能语言模型，被训练来回答各种问题和提供信息。我可以进行对话、创作文本、生成答案等等任务。我的目的是帮助用户更好地理解和解决问题，而不是替代人类专家或知识。\n",
      "----------------------------------------------------------------------------------------------------\n",
      "instruction 1: 我好久没见到你了，你最近怎么样？\n",
      "response 1: 你好！我最近在学习编程和人工智能方面的知识。很高兴能与你交流和分享我的知识。有什么问题或需要帮助的地方吗？\n",
      "----------------------------------------------------------------------------------------------------\n",
      "instruction 2: 你最近在忙什么？\n",
      "response 2: \n",
      "作为一名AI助手，我并没有实际的活动。我的目的是尽可能地回答您的问题、提供帮助和支持，并与您进行交流和互动。\n",
      "\n",
      "如果您有任何问题或需要帮助，请随时告诉我，我会尽力为您提供支持和解答。\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 格式化\n",
    "formatted_prompts = [\n",
    "    tokenizer.apply_chat_template(message, tokenize=False, add_generation_prompt=True)\n",
    "    for message in messages\n",
    "]\n",
    "\n",
    "# 编码\n",
    "model_inputs = tokenizer(\n",
    "    formatted_prompts,\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\"\n",
    ").to('cuda')\n",
    "\n",
    "# 生成\n",
    "generated_ids = model.generate(\n",
    "    model_inputs.input_ids,\n",
    "    attention_mask=model_inputs.attention_mask,\n",
    "    max_new_tokens=512\n",
    ")\n",
    "\n",
    "# 解码\n",
    "input_len = model_inputs.input_ids.shape[1]\n",
    "output_ids = generated_ids[:, input_len:]\n",
    "responses = tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
    "\n",
    "for i, instruction, response in zip(range(len(messages)), prompts, responses):\n",
    "    print(f\"instruction {i}: {instruction}\")\n",
    "    print(f\"response {i}: {response}\")\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**加载LoRA模型**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "lora_path = f\"{model_name}-lora/checkpoint-699\"\n",
    "\n",
    "lora_model = PeftModel.from_pretrained(model, model_id=lora_path)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**获取LoRA模型输出**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instruction 0: 你在这做什么？\n",
      "response 0: 妹妹，我来报信。姐姐们都出去了，我一个人在这里等你们呢。\n",
      "----------------------------------------------------------------------------------------------------\n",
      "instruction 1: 我好久没见到你了，你最近怎么样？\n",
      "response 1: 皇上驾崩后，臣妾才回到京中。\n",
      "----------------------------------------------------------------------------------------------------\n",
      "instruction 2: 你最近在忙什么？\n",
      "response 2: 公公是来陪我玩的，我可不想让公公失望。\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 格式化\n",
    "formatted_prompts = [\n",
    "    tokenizer.apply_chat_template(message, tokenize=False, add_generation_prompt=True)\n",
    "    for message in messages\n",
    "]\n",
    "\n",
    "# 编码\n",
    "model_inputs = tokenizer(\n",
    "    formatted_prompts,\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\"\n",
    ").to('cuda')\n",
    "\n",
    "# 生成\n",
    "generated_ids = model.generate(\n",
    "    model_inputs.input_ids,\n",
    "    attention_mask=model_inputs.attention_mask,\n",
    "    max_new_tokens=512\n",
    ")\n",
    "\n",
    "# 解码\n",
    "input_len = model_inputs.input_ids.shape[1]\n",
    "# 截取input_len之后的token作为response, 因为input_len之前的token是prompt\n",
    "output_ids = generated_ids[:, input_len:]\n",
    "responses = tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
    "\n",
    "for i, instruction, response in zip(range(len(messages)), prompts, responses):\n",
    "    print(f\"instruction {i}: {instruction}\")\n",
    "    print(f\"response {i}: {response}\")\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**加载fft模型**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"Qwen/Qwen2.5-0.5B-Instruct-fft\",\n",
    "    device_map=\"auto\", \n",
    "    torch_dtype=torch.bfloat16, \n",
    "    trust_remote_code=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**获取fft模型输出**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instruction 0: 你在这做什么？\n",
      "response 0: 宫里的女人太多，我怕看不过眼。\n",
      "----------------------------------------------------------------------------------------------------\n",
      "instruction 1: 我好久没见到你了，你最近怎么样？\n",
      "response 1: 一切都好，只是最近安妹妹身子一直不好，所以不能来向皇后娘娘请罪。\n",
      "----------------------------------------------------------------------------------------------------\n",
      "instruction 2: 你最近在忙什么？\n",
      "response 2: 听闻皇上很关心小家子气，就特来向太后请安。\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 格式化\n",
    "formatted_prompts = [\n",
    "    tokenizer.apply_chat_template(message, tokenize=False, add_generation_prompt=True)\n",
    "    for message in messages\n",
    "]\n",
    "\n",
    "# 编码\n",
    "model_inputs = tokenizer(\n",
    "    formatted_prompts,\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\"\n",
    ").to('cuda')\n",
    "\n",
    "# 生成\n",
    "generated_ids = fft_model.generate(\n",
    "    model_inputs.input_ids,\n",
    "    attention_mask=model_inputs.attention_mask,\n",
    "    max_new_tokens=512\n",
    ")\n",
    "\n",
    "# 解码\n",
    "input_len = model_inputs.input_ids.shape[1]\n",
    "# 截取input_len之后的token作为response, 因为input_len之前的token是prompt\n",
    "output_ids = generated_ids[:, input_len:]\n",
    "responses = tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
    "\n",
    "for i, instruction, response in zip(range(len(messages)), prompts, responses):\n",
    "    print(f\"instruction {i}: {instruction}\")\n",
    "    print(f\"response {i}: {response}\")\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行结果表明，微调成功地为模型赋予了角色化能力，使其能够精准地模拟甄嬛的口吻进行交互。\n",
    "\n",
    "值得注意的是，尽管LoRA仅训练了少量参数，但其总训练时长与全参数微调相当。这主要是因为训练中的大部分时间消耗在前向传播上，该过程需要动用模型的全部参数。LoRA的效率优势主要体现在反向传播和梯度更新阶段，但这部分耗时在整体训练循环中的占比较小，因此未能显著缩短总时长。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.4.6 LoRA微调具备的存储优势\n",
    "\n",
    "本小节我们来比较LoRA微调相较于传统微调具备的存储优势。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义辅助函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_dir_size(path='.'):\n",
    "    \"\"\"计算目录大小\"\"\"\n",
    "    total = 0\n",
    "    with os.scandir(path) as it:\n",
    "        for entry in it:\n",
    "            if entry.is_file():\n",
    "                total += entry.stat().st_size\n",
    "            elif entry.is_dir():\n",
    "                total += get_dir_size(entry.path)\n",
    "    return total\n",
    "\n",
    "def format_size(size_bytes):\n",
    "    \"\"\"将字节大小格式化为KB, MB, GB\"\"\"\n",
    "    if size_bytes < 1024:\n",
    "        return f\"{size_bytes} Bytes\"\n",
    "    elif size_bytes < 1024**2:\n",
    "        return f\"{size_bytes/1024:.2f} KB\"\n",
    "    elif size_bytes < 1024**3:\n",
    "        return f\"{size_bytes/1024**2:.2f} MB\"\n",
    "    else:\n",
    "        return f\"{size_bytes/1024**3:.2f} GB\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**原始空间占用空间大小**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始模型占用空间大小: 942.32 MB\n"
     ]
    }
   ],
   "source": [
    "model_size = get_dir_size(model_save_path)\n",
    "print(f\"原始模型占用空间大小: {format_size(model_size)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LoRA参数占用空间大小**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA模型参数大小: 12.58 MB\n"
     ]
    }
   ],
   "source": [
    "paras_size = get_dir_size(f\"{lora_model_save_path}/checkpoint-699\")\n",
    "print(f\"LoRA模型参数大小: {format_size(paras_size)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**fft模型占用空间大小**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FFT模型大小: 942.32 MB\n"
     ]
    }
   ],
   "source": [
    "fft_model_size = get_dir_size(\"Qwen/Qwen2.5-0.5B-Instruct-fft\")\n",
    "print(f\"FFT模型大小: {format_size(fft_model_size)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "存储结果的对比清晰地展示了LoRA的优势：全参数微调需占用 942.32 MB 来存储整个模型，而LoRA仅需 12.58 MB 保存其轻量的适配器参数，存储空间消耗降低了近98.7%。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.5 模型量化方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.5.1 简介"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随着人工智能的发展，模型变得越来越大，例如拥有数百亿甚至上万亿参数的语言模型（LLM）。这些庞然大物虽然性能强大，但也带来了两个严峻的挑战：\n",
    "\n",
    "1. **巨大的存储开销**：模型参数通常使用32位浮点数（FP32）存储，一个参数就需要4个字节。一个百亿参数的模型，仅存储就需要几十GB的内存/显存，远超普通消费级硬件的承载能力。\n",
    "\n",
    "2. **高昂的计算成本**：浮点数运算比整数运算要慢得多，尤其是在GPU这类并行计算设备上。\n",
    "\n",
    "模型量化就是为了解决这些问题而提出的一种关键技术，其核心思想是**通过降低模型参数的数值精度，来达到压缩模型体积和加速计算的目的**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 什么是模型量化？\n",
    "\n",
    "简单来说，模型量化就是把\"高精度\"的数值转换成\"低精度\"的数值。\n",
    "\n",
    "想象你在画一幅画，你有一盒32色的彩色铅笔（FP32），可以画出非常细腻的色彩变化。但如果你只用8色的彩色铅笔（INT8），虽然画出来的效果会略有差别，但大体上还是能保持原画的主要特征，而且你的工具箱会轻便很多，画画的速度也会更快。\n",
    "\n",
    "在深度学习中：\n",
    "- **原始模型**：使用32位浮点数（FP32）存储每个参数，精度很高但占用空间大\n",
    "- **量化模型**：使用8位整数（INT8）或更低精度存储参数，占用空间小但可能略有精度损失"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型量化为我们带来了显著的收益。然而，这种收益并非没有代价，量化本身也伴随着一系列严峻的技术挑战。\n",
    "\n",
    "**量化带来的核心优势**\n",
    "\n",
    "| **具体内容**            | **影响**                                               |\n",
    "| ----------------------- | ------------------------------------------------------------ |\n",
    "| **显存占用显著减少** | 1. **FP32 → INT8**：体积和显存占用减少约 **75%**。<br> 2. **FP32 → INT4**：体积和显存占用减少约 **87.5%**。 |\n",
    "| **计算速度大幅提升** | 整数运算（INT）比浮点运算（FP）快，且可利用硬件的专用计算单元，从而缩短推理时间。 |\n",
    "| **部署成本大幅降低** | 无需昂贵的专业级GPU，使得大模型可以在更普及、更便宜的硬件上运行，推动了AI技术的普及。 |\n",
    "| **能耗显著降低**     | 计算量和数据移动量的减少带来了更低的功耗，非常适合对能耗敏感的移动设备和边缘计算场景。 |\n",
    "\n",
    "**量化面临的核心挑战**\n",
    "\n",
    "| **具体内容**            | **影响**                                               |\n",
    "| ----------------------- | ------------------------------------------------------------ |\n",
    "| **精度损失**         | 低精度无法完全表示原始高精度数值，必然会造成一定的信息丢失，可能影响模型性能。 |\n",
    "| **量化误差累积**     | 在层数很深的网络中，每一层产生的微小误差可能会逐层传递并放大，最终影响模型的整体准确性。 |\n",
    "| **校准复杂性**       | 需要通过复杂的算法和代表性数据来确定最佳的量化参数（如缩放因子），以最小化精度损失，这是一个技术难点。 |\n",
    "| **硬件兼容性**       | 并非所有硬件（尤其是旧款或低端硬件）都对低精度整数运算（如INT4/INT8）提供高效的原生支持。 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.5.2 8比特量化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8比特量化是当前大语言模型领域中应用最广泛、最成熟的模型压缩技术之一。其核心目标是将模型中常用的32位浮点数（FP32）参数转换为8位整数（INT8）。这一转换能够在几乎不影响模型预测精度的前提下，将模型大小锐减约75%，并显著提升推理速度，从而使得在消费级GPU等资源受限设备上部署和运行大规模模型成为可能。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **8比特量化的基本原理**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8比特量化是一种将高精度浮点（FP32）张量线性映射到8位整数（INT8）区间的技术，其核心是仿射变换。这一过程由缩放因子 (S) 和零点 (Z) 两个参数定义，它们分别控制映射的比例和偏移。\n",
    "\n",
    "其数学表示如下：\n",
    "\n",
    "- 量化 (Quantization): `INT8_value = round(FP32_value / S + Z)`\n",
    "\n",
    "- 反量化 (Dequantization): `FP32_value_restored = (INT8_value - Z) * S`\n",
    "\n",
    "根据零点 (Z) 的设定，量化分为两种模式：\n",
    "\n",
    "1. 对称量化 (Symmetric):\n",
    "\n",
    "   - 特点： 假设数据分布关于0对称，强制 Z=0。\n",
    "\n",
    "   - 优劣： 计算更简单高效，但可能因无法完全利用数值范围而损失精度。\n",
    "\n",
    "2. 非对称量化 (Asymmetric):\n",
    "\n",
    "   - 特点： 不对数据分布做假设，Z 是一个可学习或计算出的浮点数。\n",
    "\n",
    "   - 优劣： 能充分利用整个INT8范围（[-128, 127]），通常精度更高，但计算稍复杂。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **8比特量化的实际应用**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设我们的量化目标是张量 `[-1.95, 0, 5.47, -7.59, 10.8, 3.08, -4.57]`。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**对称量化示例**\n",
    "\n",
    "对称量化的核心思想是，将一个可能不对称的浮点数范围，强制扩展为一个关于零点对称的范围，然后再进行线性映射。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.确定原始数据范围与目标**\n",
    "\n",
    "我们的目标是将张量 `[-1.95, 0, 5.47, -7.59, 10.8, 3.08, -4.57]` 量化到8位有符号整数（INT8）的 `[-127, 127]` 区间内。\n",
    "\n",
    "**2.寻找绝对值最大值并对称化**\n",
    "\n",
    "为了进行对称量化，我们必须找到原始数据中的绝对值最大值，并以此来定义一个全新的、关于原点0对称的范围。\n",
    "\n",
    "- `max(abs(-7.59), abs(10.8)) = 10.8`\n",
    "- 因此，我们将量化的有效范围从 `[-7.59, 10.8]` 扩展为 `[-10.8, 10.8]`。这正是图片顶部数轴所展示的范围。\n",
    "\n",
    "**3.计算量化参数**\n",
    "\n",
    "在对称量化模式下，参数定义如下：\n",
    "\n",
    "- **零点 (Zero-Point, Z)**: 强制为 `Z = 0`。\n",
    "\n",
    "- **缩放因子 (Scale, S)**: $S = \\frac{浮点数范围的绝对值上限}{整数范围的上限} = \\frac{10.8}{127} ≈ 0.085039$\n",
    "\n",
    "**4.应用量化公式**\n",
    "\n",
    "我们使用量化公式 `Quantized_Value = round(Original_Value / S)` 来计算映射关系：\n",
    "\n",
    "- 对于 10.8：\n",
    "   `round(10.8 / 0.085039) = round(127.0) = 127`\n",
    "- 对于 -7.59：\n",
    "   `round(-7.59 / 0.085039) = round(-89.25) = -89`\n",
    "- 对于 3.08：\n",
    "   `round(3.08 / 0.085039) = round(36.21) = 36`\n",
    "- ......\n",
    "\n",
    "对称量化的主要代价在于，为了覆盖 `10.8` 这个值，我们不得不将整个映射范围扩展到 `[-10.8, 10.8]`。这意味着，在原始数据中并不存在的 `[-10.8, -7.59]` 这段负值区间，同样占用了宝贵的量化格子（即 `[-127, -89]` 这一段），从而可能导致数据更密集区域的精度损失。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure style=\"text-align: center;\">\n",
    "    <img src=\"./png_chap10/quan1.png\">\n",
    "    <figcaption style=\"font-size: 0.9em; margin-top: 8px;\">\n",
    "    图3：对称量化结果示意图\n",
    "  </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**非对称量化示例**\n",
    "\n",
    "非对称量化的核心优势在于，它能够精确地利用整个数值范围，无需像对称量化那样进行范围扩展，从而通常能保留更多精度。\n",
    "\n",
    "**1.确定原始数据范围与目标**\n",
    "\n",
    "我们处理的依然是数值范围为 `[-7.59, 10.8]` 的权重张量。目标是将其量化到8位有符号整数（INT8）的 `[-128, 127]` 区间内。\n",
    "\n",
    "- `FP32_min = -7.59`\n",
    "- `FP32_max = 10.8`\n",
    "- `INT8_min = -128`\n",
    "- `INT8_max = 127`\n",
    "\n",
    "**2.计算量化参数 (缩放因子 S 和 零点 Z)**\n",
    "\n",
    "在非对称量化模式下，我们需要同时计算S和Z，以确保浮点数的0点能准确地映射到整数的某个零点上。\n",
    "\n",
    "- **缩放因子**：\n",
    "   $ S = \\frac{\\texttt{FP32\\_max} - \\texttt{FP32\\_min}}{\\texttt{INT8\\_max} - \\texttt{INT8\\_min}} = \\frac{10.8 - (-7.59)}{127 - (-128)} = \\frac{18.39}{255} ≈ 0.072117 $\n",
    "- **零点**：零点是一个整数，用于确保真实的0.0被正确映射\n",
    "\n",
    "   $ Z = round(\\texttt{INT8\\_max} - \\frac{\\texttt{FP32\\_max}}{S}) = round(127 - \\frac{10.8}{0.072117}) ≈ round(-22.7) = -23 $\n",
    "\n",
    "   - 零点-23意味着，浮点数0.0将被映射为整数-23。\n",
    "\n",
    "**3.应用量化公式**\n",
    "\n",
    "我们使用量化公式 `Quantized_Value = round(Original_Value / S + Z)` 来计算映射关系：\n",
    "\n",
    "- 对于 10.8：\n",
    "   `round(10.8 / 0.072117 - 23) = round(149.75 - 23) = round(126.75) = 127`\n",
    "- 对于 -7.59：\n",
    "   `round(-7.59 / 0.072117 - 23) = round(-105.24 - 23) = round(-128.24) = -128`\n",
    "- 对于 3.08：\n",
    "   `round(3.08 / 0.072117 - 23) = round(42.7 - 23) = round(19.7) = 20`\n",
    "- ......\n",
    "\n",
    "非对称量化通过引入一个非零的“零点”（Z=-23），使得原始浮点数范围 `[-7.59, 10.8]` 可以被“严丝合缝”地映射到 `[-128, 127]` 的完整整数区间内。这种方式充分利用了每一个量化级别，避免了范围浪费，因此通常能达到比对称量化更高的精度，但代价是反量化时需要额外的一次减法运算，计算稍复杂。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure style=\"text-align: center;\">\n",
    "    <img src=\"./png_chap10/quan2.png\">\n",
    "    <figcaption style=\"font-size: 0.9em; margin-top: 8px;\">\n",
    "    图4：非对称量化结果示意图\n",
    "  </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **8比特量化的适用场景分析**\n",
    "\n",
    "8比特量化作为一项关键的优化技术，在不同场景下的适用性与效益差异显著。下表对主要应用场景进行了汇总与评估：\n",
    "\n",
    "| 场景           | 推荐指数         | 核心原因说明                                               |\n",
    "| ------------------ | ---------------- | ------------------------------------------------------------ |\n",
    "| **模型推理部署**   | 推荐 | 这是量化最主要的应用领域。能显著降低生产环境中的显存占用、提升推理速度，从而降低服务成本。 |\n",
    "| **资源受限环境**   | 推荐 | 使得大模型能够在消费级GPU、边缘设备或移动端上运行，极大地拓宽了AI应用的部署范围。 |\n",
    "| **超大模型加载**   | 推荐 | 即使不进行推理，仅加载一个巨大的模型（如用于研究或演示），量化也能大幅降低对内存/显存的基本要求。 |\n",
    "| **模型训练过程**   | 不推荐 | 训练阶段需要通过精确的梯度进行权重更新，低精度量化会干扰这一过程，通常仅在特定技术（如QLoRA）中应用。 |\n",
    "| **高精度科研计算** | 不推荐 | 在物理模拟、金融建模等对数值精度要求达到极致的领域，量化引入的微小误差是不可接受的。 |\n",
    "| **小型模型优化**   | 谨慎使用 | 对于参数量本就很小的模型（如几百万、几千万），量化带来的性能提升和资源节省可能有限，收益不明显。 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **8比特量化的效果展示**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 模型规模 | FP32内存 | INT8内存 | 精度损失 | 推理速度提升 |\n",
    "|---------|---------|---------|----------|-------------|\n",
    "| 7B参数 | 28GB | 7GB | <0.5% | 1.8倍 |\n",
    "| 13B参数 | 52GB | 13GB | <0.3% | 1.9倍 |\n",
    "| 70B参数 | 280GB | 70GB | <0.2% | 2.1倍 |\n",
    "\n",
    "通过这些数据可以看出，8比特量化在大模型上的效果尤其显著，既大幅减少了内存需求，又提升了推理速度，且精度损失微乎其微。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.5.3 4比特量化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4比特量化是更加激进的量化方案，将32位浮点数（FP32）压缩到仅4位整数，可以将模型大小减少87.5%，让30B甚至70B参数的模型都能在单张消费级GPU上运行和微调。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **4比特量化的基本原理**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一个32位浮点数能表示超过40亿个不同的值，而4位整数只能表示 $2^4 = 16$ 个不同的值。因此，4比特量化的首要任务是建立一个从“几乎无限”到“16”的映射规则。\n",
    "\n",
    "这个过程分为两步：\n",
    "- 定义“量化表”：首先，选择16个浮点数作为代表（也称为“量化级别”）。这16个值就是所有原始FP32数值最终的归宿。\n",
    "- 寻找最近邻：对于任何一个原始的FP32权重，计算它与量化表中16个代表值的距离，并将其映射到距离最近的那个代表值上。\n",
    "\n",
    "而在存储时，我们不再存储原始的FP32值，而是存储那个代表值在量化表中的索引（一个从0到15的整数，正好可以用4位二进制表示）。\n",
    "\n",
    "现在的问题在于，我们应该如何定义“量化表”，寻找这16个代表值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**先进原理：分位数量化**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "核心思想：我们不应该让量化点的间隔相等，而应该让每个量化点所代表的数据量（或概率）相等。\n",
    "\n",
    "具体做法：\n",
    "\n",
    "1. 分析权重的分布规律（一般是正态分布）\n",
    "2. 将量化点密集地分配在数据最集中的区域（0附近）\n",
    "3. 将量化点稀疏地分配在数据稀疏的区域（远离0的尾部）\n",
    "\n",
    "**NF4** 就是基于标准正态分布 N(0,1) 计算出的一套理论上最优的16个非均匀量化点。这确保了在压缩信息时，我们优先保全了对模型性能影响最大的那部分权重信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **4比特量化的实际应用**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**原始权重**：[0.45, -0.88, 1.54, -0.12, 0.05, 0.99, -0.33, -2.10]\n",
    "\n",
    "**NF4 量化表**：这是一个预先计算好的16个“最佳”量化点，它们被归一化到 [-1, 1] 范围内。每个点都有一个对应的4比特索引（0-15）\n",
    "\n",
    "| 4比特索引 (Index) | NF4 量化值 (Value) |\n",
    "| ----------------- | ------------------ |\n",
    "| `0000` (0)        | -1.0000            |\n",
    "| `0001` (1)        | -0.6962            |\n",
    "| `0010` (2)        | -0.5251            |\n",
    "| `0011` (3)        | -0.3949            |\n",
    "| `0100` (4)        | -0.2844            |\n",
    "| `0101` (5)        | -0.1848            |\n",
    "| `0110` (6)        | -0.0911            |\n",
    "| `0111` (7)        | -0.0027            |\n",
    "| `1000` (8)        | 0.0062             |\n",
    "| `1001` (9)        | 0.0955             |\n",
    "| `1010` (10)       | 0.1906             |\n",
    "| `1011` (11)       | 0.2923             |\n",
    "| `1100` (12)       | 0.4045             |\n",
    "| `1101` (13)       | 0.5286             |\n",
    "| `1110` (14)       | 0.6717             |\n",
    "| `1111` (15)       | 1.0000             |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面是具体的计算步骤：\n",
    "\n",
    "1. 计算缩放因子 S，将我们权重张量的范围映射到NF4量化表的 [-1, 1] 范围\n",
    "   - 计算张量中每个元素的绝对值：[0.45, 0.88, 1.54, 0.12, 0.05, 0.99, 0.33, 2.10]\n",
    "   - 找到最大值：2.10\n",
    "   - 因此，我们的缩放因子 S = 2.10\n",
    "\n",
    "2. 归一化权重，用每个原始权重除以缩放因子 S，得到归一化后的权重 $R_{norm} = \\frac{R}{S}$\n",
    "   - 0.45 / 2.10 = 0.214\n",
    "   - -0.88 / 2.10 = -0.419\n",
    "   - ......\n",
    "   - 由此我们得到归一化后的张量 $R_{norm}$：[0.214, -0.419, 0.733, -0.057, 0.024, 0.471, -0.157, -1.0]\n",
    "\n",
    "3. 映射到最近的 NF4 量化点\n",
    "   \n",
    "| 归一化值 | 最近的NF4值 | 对应的4比特索引 |\n",
    "| -------- | ----------- | --------------- |\n",
    "| 0.214    | 0.1906      | `1010` (10)     |\n",
    "| -0.419   | -0.3949     | `0011` (3)      |\n",
    "| 0.733    | 0.6717      | `1110` (14)     |\n",
    "| -0.057   | -0.0911     | `0110` (6)      |\n",
    "| 0.024    | 0.0062      | `1000` (8)      |\n",
    "| 0.471    | 0.4045      | `1100` (12)     |\n",
    "| -0.157   | -0.1848     | `0101` (5)      |\n",
    "| -1.0     | -1.0000     | `0000` (0)      |\n",
    "\n",
    "4. 存储结果，经过量化，我们最终需要存储两样东西：\n",
    "   - 4比特索引数组：[10, 3, 14, 6, 8, 12, 5, 0]\n",
    "   - 缩放因子 S：2.10（用FP32存储）\n",
    "   \n",
    "   这个块的原始内存占用是 8\\*32位=256位，现在是 8\\*4位 + 32位=64位。内存压缩了 75%。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**反量化（NF4 -> FP32）步骤**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 读取索引和缩放因子\n",
    "   - 我们从内存中读取之前存储的索引数组和缩放因子 S=2.10\n",
    "\n",
    "2. 从量化表恢复归一化值：使用索引去NF4量化表中查找对应的浮点值\n",
    "   - 10 -> 0.1906\n",
    "   - 3 -> -0.3949\n",
    "   - ...\n",
    "   - 由此得到恢复的归一化张量 $R^{'}_{norm}$：[0.1906, -0.3949, 0.6717, -0.0911, 0.0062, 0.4045, -0.1848, -1.0]\n",
    "\n",
    "3. 乘以缩放因子恢复权重：将恢复的归一化值乘以缩放因子 S，得到最终的反量化权重 $R'$\n",
    "   - $R' = R'_{norm} S$\n",
    "   - 0.1906 * 2.10 = 0.400\n",
    "   - -0.3949 * 2.10 = -0.829\n",
    "   - ...\n",
    "   - 最终得到 $R'$：[0.400, -0.829, 1.411, -0.191, 0.013, 0.849, -0.388, -2.10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**比较原始值和恢复值**\n",
    "\n",
    "| 原始值 (FP32) | 恢复值 (FP32) | 量化误差 |\n",
    "| ------------- | ------------- | -------- |\n",
    "| 0.45          | 0.400         | -0.050   |\n",
    "| -0.88         | -0.829        | +0.051   |\n",
    "| 1.54          | 1.411         | -0.129   |\n",
    "| -0.12         | -0.191        | -0.071   |\n",
    "| 0.05          | 0.013         | -0.037   |\n",
    "| 0.99          | 0.849         | -0.141   |\n",
    "| -0.33         | -0.388        | -0.058   |\n",
    "| -2.10         | -2.10         | 0.000    |\n",
    "\n",
    "可以看到，恢复的值与原始值非常接近，但存在一定的量化误差。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **拓展：双重量化**\n",
    "\n",
    "在上面的例子中，我们为这8个权重存储了一个FP32的缩放因子 2.10。\n",
    "\n",
    "现在想象一个大模型，它有 10亿个权重块。那么我们就需要存储 10亿个FP32缩放因子，这本身就会占用 10亿 * 32位 / 8 = 4 GB 的显存！\n",
    "\n",
    "双重量化就是为了解决这个问题：\n",
    "1. 我们收集所有的缩放因子，形成一个新的张量：S_list = [2.10, 1.85, 2.55, 1.98, ...]\n",
    "2. 我们对这个 S_list 张量本身再进行一次量化。比如，将它们量化成8位浮点数（FP8）。\n",
    "3. 这次量化同样会产生一个“二阶”的缩放因子（S_of_S）。\n",
    "4. 最终，我们存储的是大量的8位量化后的缩放因子，以及极少数的二阶FP32缩放因子。\n",
    "\n",
    "通过这种方式，存储量化参数的开销也被极大压缩，实现更深层的优化。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **性能对比表**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 量化方式 | 内存占用 | 精度损失 | 推理速度 | 适用场景 |\n",
    "|---------|---------|----------|----------|----------|\n",
    "| FP32 | 100% | 0% | 1x | 高精度要求 |\n",
    "| FP16 | 50% | <0.1% | 1.5x | 平衡性能 |\n",
    "| INT8 | 25% | <0.5% | 2x | 主流部署 |\n",
    "| NF4 | 12.5% | 1-3% | 2.5x | 极限压缩 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **实际应用建议**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **开始时使用8比特**：对于大多数应用，8比特量化是很好的平衡点\n",
    "2. **内存不足时考虑4比特**：当8比特仍然超出内存限制时，再考虑4比特\n",
    "3. **微调优先NF4**：如果需要微调，NF4+QLoRA是目前最佳方案\n",
    "4. **关注精度变化**：部署前一定要测试量化后的模型精度\n",
    "\n",
    "通过4比特量化，我们可以让原本需要8张A100才能运行的70B模型，在单张24GB的RTX 4090上就能运行，这极大地降低了大模型的使用门槛。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.5.4 动态 vs 静态量化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型量化主要有两种执行策略：静态量化（Static Quantization）和动态量化（Dynamic Quantization）。它们的核心区别在于何时以及如何计算用于量化的缩放因子（S）和零点（Z）等参数，这直接决定了它们在性能、精度和易用性上的不同取舍。我们先看看他们的核心流程。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**核心流程概览**\n",
    "\n",
    "**静态量化：三步走**\n",
    "\n",
    "1. **校准 (Offline)**：在一个小的代表性数据集上运行FP32模型，记录激活值的统计分布，并计算出固定的量化参数（S和Z）。\n",
    "\n",
    "2. **转换 (Offline)**: 使用计算出的参数，将模型的权重和激活值的处理方式永久转换为INT8格式，生成最终的量化模型。\n",
    "\n",
    "3. **推理 (Online)**: 加载已完全量化的模型直接运行，无任何额外开销。\n",
    "\n",
    "**动态量化：边算边转**\n",
    "\n",
    "1. **准备 (Offline)**: 仅将模型中固定不变的权重预先量化为INT8。\n",
    "\n",
    "2. **推理 (Online)**:\n",
    "\n",
    "   - 激活值以FP32格式在层间流动。\n",
    "\n",
    "   - 在执行每个计算前，实时分析当前激活值的范围（min, max）。\n",
    "\n",
    "   - 为这批激活值动态计算出量化参数，并将其转换为INT8。\n",
    "\n",
    "   - 执行计算后，结果通常被反量化回FP32，以供下一层使用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**核心差异对比**\n",
    "\n",
    "| 对比维度 | 静态量化 (Static Quantization) | 动态量化 (Dynamic Quantization) |\n",
    "| :--- | :--- | :--- |\n",
    "| **核心思想** | **离线校准，在线推理** | **在线实时计算** |\n",
    "| **参数计算时机** | **部署前**，通过校准数据集预先计算并固定所有量化参数。 | **推理时**，实时计算激活值的量化参数；权重参数是预先量化的。 |\n",
    "| **数据依赖** | **高度依赖**一个有代表性的“校准数据集”。 | **完全不依赖**外部校准数据。 |\n",
    "| **推理性能** | **极高**。无任何实时计算开销，是**速度最快**的量化方式。 | **较低**。需要实时计算激活值的量化参数，带来额外延迟。 |\n",
    "| **精度与泛化性** | 精度受校准集质量影响，对未知数据分布可能表现不佳。 | 精度通常**更高、更鲁棒**，能自适应不同的输入数据。 |\n",
    "| **部署复杂度** | 较高，需要额外的数据准备和校准步骤。 | **极低**，可“即插即用”地应用于预训练模型。 |\n",
    "| **适用场景** | 对延迟极度敏感、输入数据分布稳定的生产环境。 | 快速验证量化效果、输入数据分布多变的场景。 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "简单来说，选择哪种策略是一个典型的权衡：\n",
    "\n",
    "- **静态量化**：用**前期复杂的校准工作**换取极致的推理性能。\n",
    "\n",
    "- **动态量化**：用**推理时的一点性能开销**换取最高的易用性和精度鲁棒性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **两种策略的直观对比**\n",
    "\n",
    "| 对比维度 | 静态量化 (Static) | 动态量化 (Dynamic) |\n",
    "| :--- | :--- | :--- |\n",
    "| **量化时机** | **部署前** (Offline) | **推理时** (Online/Runtime) |\n",
    "| **校准数据** | **必需** | **无需** |\n",
    "| **推理速度** | **极致性能** (无运行时开销) | **较高性能** (有运行时开销) |\n",
    "| **内存带宽** | **最低** (INT8计算) | **中等** (FP32激活值传输) |\n",
    "| **精度鲁棒性** | 依赖校准质量 | **通常更高**，对数据分布不敏感 |\n",
    "| **部署复杂度**| **中等** (需要校准步骤) | **简单** (即插即用) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.6 实战：LoRA微调结合模型量化\n",
    "\n",
    "在本节中，我们将演示一个综合示例：对Qwen 7B模型应用LoRA微调，之后再进行 8-bit 量化。并提供代码运行结果展示以下现象：\n",
    "\n",
    "1. 经过LoRA微调后，模型特定领域能力上升\n",
    "2. 量化后的模型在推理时显存占用明显降低\n",
    "3. 量化后模型能力略有下降，但推理速度上升"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "#### 10.6.1 对Qwen/Qwen2.5-7B-Instruct模型应用LoRA微调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初始GPU内存: 0.00 GB\n",
      "初始CPU内存: 1.58 GB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import psutil\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import LoraConfig, TaskType, get_peft_model, PeftModel\n",
    "import gc\n",
    "\n",
    "# 获取GPU内存使用情况的辅助函数\n",
    "def get_gpu_memory():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.cuda.memory_allocated() / 1024**3  # 转换为GB\n",
    "    return 0\n",
    "\n",
    "# 获取CPU内存使用情况\n",
    "def get_cpu_memory():\n",
    "    return psutil.Process().memory_info().rss / 1024**3  # 转换为GB\n",
    "\n",
    "print(f\"初始GPU内存: {get_gpu_memory():.2f} GB\")\n",
    "print(f\"初始CPU内存: {get_cpu_memory():.2f} GB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**加载模型和分词器**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/lora/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型加载完成!\n",
      "模型参数量: 7,615,616,512\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_name = \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name, \n",
    "    torch_dtype=torch.float32, \n",
    "    trust_remote_code=True\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "print(f\"模型加载完成!\")\n",
    "print(f\"模型参数量: {model.num_parameters():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**加载数据集**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集加载完成\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "df = pd.read_json('./dataset_chap10/huanhuan.json')\n",
    "ds = Dataset.from_pandas(df)\n",
    "\n",
    "print(\"数据集加载完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**定义数据处理函数**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_func(example):\n",
    "    MAX_LENGTH = 512\n",
    "\n",
    "    instruction_part = f\"<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>user\\n{example['instruction'] + example['input']}<|im_end|>\\n<|im_start|>assistant\\n\"\n",
    "    response_part = f\"{example['output']}<|im_end|>\"\n",
    "\n",
    "    instruction_ids = tokenizer(instruction_part, add_special_tokens=False)[\"input_ids\"]\n",
    "    response_ids = tokenizer(response_part, add_special_tokens=False)[\"input_ids\"]\n",
    "\n",
    "    input_ids = instruction_ids + response_ids\n",
    "    labels = [-100] * len(instruction_ids) + response_ids\n",
    "\n",
    "    if len(input_ids) > MAX_LENGTH:\n",
    "        input_ids = input_ids[:MAX_LENGTH]\n",
    "        labels = labels[:MAX_LENGTH]\n",
    "\n",
    "    # 手动构建 attention_mask\n",
    "    attention_mask = [1] * len(input_ids)\n",
    "\n",
    "    # 填充到 MAX_LENGTH\n",
    "    padding_len = MAX_LENGTH - len(input_ids)\n",
    "    input_ids += [tokenizer.pad_token_id] * padding_len\n",
    "    labels += [-100] * padding_len # label 的填充值也必须是 -100\n",
    "    attention_mask += [0] * padding_len\n",
    "    \n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"labels\": labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3729/3729 [00:01<00:00, 2754.97 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# 预处理数据集\n",
    "\n",
    "tokenized_id = ds.map(process_func, remove_columns=ds.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 5,046,272 || all params: 7,620,662,784 || trainable%: 0.0662\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "# 定义LoRA配置\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"],\n",
    "    inference_mode=False,\n",
    "    r=8,   # LoRA的秩\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    ")\n",
    "\n",
    "# 将基础模型转换为LoRA模型\n",
    "lora_model = get_peft_model(model, lora_config)\n",
    "\n",
    "# 打印可训练参数详情\n",
    "lora_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始LoRA微调...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='699' max='699' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [699/699 2:17:00, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.502800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.079000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>3.027100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.001100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>3.012600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.881100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>2.875100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.856100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>2.884300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.816300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>2.797400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.772200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>2.784300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/lora/lib/python3.10/site-packages/peft/utils/other.py:1110: UserWarning: Unable to fetch remote file due to the following error 401 Client Error: Unauthorized for url: https://hf-mirror.com/Qwen/Qwen2.5-7B-Instruct/resolve/main/config.json (Request ID: Root=1-686e0a01-0f83284975611e311f2f2716;d8ce5793-0263-489f-a282-df6abbd5ebdd)\n",
      "\n",
      "Invalid credentials in Authorization header - silently ignoring the lookup for the file config.json in Qwen/Qwen2.5-7B-Instruct.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/lora/lib/python3.10/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in Qwen/Qwen2.5-7B-Instruct - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/lora/lib/python3.10/site-packages/peft/utils/other.py:1110: UserWarning: Unable to fetch remote file due to the following error 401 Client Error: Unauthorized for url: https://hf-mirror.com/Qwen/Qwen2.5-7B-Instruct/resolve/main/config.json (Request ID: Root=1-686e0e9b-688d58d234a80bc55d4e2ad3;9971a418-5673-4530-9d44-189de48efbcf)\n",
      "\n",
      "Invalid credentials in Authorization header - silently ignoring the lookup for the file config.json in Qwen/Qwen2.5-7B-Instruct.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/lora/lib/python3.10/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in Qwen/Qwen2.5-7B-Instruct - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/lora/lib/python3.10/site-packages/peft/utils/other.py:1110: UserWarning: Unable to fetch remote file due to the following error 401 Client Error: Unauthorized for url: https://hf-mirror.com/Qwen/Qwen2.5-7B-Instruct/resolve/main/config.json (Request ID: Root=1-686e1334-647529ff28f86f1f7dd86786;beb87fd3-5119-46ac-aba0-45308f59bd4a)\n",
      "\n",
      "Invalid credentials in Authorization header - silently ignoring the lookup for the file config.json in Qwen/Qwen2.5-7B-Instruct.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/lora/lib/python3.10/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in Qwen/Qwen2.5-7B-Instruct - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/lora/lib/python3.10/site-packages/peft/utils/other.py:1110: UserWarning: Unable to fetch remote file due to the following error 401 Client Error: Unauthorized for url: https://hf-mirror.com/Qwen/Qwen2.5-7B-Instruct/resolve/main/config.json (Request ID: Root=1-686e17ce-67923d2d676a959e3faf726f;c9818d51-a7f0-494b-8c6e-74dee061abc7)\n",
      "\n",
      "Invalid credentials in Authorization header - silently ignoring the lookup for the file config.json in Qwen/Qwen2.5-7B-Instruct.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/lora/lib/python3.10/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in Qwen/Qwen2.5-7B-Instruct - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/lora/lib/python3.10/site-packages/peft/utils/other.py:1110: UserWarning: Unable to fetch remote file due to the following error 401 Client Error: Unauthorized for url: https://hf-mirror.com/Qwen/Qwen2.5-7B-Instruct/resolve/main/config.json (Request ID: Root=1-686e1c66-0e950f6569f9659e4d475fb7;74e6ee7b-880e-48fa-820d-612eb6f99dc6)\n",
      "\n",
      "Invalid credentials in Authorization header - silently ignoring the lookup for the file config.json in Qwen/Qwen2.5-7B-Instruct.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/lora/lib/python3.10/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in Qwen/Qwen2.5-7B-Instruct - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/lora/lib/python3.10/site-packages/peft/utils/other.py:1110: UserWarning: Unable to fetch remote file due to the following error 401 Client Error: Unauthorized for url: https://hf-mirror.com/Qwen/Qwen2.5-7B-Instruct/resolve/main/config.json (Request ID: Root=1-686e2101-197c06084c0134f73e55491c;58099cc9-6324-4658-8534-8ffe8aabc2e0)\n",
      "\n",
      "Invalid credentials in Authorization header - silently ignoring the lookup for the file config.json in Qwen/Qwen2.5-7B-Instruct.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/lora/lib/python3.10/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in Qwen/Qwen2.5-7B-Instruct - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/lora/lib/python3.10/site-packages/peft/utils/other.py:1110: UserWarning: Unable to fetch remote file due to the following error 401 Client Error: Unauthorized for url: https://hf-mirror.com/Qwen/Qwen2.5-7B-Instruct/resolve/main/config.json (Request ID: Root=1-686e258f-1988c7fc50cf884430085e3a;58ff9891-5c83-4fa4-8624-c9d7228616a0)\n",
      "\n",
      "Invalid credentials in Authorization header - silently ignoring the lookup for the file config.json in Qwen/Qwen2.5-7B-Instruct.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/lora/lib/python3.10/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in Qwen/Qwen2.5-7B-Instruct - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "微调完成! 耗时: 8232.58 秒\n",
      "训练后GPU内存: 28.57 GB\n",
      "训练后CPU内存: 4.35 GB\n",
      "LoRA权重已保存!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/lora/lib/python3.10/site-packages/peft/utils/other.py:1110: UserWarning: Unable to fetch remote file due to the following error 401 Client Error: Unauthorized for url: https://hf-mirror.com/Qwen/Qwen2.5-7B-Instruct/resolve/main/config.json (Request ID: Root=1-686e2590-28db2f2c7928a1b36eb8e0dc;a58ad2e2-e8e8-4e81-92ad-3690ae98256a)\n",
      "\n",
      "Invalid credentials in Authorization header - silently ignoring the lookup for the file config.json in Qwen/Qwen2.5-7B-Instruct.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/lora/lib/python3.10/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in Qwen/Qwen2.5-7B-Instruct - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments, DataCollatorForSeq2Seq\n",
    "\n",
    "### LoRA微调训练\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"./7b_results\",\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    logging_steps=50,\n",
    "    num_train_epochs=3,\n",
    "    save_steps=100,\n",
    "    learning_rate=1e-4,\n",
    "    save_on_each_node=True,\n",
    "    gradient_checkpointing=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=lora_model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_id,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer, padding=True),\n",
    ")\n",
    "\n",
    "print(\"开始LoRA微调...\")\n",
    "start_time = time.time()\n",
    "trainer.train()\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "print(f\"微调完成! 耗时: {training_time:.2f} 秒\")\n",
    "\n",
    "# 保存LoRA权重\n",
    "lora_model.save_pretrained(\"./lora_7b_weights\")\n",
    "print(\"LoRA权重已保存!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "#### 10.6.2 对微调后模型进行 8-bit 量化\n",
    "\n",
    "在本小节中，我们将实现8-bit量化模型。由于 `torch.ao.quantization.quantize_dynamic` 量化后的模型通常只能在CPU上运行，无法在NVIDIA显卡上获得加速，因此量化全过程在cpu上进行。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**首先，我们加载原始模型**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/lora/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型加载完成!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "model_name = \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name, \n",
    "    torch_dtype=torch.float32, \n",
    "    trust_remote_code=True\n",
    ")\n",
    "base_model.to(device)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "print(f\"模型加载完成!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**将微调得到的LoRA参数加载到原始模型中**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "import copy\n",
    "\n",
    "copied_base_model = copy.deepcopy(base_model)\n",
    "lora_model = PeftModel.from_pretrained(copied_base_model, \"./lora_7b_weights\")\n",
    "\n",
    "# 合并LoRA权重，将lora模型的架构恢复到原始模型状态，以便进行量化操作\n",
    "unlora_model = lora_model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**由于当前实验环境未配备NVIDIA GPU，我们无法采用依赖CUDA的bitsandbytes库。因此，我们选择使用PyTorch原生的torch.ao.quantization模块来完成模型的8位量化。**\n",
    "\n",
    "在这之前让我们先介绍一下 `qconfig_spec` 参数：\n",
    "- 作用：精确地告诉 `qconfig_spec` 函数要对哪些类型的层进行量化\n",
    "- 格式：它的值是一个集合或字典\n",
    "\n",
    "在很多大语言模型和 Transformer 架构中，Linear 层占据了绝大部分的参数量和计算量，所以量化Linear层就能获得显著的模型压缩效果和性能提升。在量化Linear层时，模型中其他类型的层，例如 `torch.nn.Embedding`, `torch.nn.LayerNorm`, `torch.nn.Conv2d`将保持不变，继续用浮点数计算。\n",
    "\n",
    "量化模型代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_int8 = torch.ao.quantization.quantize_dynamic(\n",
    "    unlora_model,\n",
    "    qconfig_spec={torch.nn.Linear},\n",
    "    dtype=torch.qint8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.6.3 LoRA微调和模型量化的效果展示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们先定义一个推理性能测试函数，其主要功能是评估模型在处理一系列标准提示词时的平均推理耗时和静态存储空间占用情况，以量化其运行性能。\n",
    "\n",
    "其中 `model` 代表需要测试的模型，`max_new_tokens` 表示模型生成的最大新token数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def test_model_inference(model, tokenizer, model_name=\"Model\", max_new_tokens=512):\n",
    "    \"\"\"\n",
    "    测试CPU模型的推理性能，包括平均推理时间。\n",
    "    \n",
    "    Args:\n",
    "        model (torch.nn.Module): 需要测试的CPU模型。\n",
    "        tokenizer: 模型对应的Tokenizer。\n",
    "        model_name (str): 用于打印输出的模型名称。\n",
    "        max_new_tokens (int): 模型生成的最大新token数。\n",
    "        \n",
    "    Returns:\n",
    "        dict: 包含平均推理时间和RAM占用信息的字典。\n",
    "    \"\"\"\n",
    "\n",
    "    test_prompts = [\n",
    "        \"你是谁？\",\n",
    "        \"你住在哪里？\", \n",
    "        \"你最喜欢什么？\",\n",
    "        \"你今天心情如何？\"\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\\\n--- {model_name} 推理测试 ---\")\n",
    "    \n",
    "    total_time = 0\n",
    "    for i, prompt in enumerate(test_prompts):\n",
    "        message = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "        \n",
    "        input_text = tokenizer.apply_chat_template(message, tokenize=False, add_generation_prompt=True)\n",
    "        inputs = tokenizer(input_text, return_tensors=\"pt\").to(model.device)\n",
    "        \n",
    "        # 测量推理时间\n",
    "        start_time = time.time()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                inputs.input_ids,\n",
    "                attention_mask=inputs.attention_mask,\n",
    "                max_new_tokens=max_new_tokens\n",
    "            )\n",
    "        inference_time = time.time() - start_time\n",
    "        total_time += inference_time\n",
    "        \n",
    "        # 解码输出\n",
    "        response = tokenizer.decode(outputs[0][inputs.input_ids.shape[1]:], skip_special_tokens=True)\n",
    "        \n",
    "        print(f\"问题 {i+1}: {prompt}\")\n",
    "        print(f\"回答: {response}\")\n",
    "        print(f\"推理时间: {inference_time:.3f}s\")\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    avg_time = total_time / len(test_prompts)\n",
    "    print(f\"平均推理时间: {avg_time:.3f}s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面分别让原始模型、LoRA模型、量化模型在 `max_new_tokens=512` 的设置下进行推理，比较其回答质量和平均推理时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\n--- 原始模型 推理测试 ---\n",
      "问题 1: 你是谁？\n",
      "回答: 我是阿里云开发的一款超大规模语言模型，我叫通义千问。\n",
      "推理时间: 5.166s\n",
      "--------------------------------------------------\n",
      "问题 2: 你住在哪里？\n",
      "回答: 作为一个AI模型，我没有具体的居住地。我是阿里云开发的大规模语言模型，可以运行在各种设备和平台上。\n",
      "推理时间: 11.482s\n",
      "--------------------------------------------------\n",
      "问题 3: 你最喜欢什么？\n",
      "回答: 作为一个AI模型，我没有个人喜好或情感。但我可以提供关于各种主题的信息、与用户进行对话，并帮助用户完成任务。如果你有任何问题或需要帮助，请随时告诉我！\n",
      "推理时间: 10.402s\n",
      "--------------------------------------------------\n",
      "问题 4: 你今天心情如何？\n",
      "回答: 作为人工智能，我没有情感和感受，但我随时准备帮助您！如果您有任何问题或需要帮助，请尽管告诉我。\n",
      "推理时间: 8.234s\n",
      "--------------------------------------------------\n",
      "平均推理时间: 8.821s\n"
     ]
    }
   ],
   "source": [
    "test_model_inference(base_model, tokenizer, \"原始模型\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\n--- LoRA Model 推理测试 ---\n",
      "问题 1: 你是谁？\n",
      "回答: 我是甄嬛，家父是大理寺少卿甄远道。\n",
      "推理时间: 4.663s\n",
      "--------------------------------------------------\n",
      "问题 2: 你住在哪里？\n",
      "回答: 臣妾是眉姐姐的陪嫁，住在眉姐姐的宫里。\n",
      "推理时间: 4.753s\n",
      "--------------------------------------------------\n",
      "问题 3: 你最喜欢什么？\n",
      "回答: 臣妾喜欢玉。\n",
      "推理时间: 1.885s\n",
      "--------------------------------------------------\n",
      "问题 4: 你今天心情如何？\n",
      "回答: 皇上，臣妾的肚子好疼。\n",
      "推理时间: 3.295s\n",
      "--------------------------------------------------\n",
      "平均推理时间: 3.649s\n"
     ]
    }
   ],
   "source": [
    "test_model_inference(lora_model, tokenizer, model_name=\"LoRA Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\n--- quantized_model 推理测试 ---\n",
      "问题 1: 你是谁？\n",
      "回答: ，眉眼如画，举止落落大方。嬛嬛，本宫向来不喜争宠之事，但本宫也不愿见你被外人欺辱。嬛嬛，本宫是后宫之主，自然不能让别人欺侮了你。嬛嬛，本宫答应你，本宫会好好照顾你的，不会让你受委屈的，可你一定要听本宫的话，不可再与那些人结怨，知道吗？嬛嬛，本宫是后宫之主，要懂得察言观色，学会做人，本宫希望你能明白。嬛嬛，本宫答应过你，本宫一定会好好照顾你的，本宫也一定会做到。嬛嬛，本宫答应过你，本宫一定会好好照顾你的，本宫也一定会做到。嬛嬛，本宫答应过你，本宫一定会好好照顾你的，本宫也一定会做到。嬛嬛，本宫答应过你，本宫一定会好好照顾你的，本宫也一定会做到。嬛嬛，本宫答应过你，本宫一定会好好照顾你的，本宫也一定会做到。嬛嬛，本宫答应过你，本宫一定会好好照顾你的，本宫也一定会做到。嬛嬛，本宫答应过你，本宫一定会好好照顾你的，本宫也一定会做到。嬛嬛，本宫答应过你，本宫一定会好好照顾你的，本宫也一定会做到。嬛嬛，本宫答应过你，本宫一定会好好照顾你的，本宫也一定会做到。嬛嬛，本宫答应过你，本宫一定会好好照顾你的，本宫也一定会做到。嬛嬛，本宫答应过你，本宫一定会好好照顾你的，本宫也一定会做到。嬛嬛，本宫答应过你，本宫一定会好好照顾你的，本宫也一定会做到。嬛嬛，本宫答应过你，本宫一定会好好照顾你的，本宫也一定会做到。嬛嬛，本宫答应过你，本宫一定会好好照顾你的，本宫也一定会做到。嬛嬛，本宫答应过你，本宫一定会好好照顾你的，本宫也一定会做到。嬛嬛，本宫答应过你，本宫一定会好好照顾你的，本宫也一定会做到。嬛嬛，本宫答应过你，本宫一定会好好照顾你的，本宫也一定会做到。嬛嬛，本宫答应过你，本宫一定会好好照顾\n",
      "推理时间: 50.227s\n",
      "--------------------------------------------------\n",
      "问题 2: 你住在哪里？\n",
      "回答: 在西宫。\n",
      "推理时间: 0.513s\n",
      "--------------------------------------------------\n",
      "问题 3: 你最喜欢什么？\n",
      "回答: 是吗，那好，我们来比一比，谁的字写得最漂亮。姐姐要来教妹妹写字了。姐姐来教妹妹，好吗？姐姐要教妹妹，就要先来学学妹妹喜欢的东西，来，先来学学妹妹喜欢的东西，好不好？妹妹，妹妹，来教姐姐呀！姐姐来学了，妹妹就来教教姐姐吧。姐姐，你看，这个“眉”字，上面是眉毛的眉，下面是耳朵的耳，这个“眉”是眉心的意思，妹妹，你瞧见了吗？眉心眉心，眉心就是眼睛中间的地方，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，眉心眉心，\n",
      "推理时间: 51.882s\n",
      "--------------------------------------------------\n",
      "问题 4: 你今天心情如何？\n",
      "回答: 皇上，臣妾与皇上情深意重，今日是臣妾的生辰，望皇上不要忘记臣妾。皇上，臣妾为皇上育有四子，可臣妾为皇上所生的第一位皇子，却在出生后被赐死，臣妾的心中怎忍得下这口恶气！皇上，请皇上为臣妾做主！皇上，皇上！皇上！嬛儿！嬛儿！嬛儿！嬛儿！嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛嬛\n",
      "推理时间: 48.131s\n",
      "--------------------------------------------------\n",
      "平均推理时间: 37.688s\n"
     ]
    }
   ],
   "source": [
    "test_model_inference(model_int8, tokenizer, model_name=\"quantized_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从模型的表现来看，微调带来了质的飞跃。原始基础模型由于未经特定优化，回答显得较为刻板通用；相比之下，经过数据集微调的LoRA及量化模型则成功地融入了“甄嬛”的独特语调，使对话更具个性。\n",
    "\n",
    "有趣的是，在推理速度上出现了一个悖论。理论上，量化模型应是最快的，但由于量化带来轻微的性能损失，模型输出了许多重复语句，反而拉长了总体耗时。同时，原始模型因未经微调，回答冗长，耗时也较多。\n",
    "\n",
    "显然，生成内容的长度和质量干扰了我们对模型真实速度的判断。为了更“公平”地比较它们的推理速度，我们将限制 `max_new_tokens=10` 进行下一轮测试。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\n--- 原始模型 推理测试 ---\n",
      "问题 1: 你是谁？\n",
      "回答: 我是阿里云开发的一款超大规模语言模型，\n",
      "推理时间: 3.021s\n",
      "--------------------------------------------------\n",
      "问题 2: 你住在哪里？\n",
      "回答: 作为一个AI模型，我没有具体的居住地。我\n",
      "推理时间: 3.036s\n",
      "--------------------------------------------------\n",
      "问题 3: 你最喜欢什么？\n",
      "回答: 作为一个人工智能模型，我没有情感和个人偏好\n",
      "推理时间: 2.778s\n",
      "--------------------------------------------------\n",
      "问题 4: 你今天心情如何？\n",
      "回答: 作为人工智能，我没有情绪和感受，但我随时\n",
      "推理时间: 2.812s\n",
      "--------------------------------------------------\n",
      "平均推理时间: 2.912s\n"
     ]
    }
   ],
   "source": [
    "test_model_inference(base_model, tokenizer, \"原始模型\", max_new_tokens=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\n--- LoRA Model 推理测试 ---\n",
      "问题 1: 你是谁？\n",
      "回答: 我是甄嬛，家父是大理寺少\n",
      "推理时间: 3.198s\n",
      "--------------------------------------------------\n",
      "问题 2: 你住在哪里？\n",
      "回答: 臣妾家在西边，离皇上寝\n",
      "推理时间: 3.193s\n",
      "--------------------------------------------------\n",
      "问题 3: 你最喜欢什么？\n",
      "回答: 臣妾喜欢花，尤其是梅花。\n",
      "推理时间: 2.748s\n",
      "--------------------------------------------------\n",
      "问题 4: 你今天心情如何？\n",
      "回答: 臣妾近日心事重重，不敢多想\n",
      "推理时间: 3.041s\n",
      "--------------------------------------------------\n",
      "平均推理时间: 3.045s\n"
     ]
    }
   ],
   "source": [
    "test_model_inference(lora_model, tokenizer, model_name=\"LoRA Model\", max_new_tokens=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\n--- quantized_model 推理测试 ---\n",
      "问题 1: 你是谁？\n",
      "回答: ，你怎么知道她病了？——别理\n",
      "推理时间: 1.103s\n",
      "--------------------------------------------------\n",
      "问题 2: 你住在哪里？\n",
      "回答: 我叫甄嬛，是大理寺少卿\n",
      "推理时间: 1.138s\n",
      "--------------------------------------------------\n",
      "问题 3: 你最喜欢什么？\n",
      "回答: 最是那一低头的温柔，像一朵水\n",
      "推理时间: 1.083s\n",
      "--------------------------------------------------\n",
      "问题 4: 你今天心情如何？\n",
      "回答: 我好得很，皇上也很好，只是眉\n",
      "推理时间: 1.093s\n",
      "--------------------------------------------------\n",
      "平均推理时间: 1.104s\n"
     ]
    }
   ],
   "source": [
    "test_model_inference(model_int8, tokenizer, model_name=\"quantized_model\", max_new_tokens=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从上面运行结果可以看出，当模型的**输出内容长度相近**时，原始模型和LoRA模型的**推理速度相近**，因为他们的**架构和参数类型相同**；而量化模型通过**将参数类型转换为8-bit**，大幅**提升了推理速度**。\n",
    "\n",
    "下面我们来比较模型占用的静态存储空间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义辅助函数\n",
    "\n",
    "def get_directory_size(directory_path):\n",
    "    \"\"\"计算一个目录的总大小（单位：字节）\"\"\"\n",
    "    total_size = 0\n",
    "    # os.walk 会遍历目录树\n",
    "    for dirpath, dirnames, filenames in os.walk(directory_path):\n",
    "        for f in filenames:\n",
    "            # 拼接完整的文件路径\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            # 跳过符号链接，以防无限循环\n",
    "            if not os.path.islink(fp):\n",
    "                total_size += os.path.getsize(fp)\n",
    "    return total_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始模型大小: 29051.48 MB\n"
     ]
    }
   ],
   "source": [
    "# 原始模型\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# 将原始模型保存到本地\n",
    "torch.save(base_model, \"./base_model.pt\")\n",
    "\n",
    "# 计算base_model的大小\n",
    "file_size_mb = os.path.getsize(\"./base_model.pt\") / 1024**2\n",
    "print(f\"原始模型大小: {file_size_mb:.2f} MB\")\n",
    "\n",
    "# 删除base_model\n",
    "os.remove(\"./base_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA参数大小: 19.28 MB\n",
      "lora模型大小: 29051.48 MB\n"
     ]
    }
   ],
   "source": [
    "# LoRA模型参数和LoRA模型大小\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "dir_size = get_directory_size(\"./lora_7b_weights\")\n",
    "print(f\"LoRA参数大小: {dir_size / 1024**2:.2f} MB\")\n",
    "\n",
    "# 将LoRA模型保存到本地\n",
    "torch.save(unlora_model, \"./lora_model.pt\")\n",
    "file_size_mb = os.path.getsize(\"./lora_model.pt\") / 1024**2\n",
    "print(f\"lora模型大小: {file_size_mb:.2f} MB\")\n",
    "\n",
    "# 删除lora_model\n",
    "os.remove(\"./lora_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "量化后模型大小: 8823.28 MB\n"
     ]
    }
   ],
   "source": [
    "# 量化后模型大小\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# 将量化后模型保存到本地\n",
    "torch.save(model_int8, \"./model_int8.pt\")\n",
    "\n",
    "# 计算base_model的大小\n",
    "file_size_mb = os.path.getsize(\"./model_int8.pt\") / 1024**2\n",
    "print(f\"量化后模型大小: {file_size_mb:.2f} MB\")\n",
    "\n",
    "# 删除model_int8\n",
    "os.remove(\"./model_int8.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从代码运行结果可以看出：\n",
    "\n",
    "- 传统微调成本高昂，每个微调版本都需要存储一个完整的GB级模型副本\n",
    "\n",
    "- LoRA技术解决了微调存储的难题，仅需保存MB级的轻量适配器，极大提升了多版本管理的效率与可行性\n",
    "\n",
    "- 量化技术解决了基础模型存储的难题，通过压缩权重，直接减小核心模型的体积。\n",
    "\n",
    "结合LoRA微调和模型量化技术，我们可以实现存储成本的极致优化。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.7 小结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在本章的探索之旅中，我们一同揭开了LoRA微调与模型量化的神秘面纱。这两项强大的技术，正在悄然改变着我们与大模型互动的方式，让曾经遥不可及的AI能力，如今触手可得。\n",
    "\n",
    "让我们回顾整个过程：\n",
    "\n",
    "- 首先，我们领略了LoRA的魅力，它仅需训练一小部分“插件”参数，就能让大模型了解我们的需求，高效地适应新任务。\n",
    "\n",
    "- 接着，我们深入了解了量化技术，它通过巧妙的数值转换，让模型的存储占用和推理速度都得到了显著优化。\n",
    "\n",
    "希望通过本章的学习，您不仅掌握了两种实用的工具，更能感受到技术创新背后那份化繁为简的独特魅力。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.8 参考文献"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **LoRA: Low-Rank Adaptation of Large Language Models**  \n",
    "   Hu, Edward J., et al. (2021)  \n",
    "   [https://arxiv.org/abs/2106.09685](https://arxiv.org/abs/2106.09685)\n",
    "\n",
    "2. **QLoRA: Efficient Finetuning of Quantized LLMs**  \n",
    "   Dettmers, Tim, et al. (2023)  \n",
    "   [https://arxiv.org/abs/2305.14314](https://arxiv.org/abs/2305.14314)\n",
    "\n",
    "3. **Parameter-Efficient Fine-Tuning of Large-Scale Pre-Trained Language Models**  \n",
    "   Li, Xiang Lisa, and Percy Liang (2021)  \n",
    "   Nature Machine Intelligence\n",
    "\n",
    "4. **The Power of Scale for Parameter-Efficient Prompt Tuning**  \n",
    "   Lester, Brian, et al. (2021)  \n",
    "   [https://arxiv.org/abs/2104.08691](https://arxiv.org/abs/2104.08691)\n",
    "\n",
    "5. **PEFT: State-of-the-art Parameter-Efficient Fine-tuning methods**  \n",
    "   Hugging Face PEFT Library  \n",
    "   [https://github.com/huggingface/peft](https://github.com/huggingface/peft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.9 参考习题\n",
    "\n",
    "### 习题 1\n",
    "\n",
    "LoRA (Low-Rank Adaptation) 微调技术的核心思想是什么？\n",
    "\n",
    "A. 在微调过程中，更新模型的所有参数以适应新任务。\n",
    "\n",
    "B. 冻结预训练模型的大部分参数，仅注入并训练少量可训练的低秩矩阵。\n",
    "\n",
    "C. 剪枝（Pruning）模型中不重要的参数，以减少模型大小。\n",
    "\n",
    "D. 只对模型的嵌入层（Embedding Layer）进行训练。\n",
    "\n",
    "参考答案：B。\n",
    "\n",
    "解析：LoRA的核心思想是保持预训练模型的主体参数不变（冻结），只在特定层（如注意力层）中加入新的、参数量很少的低秩矩阵（即旁路）进行训练，从而以极小的代价实现对模型的微调。\n",
    "\n",
    "### 习题 2\n",
    "\n",
    "在LoRA中，低秩矩阵A和B通常如何初始化，为什么？\n",
    "\n",
    "A. A和B都初始化为零矩阵，以保证训练的稳定性。\n",
    "\n",
    "B. A采用高斯分布初始化，B初始化为零矩阵，以确保微调在初始时对原模型没有影响，从而平稳过渡。\n",
    "\n",
    "C. A和B都采用高斯分布初始化，以引入随机性，帮助模型跳出局部最优。\n",
    "\n",
    "D. A初始化为零矩阵，B采用高斯分布初始化，这是效果最好的组合。\n",
    "\n",
    "**参考答案**：B。解析：如10.3.3节所述，将矩阵B初始化为零，可以保证在训练开始时，LoRA模块的输出为零（$\\triangle W = BA = 0$），这意味着微调从原始模型状态平稳启动，避免了初始的随机扰动。如果A也为零，则梯度始终为零，无法训练。\n",
    "\n",
    "### 习题 3\n",
    "\n",
    "模型量化（Quantization）技术最主要的目标是？\n",
    "\n",
    "A. 提升模型在所有任务上的预测准确率。\n",
    "\n",
    "B. 增加模型的参数量，使其具备更强的学习能力。\n",
    "\n",
    "C. 方便研究人员理解模型每一层的具体作用。\n",
    "\n",
    "D. 降低模型参数的数值精度，以减小模型体积、降低显存占用并加速推理。\n",
    "\n",
    "**参考答案**：D。解析：模型量化的核心价值在于模型压缩和加速。通过将高精度浮点数（如FP32）转换为低精度整数（如INT8、INT4），模型占用的存储空间和内存（显存）大幅减少，并且整数运算在很多硬件上比浮点运算更快，从而提升了推理速度。\n",
    "\n",
    "### 习题 4\n",
    "\n",
    "关于8比特量化中的对称量化（Symmetric）与非对称量化（Asymmetric），以下描述正确的是？\n",
    "\n",
    "A. 对称量化通过调整零点（Zero-Point）来精确匹配数据的实际范围，精度通常更高。\n",
    "\n",
    "B. 非对称量化强制将零点（Zero-Point）设为0，计算更简单。\n",
    "\n",
    "C. 对称量化将浮点数范围强制扩展为关于0对称后再映射，而非对称量化则会计算一个零点来精确利用整个整数范围。\n",
    "\n",
    "D. 在大语言模型中，对称量化是唯一被使用的方法。\n",
    "\n",
    "**参考答案**：C。解析：根据10.5.2节的图文解释，对称量化的特点是强制零点Z=0，并将数据范围对称化（如[-7.59, 10.8]扩展为[-10.8, 10.8]），这可能浪费一部分量化空间。非对称量化会计算一个浮点零点Z，使原始数据范围能更紧密地映射到整数范围，通常能保留更高精度。\n",
    "\n",
    "### 习题 5\n",
    "\n",
    "编写一段代码，可视化 LoRA 对模型权重的改变\n",
    "\n",
    "**Hint**: 可以通过查看模型结构并选择目标层来进行权重比较，你可能会用到 `getattr` 来提取相关内容\n",
    "\n",
    "参考代码：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/lora/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. 环境准备 ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # 可视化在CPU上进行即可\n",
    "model_name = \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "\n",
    "# --- 2. 提取特定层的权重 ---\n",
    "# 我们选择第一个注意力块中的 q_proj 线性层\n",
    "layer_index = 0\n",
    "target_layer_name = f\"model.layers.{layer_index}.self_attn.q_proj\"\n",
    "\n",
    "# 使用 getattr 递归获取层对象\n",
    "def get_layer(model, name):\n",
    "    for part in name.split('.'):\n",
    "        model = getattr(model, part)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.80it/s]\n"
     ]
    }
   ],
   "source": [
    "# 加载基础模型\n",
    "base_model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float32, trust_remote_code=True).to(device)\n",
    "\n",
    "base_layer_weight = get_layer(base_model, target_layer_name).weight.detach().cpu()\n",
    "\n",
    "lora_model = PeftModel.from_pretrained(base_model, \"./lora_7b_weights\")\n",
    "merged_model = lora_model.merge_and_unload()\n",
    "\n",
    "merged_layer_weight = get_layer(merged_model, target_layer_name).weight.detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "基础模型中 'model.layers.0.self_attn.q_proj' 的权重张量形状: torch.Size([3584, 3584])\n",
      "权重差异张量的均值: -1.683461761e-07\n",
      "权重差异张量的标准差: 2.9283e-04\n",
      "权重差异张量的最大值: 0.0036\n",
      "权重差异张量的最小值: -0.0032\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- 3. 计算并可视化权重差异 ---\n",
    "weight_difference = merged_layer_weight - base_layer_weight\n",
    "\n",
    "print(f\"基础模型中 '{target_layer_name}' 的权重张量形状: {base_layer_weight.shape}\")\n",
    "print(f\"权重差异张量的均值: {weight_difference.mean():.9e}\")\n",
    "print(f\"权重差异张量的标准差: {weight_difference.std():.4e}\")\n",
    "print(f\"权重差异张量的最大值: {weight_difference.max():.4f}\")\n",
    "print(f\"权重差异张量的最小值: {weight_difference.min():.4f}\")\n",
    "\n",
    "# 绘制权重差异的直方图\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(weight_difference.numpy().flatten(), bins=100, color='skyblue', edgecolor='black')\n",
    "plt.title(f'Histogram of Weight Difference ({target_layer_name})')\n",
    "plt.xlabel('Weight Difference (Merged - Base)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lora",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
